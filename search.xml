<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>基于日志的崩溃后的数据恢复 | redo, undo log</title>
    <url>/2019/03/21/Storage/data_crash_recovery/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="15d8148e902bf538b15af1cf4ed188259b1765ad7444ce8e9719ba66f764a764">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Storage</category>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>C/C++ Optimization Tools</title>
    <url>/2018/07/12/Tool/C++_develop_tools/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="3fd51de59615cf3d055867c7adf8c3bb0aa9df0e908e4be6b20de83cc17ba661">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Tool</category>
      </categories>
  </entry>
  <entry>
    <title>Database Transaction - ACID &amp; Isolation Level</title>
    <url>/2021/04/05/Storage/Database/Database_Transaction/</url>
    <content><![CDATA[<h1 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h1><p>ACID  is a set of properties of database transactions intended to guarantee data validity despite concurrency, errors, power failures, and other mishaps.</p>
<h2 id="A-Atomcity-原子性"><a href="#A-Atomcity-原子性" class="headerlink" title="A - Atomcity - 原子性"></a>A - Atomcity - 原子性</h2><p><strong>ALL-or-Nothing</strong><br>Transactions are often composed of multiple statements. Atomicity guarantees that each transaction is treated as a single “unit”, which either succeeds completely or fails completely: if any of the statements constituting a transaction fails to complete, the entire transaction fails and <code>rollback</code> the data to the unchanged. </p>
<h2 id="C-Consistency-一致性"><a href="#C-Consistency-一致性" class="headerlink" title="C - Consistency - 一致性"></a>C - Consistency - 一致性</h2><p>The guarantee that database constraints are not violated, particularly once a transaction commits.<br>The guarantee that any transactions started in the future necessarily see the effects of other transactions committed in the past.</p>
<h2 id="I-Isolation-隔离性"><a href="#I-Isolation-隔离性" class="headerlink" title="I - Isolation - 隔离性"></a>I - Isolation - 隔离性</h2><p>Transactions are often executed concurrently (e.g., multiple transactions reading and writing to a table at the same time). Isolation ensures that concurrent execution of transactions leaves the database in the same state that would have been obtained if the transactions were executed sequentially. Isolation is the main goal of <strong>concurrency control(isolation level)</strong>.</p>
<blockquote>
<p>the effects of an incomplete transaction might not be visible to other transactions depending on the isolation level</p>
</blockquote>
<h2 id="D-Durability-持久性"><a href="#D-Durability-持久性" class="headerlink" title="D - Durability - 持久性"></a>D - Durability - 持久性</h2><p>It guarantees that once a transaction has been committed, it will remain committed even in the case of a system failure. This usually means that completed transactions (or their effects) are recorded in non-volatile memory(e.g. disk).</p>
<h1 id="Isolation-Level-Concurrency-Control"><a href="#Isolation-Level-Concurrency-Control" class="headerlink" title="Isolation Level - Concurrency Control"></a>Isolation Level - Concurrency Control</h1><h2 id="Serializable-可序列化-level-3"><a href="#Serializable-可序列化-level-3" class="headerlink" title="Serializable(可序列化) - level 3"></a>Serializable(可序列化) - level 3</h2><p>It’s the most restrictive of all isolation levels. All Transactions that may affect others are executed serially.<br>All transactions are protected by <strong>read-write(RW) lock</strong> with the level of <strong>range&#x2F;table</strong>. </p>
<ul>
<li>Pros: best consistency of all committed value</li>
<li>Cons: extremely bad performance, usually 30x slower than <strong>repeatable read</strong></li>
</ul>
<h2 id="Repeatable-Read-可重复读-level-2-Default-level-in-most-DBs"><a href="#Repeatable-Read-可重复读-level-2-Default-level-in-most-DBs" class="headerlink" title="Repeatable Read(可重复读) - level 2 - Default level in most DBs"></a>Repeatable Read(可重复读) - level 2 - Default level in most DBs</h2><ul>
<li>Pros: consistency of row-level committed value</li>
<li>Cons: range-based query may meet <strong>phantom read</strong></li>
</ul>
<h3 id="Phantom-Read-幻读"><a href="#Phantom-Read-幻读" class="headerlink" title="Phantom Read(幻读)"></a>Phantom Read(幻读)</h3><p><img src="/2021/04/05/Storage/Database/Database_Transaction/phantom_read.png" alt="Phantom read" loading="lazy"><br>Transaction A reads the same range again and will get the new record that Transaction B just inserted. The results of these two range-based readings are different. e.g. count operation.</p>
<h2 id="Read-Committed-读已提交-level-1"><a href="#Read-Committed-读已提交-level-1" class="headerlink" title="Read Committed(读已提交) - level 1"></a>Read Committed(读已提交) - level 1</h2><p>A transaction can’t read data that is not yet committed by other transactions.</p>
<ul>
<li>Pros: solve dirty read</li>
<li>Cons: query may hit non-repeated&#x2F;Phantom read</li>
</ul>
<h3 id="Non-Repeated-Read-不可重复读"><a href="#Non-Repeated-Read-不可重复读" class="headerlink" title="Non-Repeated Read(不可重复读)"></a>Non-Repeated Read(不可重复读)</h3><p><img src="/2021/04/05/Storage/Database/Database_Transaction/Non-repeatable_read.png" alt="2022-12-03T143934" loading="lazy"></p>
<h2 id="Read-uncommitted-level-0-未提交读-无锁"><a href="#Read-uncommitted-level-0-未提交读-无锁" class="headerlink" title="Read uncommitted - level 0 - 未提交读 ~ 无锁"></a>Read uncommitted - level 0 - 未提交读 ~ 无锁</h2><p>A transaction can read the latest data modified by other transactions which may be even uncommitted (Dirty Read). </p>
<h3 id="Dirty-Read-脏读-："><a href="#Dirty-Read-脏读-：" class="headerlink" title="Dirty Read(脏读)："></a>Dirty Read(脏读)：</h3><p><img src="/2021/04/05/Storage/Database/Database_Transaction/dirty_read.png" alt="dirty_read" loading="lazy"><br>Transaction B may read the uncommitted data written by A.</p>
<h2 id="Isolation-Summary"><a href="#Isolation-Summary" class="headerlink" title="Isolation Summary"></a>Isolation Summary</h2><table>
<thead>
<tr>
<th>Consistency Problem</th>
<th>Dirty Read</th>
<th>Non-repeatable read</th>
<th>Phantom read</th>
</tr>
</thead>
<tbody><tr>
<td>SERIALIZABLE</td>
<td>no</td>
<td>no</td>
<td>no</td>
</tr>
<tr>
<td>REPEATABLE_READ</td>
<td>no</td>
<td>no</td>
<td>yes in isolation definition <br> <strong>No for MVCC based snapshot read</strong></td>
</tr>
<tr>
<td>READ_COMMITTED</td>
<td>no</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>READ_UNCOMMITTED</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
</tbody></table>
<h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><h2 id="Atomicity-Durability"><a href="#Atomicity-Durability" class="headerlink" title="Atomicity + Durability"></a>Atomicity + Durability</h2><p>Common mechanisms:</p>
<ol>
<li><p><strong>Redo&#x2F;Undo Logging</strong>: Write ahead log(WAL) records all operations before execution. It could redo or undo incompleted operations when failures happen.</p>
</li>
<li><p><strong>Shadow Paging</strong>: a <strong>copy-on-write</strong> technique for avoiding in-place updates of pages. Instead, when a page is to be modified, a shadow page is allocated. Since the shadow page has no references (from other pages on disk), it can be modified liberally, without concern for consistency constraints, etc. When the page is ready to become durable, all pages that referred to the original are updated to refer to the new replacement page instead. Because the page is “activated” only when it is ready, it is atomic.</p>
</li>
</ol>
<h2 id="Consistency-Isolation"><a href="#Consistency-Isolation" class="headerlink" title="Consistency + Isolation"></a>Consistency + Isolation</h2><h3 id="Legacy-LBCC-Pessimistic-悲观-Lock"><a href="#Legacy-LBCC-Pessimistic-悲观-Lock" class="headerlink" title="Legacy - LBCC - Pessimistic(悲观) Lock"></a>Legacy - LBCC - Pessimistic(悲观) Lock</h3><p><em><strong>Lock Based Concurrency Control</strong></em><br>Database with legacy version applies lock-based concurrency control.</p>
<ul>
<li>Serializable(可序列化) -  table&#x2F;range RW lock</li>
<li>Repeatable Read(可重复读) - row-level RW lock</li>
<li>Read Committed(读已提交)<ul>
<li>It’s still row-level RW lock based but the read operation just checks W(X) lock but did not acquire R(X) lock, write operation acquires W(X) Lock to block other operations and releases the lock after commit.</li>
</ul>
</li>
<li>Read uncommitted(读未提交)<ul>
<li>Just control concurrency on the statement level: it’s almost the same with <code>Read</code> Committed&#96; but release lock right after statement execution instead of commit.</li>
</ul>
</li>
</ul>
<blockquote>
<p>It usually uses shared(read) and exclusive(write) lock to achieve the read-write(RW) lock.</p>
<ul>
<li>A shared (S, read) lock permits the transaction that holds the lock to read a row.</li>
<li>An exclusive (X, write) lock permits the transaction that holds the lock to update or delete a row.</li>
</ul>
</blockquote>
<ul>
<li>Pros: easy to implement and understand </li>
<li>Cons: <strong>too many blockers &#x3D;&gt; too much read waiting!!!!</strong></li>
</ul>
<h3 id="Modern-MVCC-Version-as-Optimistic-乐观-Lock"><a href="#Modern-MVCC-Version-as-Optimistic-乐观-Lock" class="headerlink" title="Modern - MVCC - Version as Optimistic(乐观) Lock"></a>Modern - MVCC - Version as Optimistic(乐观) Lock</h3><p><em><strong>Multi-Version Concurrency Control</strong></em><br>Mysql default storage engine InnoDB applies MVCC to optimize <code>READ_COMMITED</code> and <code>REPEATED_READ</code>, since there is no need to check&#x2F;acquire lock when reading. </p>
<p>It <strong>enables snapshot read</strong>, that is, the read operation gets data with a bit early version without waiting even when it’s operated by the write operation.</p>
<blockquote>
<p>There is no difference on level READ_UNCOMMITTED and SEARIALIZABLE, the write lock is still maintained by sql Server which is out of InnoDB engine to avoid parallel write operations on the same record (row).</p>
</blockquote>
<h4 id="Two-additional-hidden-columns-per-row"><a href="#Two-additional-hidden-columns-per-row" class="headerlink" title="Two additional hidden columns per row"></a>Two additional hidden columns per row</h4><ol>
<li>transaction id <code>DB_TRX_ID</code>:<br>  It indicates the transaction identifier for the last transaction that inserted or updated the row. Also, a deletion is treated internally as an update where a special bit in the row is set to mark it as deleted.</li>
<li>rollback pointer <code>DB_ROLL_PTR</code>:<br> It points to an <strong>undo log record</strong> written to the rollback segment. If the row was updated, the undo log record contains the information necessary to rebuild the content of the row before it was updated.</li>
</ol>
<h4 id="How-version-transcation-id-works"><a href="#How-version-transcation-id-works" class="headerlink" title="How version(transcation id) works?"></a>How version(transcation id) works?</h4><p>Every transaction is created along with a monotonically increasing ID (e.g. timestamps). In other words, the latest created transaction ID owns the largest ID.</p>
<ul>
<li><p>Write</p>
<ul>
<li><code>INSERT</code>: insert the new record(row) setting <code>DB_TRX_ID</code> with current transaction ID</li>
<li><code>DELETE</code>: do not remove the record, but update <code>DB_TRX_ID</code> of the record(row) to current transaction ID and mark it as <code>deleted</code>.</li>
<li><code>UPDATE</code>: keep the original record(row) but mark it as <code>deleted</code>, then create a new record(row) with changed data and current transaction ID.</li>
</ul>
<p>All write operations will add rollback segment to undo log and set the pointer in the changed record.</p>
</li>
<li><p>Snapshot Read(快照读) </p>
<ul>
<li><code>SELECT</code>: transcation is only able to read the record whose <code>DB_TRX_ID</code> is &lt;&#x3D; current transaction ID and not in the ReadView.</li>
<li><strong>ReadView</strong>: a transaction id list stands for all active(uncommitted) transactions at the moment of executing <code>Select</code>. Read View is a <strong>static view</strong> of active transactions id and created right before executing<ul>
<li>the first <code>select</code> in transaction for REPEATED_READ</li>
<li>every <code>select</code> for READ_COMMITED</li>
</ul>
</li>
</ul>
<p>In REPEATED_READ level, static view protects the current transaction from the impact of the other. For example, even the active transaction commits after creating read view, its effect is ignored due to either a bigger ID or exsitence of ReadView. So snapshot read could prevent phantom read.</p>
</li>
</ul>
<blockquote>
<p>*Further Reading: Locking Read(当前读, 锁定读)<br>However database also supports the statement to read the latest committed values in the REPEATED_READ level，such as</p>
<ul>
<li>SELECT … LOCK IN SHARE MODE;  # R(S) LOCK</li>
<li>SELECT … FOR UPDATE; # X(W) LOCK</li>
<li>In a transaction, SELECT … after<ul>
<li>INSERT INTO  values …  # X(W) LOCK</li>
<li>DELETE FROM  WHERE …  # X(W) LOCK</li>
<li>UPDATE  SET …  # X(W) LOCK</li>
</ul>
</li>
</ul>
<p>Modern database will add lock to avoid confict and the Lock Reading should wait for the lock release in </p>
</blockquote>
<blockquote>
<p> The Phantom read may happen during Locking Read if the database does not support range-based(next-key, gap) RW lock for Locking Read.</p>
</blockquote>
<h4 id="Relationship-between-MVCC-and-index"><a href="#Relationship-between-MVCC-and-index" class="headerlink" title="Relationship between MVCC and index"></a>Relationship between MVCC and index</h4><p>In short, MVCC is transparent to index. They are independent.</p>
<p>MVCC creates additional rows&amp;columns to keep multiple versions of one row in the table at the same time, index regards all rows as valid rows so that it also keeps multiple index entries for different versions of a single row.</p>
<!-- # BASE 
Basic Availability, Soft-state, Eventual Consistency

- Reduce consistency to eventual consistency
- Improve Availability
Applied in the modern large distributed system
<!-- https://yeasy.gitbook.io/blockchain_guide/04_distributed_system/acid -->





<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://vcfvct.wordpress.com/2015/10/15/spring-transaction-isolation-level/">Spring transaction isolation level</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1731489">腾讯面试：MySQL事务与MVCC如何实现的隔离级别</a></li>
<li><a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html">MySQL 5.7 Reference Manual  &#x2F;  The InnoDB Storage Engine  &#x2F;  InnoDB Multi-Versioning</a></li>
</ul>
]]></content>
      <categories>
        <category>Storage</category>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>LevelDB 和 RocksDB 结构详解</title>
    <url>/2020/07/21/Storage/Database/LevelDB_RocksDB/</url>
    <content><![CDATA[<p>阅读本文之前建议对LSM树有一定的认识。本文将介绍LSM Tree的主流实现，即LevelDB和RocksDB作为KV数据库。</p>
<p>两者对外提供的主要接口基本一致，就是包含以下5个基本操作</p>
<ul>
<li>get(K) 查找key K对应的value</li>
<li>put(K,V) 插入键值对（K，V）</li>
<li>update(K,V) 查找key K对应的value更新为V</li>
<li>delete(K) 删除key K对应的条目</li>
<li>scan(K1,K2) 得到从K1到K2的所有key和value</li>
</ul>
<p>我们将从静态和动态角度去介绍两个数据库<br>先从LevelDB开始，相对好理解。毕竟RocksDB是在levelDB上做的改进</p>
<h1 id="LeveldDB"><a href="#LeveldDB" class="headerlink" title="LeveldDB"></a>LeveldDB</h1><p>接下从静态和动态角度去介绍</p>
<blockquote>
<p>静态视角：假想整个系统正在运行过程中（不断插入删除读取数据），此时我们给LevelDb照相，从照片可以看到之前系统的数据在内存和磁盘中是如何分布的，处于什么状态等.<br>动态视角：了解系统是如何写入一条记录，读出一条记录，删除一条记录的，同时也包括除了这些接口操作外的内部操作比如compaction，系统运行时崩溃后如何恢复系统等等方面。</p>
</blockquote>
<h2 id="架构-静态视角"><a href="#架构-静态视角" class="headerlink" title="架构 - 静态视角"></a>架构 - 静态视角</h2><p><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/leveldb_str.png" loading="lazy"></p>
<h3 id="内存-（对应LSM的C0）"><a href="#内存-（对应LSM的C0）" class="headerlink" title="内存 （对应LSM的C0）"></a>内存 （对应LSM的C0）</h3><ul>
<li><p>memtable  </p>
<ul>
<li>结构：<strong>SKIPLIST</strong> ， 和immutable memtable 完全相同。</li>
<li>读写：允许读写</li>
<li>功能：当Memtable写入的数据占用内存到达指定数量，则自动转换为Immutable Memtable，等待Dump到磁盘中，系统会自动生成新的Memtable供写操作写入新数据</li>
<li>删除：并不存在真正的删除操作,删除某个Key的Value在Memtable内是作为插入一条记录实施的，但是会打上一个Key的删除标记，真正的删除操作是Lazy的，会在以后的Compaction过程中去掉这个KV </li>
<li>重启时：会从log中恢复。</li>
</ul>
</li>
<li><p>immutable memtable</p>
<ul>
<li>正在进行写入磁盘操作的memtable</li>
</ul>
</li>
</ul>
<h3 id="磁盘中"><a href="#磁盘中" class="headerlink" title="磁盘中"></a>磁盘中</h3><ul>
<li><p>log(WAL)</p>
<ul>
<li>属于write-ahead-log，每个写入操作，都会往log尾部添加一个完整的kv记录</li>
<li>主作用是故障恢复，可以用于恢复memtable和immutable memtable</li>
</ul>
</li>
<li><p>current<br>current指出当前有效的那个manifest是哪个<br>随着Compaction进行，sstable变化，manifest会记录这些变化</p>
</li>
<li><p>manifest<br> 记载sst各文件的信息(LEVEL, NAME, MIN_KEY, MAX_KEY)<br><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/manifest.png" loading="lazy"></p>
</li>
<li><p>SST文件（Semi-sort table） （<strong>对应LSM的C1-N</strong>）</p>
<ul>
<li>文件中key有序存储，存储一个范围(K1,K2)之间的键值对</li>
<li>Level 0的 SST之间可能存在key重叠 ， Level 1+ 的SST不会有key重叠</li>
<li>所有文件是一种层级结构，第一层为Level 0，第二层为Level 1，层级逐渐增高，每一层的容量也会增大，这也是称为LevelDB的原因。这level的设计上LevelDB和RocksDB完全一致。其大小关系往往是每个级别差10倍，如下图：<br><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/rocksdb_level.png" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="SST文件-对应LSM的C1-N"><a href="#SST文件-对应LSM的C1-N" class="headerlink" title="SST文件 (对应LSM的C1-N)"></a>SST文件 (对应LSM的C1-N)</h3><h4 id="物理布局"><a href="#物理布局" class="headerlink" title="物理布局"></a>物理布局</h4><p><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/leveldb_sst_phy.png" loading="lazy"></p>
<h4 id="逻辑结构"><a href="#逻辑结构" class="headerlink" title="逻辑结构"></a>逻辑结构</h4><p><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/leveldb_sst_logic.png" loading="lazy"></p>
<h5 id="数据存储区"><a href="#数据存储区" class="headerlink" title="数据存储区"></a>数据存储区</h5><p>存储实际的key-value，<strong>单个</strong>block里面内容如下<br>  <img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/LSM_data_block.png" loading="lazy"></p>
<p>“重启点”（Restart Point）, 其实是一些指针，<strong>为了降低数据冗余</strong> 指出Block内容中的一些记录位置。在这条记录开始，不再采取只记载不同的Key部分，而是重新记录所有的Key值。<br><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/leveldb_restart.png" loading="lazy"></p>
<h5 id="数据管理区"><a href="#数据管理区" class="headerlink" title="数据管理区"></a>数据管理区</h5><ul>
<li>meta block ：记录这个SST文件的一些元信息，比如record个数，数据大小等</li>
<li>footer ： 指向（索引）index block的index</li>
<li><strong>index block</strong>： 指向data block在文件中的地址，用于查找数据在哪个block内<br><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/leveldb_index_block.png" loading="lazy"></li>
</ul>
<h2 id="操作-动态视角"><a href="#操作-动态视角" class="headerlink" title="操作 - 动态视角"></a>操作 - 动态视角</h2><h3 id="写-插入、-更新、删除数据"><a href="#写-插入、-更新、删除数据" class="headerlink" title="写 - 插入、 更新、删除数据"></a>写 - 插入、 更新、删除数据</h3><ul>
<li>插入： 同步操作就是（决定延迟），就是先顺序写入log（内部无序），然后写入memtable。 异步写入后续就是要看compaction。</li>
<li>更新： 当做插入处理。</li>
<li>删除： 不是直接删除，而是加入了一个删除标记</li>
</ul>
<h4 id="compaction"><a href="#compaction" class="headerlink" title="compaction"></a>compaction</h4><p>目的： 完成数据的沉降，同时由于之前的插入、删除操作，数据有很多的冗余。压缩，然后删除掉一些不再有效的KV数据，减小数据规模，减少文件数。</p>
<h5 id="flush-Memtable-gt-LEVEL0"><a href="#flush-Memtable-gt-LEVEL0" class="headerlink" title="flush (Memtable -&gt; LEVEL0)"></a>flush (Memtable -&gt; LEVEL0)</h5><ul>
<li>触发条件： memtable大小超过阈值</li>
<li>结果： 其过程就是把immutable memtable简单持久化一个新sst</li>
<li>过程：依次写入sst，然后新建索引（所以一个level 0 sst数据大小和immutable memtable是一样的）</li>
<li>注意： 因为不考虑其他sst，所以level0的sst 键会存在会重叠</li>
</ul>
<h5 id="compaction-Level-i-gt-Level-i-1"><a href="#compaction-Level-i-gt-Level-i-1" class="headerlink" title="compaction (Level i -&gt; Level i+1)"></a>compaction (Level i -&gt; Level i+1)</h5><p>就是按文件产生次序轮询，合并之后原文件就失效等待删除，新的文件生效（manifest记录）</p>
<ul>
<li>触发条件level i 大小或者文件个数超过阈值 </li>
<li>过程: 以level i的一个文件为驱动，在 level i 找和level i+1 找存在key重叠的sst，然后滚动合并<ul>
<li>当i是0时，因为leveli文件之间存在重叠，所以是leveli和leveli+1的多个文件一起合并。 </li>
<li>当i是1时，当因为leveli的sst之间没有重叠，所以就是一个leveli的文件和多个L+1合并</li>
</ul>
</li>
<li>结果图示(i&gt;&#x3D;1情况)：<br><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/compaction.png" loading="lazy"></li>
<li>合并过程图示（即一个多路归并排序,图中L代表leveli的文件，L+1代表leveli+1的文件）：<br><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/leveldb_merge.png" loading="lazy"></li>
</ul>
<h4 id="读"><a href="#读" class="headerlink" title="读"></a>读</h4><p>先内存后磁盘，硬盘从上层至下层。（找到数据就返回，因为level小的里面的记录肯定是最新的）<br>先在memtable里面找，如果找不到则从磁盘文件中，对于磁盘上的每一个level，查找有三级：</p>
<ol>
<li>sst定位：优先新鲜(level小的)sst， 唯一特殊的就是level 0不同sst可能会有key重叠，所以要在manifest中找到符合条件的文件，按<strong>从新到旧的顺序</strong>依次查找。</li>
<li>sst内查找： 先看sst的索引是否已经加载到Cache， 没有就加载，然后定位block</li>
<li>block内查找：先在restart points上找，然后restart points之间顺序查找</li>
</ol>
<h5 id="缓存-Cache"><a href="#缓存-Cache" class="headerlink" title="缓存 Cache"></a>缓存 Cache</h5><p>为了加快查询，数据库都会将数据放入内存，来降低重复访问同一段数据带来的开销。<br>如：</p>
<ol>
<li>manifest内容存在缓存中</li>
<li>打开一个sst时，其索引块也会加载到缓存中</li>
<li>在一个block内查找时，也会将block加入到缓存</li>
</ol>
<h1 id="RocksDB"><a href="#RocksDB" class="headerlink" title="RocksDB"></a>RocksDB</h1><p>结构和levelDB大同小异，只是多了一些改进</p>
<ol>
<li>增加了column family，有了列簇的概念，可把一些相关的key存储在一起</li>
<li>内存中有多个immute memtalbe，可防止Leveldb中的 write stall</li>
<li>可支持多线程同时compation，理论上多线程同时comaption会比一个线程compation要快（TODO执行commpactiron的中心在哪）<!-- 4. 增加了merge operator，也就是原地更新，优化了modify的效率 （TODO）--></li>
<li>支持TTL </li>
<li>flush与compation分开不同的线程池来调度，并具有不同的优先级，flush要优于compation，这样可以加快flush，防止stall </li>
<li>对SSD存储做了优化，可以以in-memory方式运行 </li>
<li>增加了对 write ahead log（WAL）的管理机制，更方便管理WAL，WAL是binlog文件</li>
<li>支持多种不同的compaction策略</li>
</ol>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p><img src="/2020/07/21/Storage/Database/LevelDB_RocksDB/rocksdb_str.png" loading="lazy"></p>
<h1 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h1><p>同LSM Tree，唯一区别在于每一层分成了多个文件。</p>
<ul>
<li>优点：<ul>
<li>写延迟低</li>
<li>访问新数据更快，适合时序、实时存储<!-- - IO随机读写很少 --></li>
<li>空间放大率低</li>
</ul>
</li>
<li>缺点：<ul>
<li>写放大、读放大高</li>
<li>读放大</li>
<li>磁盘上修改数据的粒度必须是文件</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Storage</category>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>排序算法</title>
    <url>/2016/08/22/Programming/Algorithm/sort/</url>
    <content><![CDATA[<p>这里列举一下常见排序算法的对比。<br>个人觉得相对重要需要会手写的排序算法还是快速、归并、堆排序、插入，以及借助桶(基数)排序了解桶的思想。<br>其他排序不常用，就是了解概念即可。</p>
<h2 id="冒泡-Bubble-Sort"><a href="#冒泡-Bubble-Sort" class="headerlink" title="冒泡 Bubble Sort"></a>冒泡 Bubble Sort</h2><ul>
<li>说明<ul>
<li><p>相邻元素的比较和交换来把小的数交换到最前面，过程类似水泡上升</p>
</li>
<li><p>举例： 原始5,3,8,6,4，每一轮都是遍历N-1个元素，然后比较相邻元素，按大小关系交换，如下展示从尾部遍历的第一轮的过程</p>
<ol>
<li>46比较： 5,3,8,4,6</li>
<li>84比较： 5,3,4,8,6</li>
<li>…</li>
<li>第一轮结束： 3,5,4,8,6</li>
</ol>
<p>如此反复遍历全数据比较，直至某一轮没法发生交换即排序完成。</p>
</li>
</ul>
</li>
<li>复杂度 <ul>
<li>最好： O(n) 原本有序，一轮结束</li>
<li>最差，平均： O($n^2$)</li>
</ul>
</li>
</ul>
<h3 id="梳排序-comb-sort"><a href="#梳排序-comb-sort" class="headerlink" title="*梳排序 comb sort"></a>*梳排序 comb sort</h3><p>改进了冒泡排序，改进思想与下文希尔排序类似<br>比较少用，暂时不在这里说明了<br>复杂度有所改进，有兴趣可自己查阅其他资料，如<a href="https://www.yiibai.com/data_structure/comb-sort.html">梳排序 - 易百教程</a></p>
<h2 id="选择-Selection-Sort"><a href="#选择-Selection-Sort" class="headerlink" title="选择 Selection Sort"></a>选择 Selection Sort</h2><ul>
<li>说明<br>  每次选使得一个元素找到他应该所在的次序位置。<br>  每一趟在剩余元素中选择最值，将其交换至应该存在的位置，直到所有元素排序完成。<br>  保证第i轮结束后，前i个元素有序</li>
<li>复杂度<ul>
<li>最好、最差、平均：O($n^2$)</li>
<li>但是一般性能优于冒泡，因为选择排序每一轮至多有一次交换，即最多n次交换，而冒泡交换是O($n^2$)级别的</li>
</ul>
</li>
</ul>
<h2 id="插入-Insertion-Sort"><a href="#插入-Insertion-Sort" class="headerlink" title="插入 Insertion Sort"></a>插入 Insertion Sort</h2><ul>
<li><p>说明<br>基本操作是将一个元素插入到已经有序的数列中，从而得到一个新的有序数列<br>实质是用增量排序操作去解决定量排序问题</p>
</li>
<li><p>复杂度</p>
<ul>
<li>最好: O(n) 原本有序</li>
<li>最差、平均: O($n^2$)</li>
</ul>
</li>
</ul>
<h3 id="折半插入"><a href="#折半插入" class="headerlink" title="折半插入"></a>折半插入</h3><p>靠二分去定位要插入的位置，但是后续多个元素的位移，仍旧是O(n)级别的操作<br>复杂度类似</p>
<h3 id="希尔排序-Shell-Sort"><a href="#希尔排序-Shell-Sort" class="headerlink" title="希尔排序 Shell Sort"></a>希尔排序 Shell Sort</h3><p>基本思想是将相距某个增量gap的记录组成一个子序列，通过插入排序使得这个子序列基本有序。然后不断缩小gap，gap以不断折半为规则。 总体复杂度为<br>图解如下：<br><img src="/2016/08/22/Programming/Algorithm/sort/ss_1.png" loading="lazy"></p>
<h4 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h4><p>复杂度最终说法不一，可以明确的是 在O(N)和O(logN)之间，但是有些说是 O($n^{1.3}$) ，有些说是接近于O($NlogN$)， 我还没研究证明过</p>
<h2 id="快速排序-Quick-Sort"><a href="#快速排序-Quick-Sort" class="headerlink" title="快速排序 Quick Sort"></a>快速排序 Quick Sort</h2><p><strong>最常见</strong>的排序算法，各大基础库内置的基本都是这个算法。<br>采用分治思想，每次递归时选择一个点作为当前区间内的中点，将小于该中点的值放入左子树，大于该中点的放入右子树，然后继续对左子树和右子树进行相同的操作。 步骤描述如下：</p>
<ol>
<li>从数列中挑出一个元素，称为 “基准”（pivot）</li>
<li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。</li>
<li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。</li>
</ol>
<h3 id="几种实现方法"><a href="#几种实现方法" class="headerlink" title="几种实现方法"></a>几种实现方法</h3><p>实现的时候对于第2步的实现，有些trick的地方，直接按这个意思写写出来的代码性能会稍差，高效实现可以参看如下代码（均以顺序排序为例）：<br>下面代码中left和right都是指有效索引，即<code>vec[left]</code>和和<code>vec[right]</code>都有值</p>
<ul>
<li><p>取端点pivot的填充法</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuickSort</span><span class="params">(vector&lt;T&gt; &amp;vec, <span class="type">int</span> left, <span class="type">int</span> right)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 1 </span></span><br><span class="line">  T pivot = vec[left]; <span class="comment">//提出枢纽，这时left位置空出来了。</span></span><br><span class="line">  <span class="type">int</span> i = left, j = right;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (i &lt; j) &#123;<span class="comment">//注意两个内层while的顺序不能换</span></span><br><span class="line">      <span class="keyword">while</span> (i &lt; j &amp;&amp; vec[j] &gt;= pivot) j--; <span class="comment">//这里是&gt;=不能使&gt;，否则当数组元素等于枢纽时会死循环</span></span><br><span class="line">      vec[i] = vec[j];<span class="comment">//将找到的小于于枢纽的元素存到j所指的空穴，这时j位置空出来了</span></span><br><span class="line">      <span class="keyword">while</span> (i &lt; j &amp;&amp; vec[i] &lt;= pivot) i++; <span class="comment">//这里是&lt;=不能使&lt;，否则当数组元素等于枢纽时会死循环</span></span><br><span class="line">      vec[j] = vec[i];<span class="comment">//将找到的大于枢纽的元素存到j所指的空穴，这时i位置空出来了</span></span><br><span class="line">  &#125;</span><br><span class="line">  vec[i] = pivot;</span><br><span class="line">  <span class="type">int</span> pivot_pos = i;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (left &lt; pivot_pos - <span class="number">1</span>) <span class="built_in">QuickSort</span>(vec, left, pivot_pos - <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">if</span> (right &gt; pivot_pos + <span class="number">1</span>) <span class="built_in">QuickSort</span>(vec, pivot_pos + <span class="number">1</span>, right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
<li><p>Hoare交换法（以pivot中点为例）<br>减少了交换次数，效率更高</p>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuickSort</span><span class="params">(vector&lt;T&gt; &amp;vec, <span class="type">int</span> left, <span class="type">int</span> right)</span> </span>&#123; </span><br><span class="line"><span class="comment">// 1 </span></span><br><span class="line"> T pivot = vec[(left + right) / <span class="number">2</span>];</span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line"> <span class="type">int</span> i = left;</span><br><span class="line"> <span class="type">int</span> j = right;</span><br><span class="line"> <span class="keyword">while</span> (i &lt;= j) &#123;</span><br><span class="line">     <span class="keyword">while</span> (vec[i] &lt; pivot) i++; <span class="comment">// 从左找到一个&gt;=pivot的元素</span></span><br><span class="line">     <span class="keyword">while</span> (vec[j] &gt; pivot) j--; <span class="comment">// 从右找到一个&lt;=pivot的元素</span></span><br><span class="line">     <span class="keyword">if</span> (i &lt;= j) <span class="comment">// 交换两者位置</span></span><br><span class="line">         <span class="built_in">swap</span>(vec[i++], vec[j--]);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">// 3</span></span><br><span class="line"> <span class="keyword">if</span> (left &lt; j)  <span class="built_in">QuickSort</span>(vec, left, j);</span><br><span class="line"> <span class="keyword">if</span> (i &lt; right) <span class="built_in">QuickSort</span>(vec, i, right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h3><p>快排存在一定的随机性，主要来源于中点值的选择，</p>
<ul>
<li>最好情况O(NlogN)： 中点能平衡左右子树元素个数（选取的中点接近实际中点），那么属于最好情况</li>
<li>最差情况O($N^2$)： 中点划分出的左右子树元素非常不平衡，如刚好选择了最大值或者最小值。会导致随着深度增加，元素规模只会逐个减少。<ul>
<li>如果每次选取端点为中点，那么对于完全逆序的情况，就是最差情况。</li>
<li>选用随机基准法可以降低最差情况的概率</li>
</ul>
</li>
<li>平均O(NlogN)</li>
</ul>
<h3 id="优化"><a href="#优化" class="headerlink" title="*优化"></a>*优化</h3><ul>
<li>大规模下针对pivot选择做优化<ul>
<li>比如<code>三位取中法</code>， 从 数组左端，中断，右端选取一个中间大小的值，来提升中点能平衡左右个数的概率</li>
</ul>
</li>
<li>小规模下换其他算法<ul>
<li>因为递归调用和分割开销较大，可用插入排序代替</li>
</ul>
</li>
<li>3-way 特殊场景优化 相同的值做合并，每次划分，分成三个集合， 小于中点的集合，等于中点的集合，大于中点的集合<ul>
<li>如对于1 4 6 6 7 6 7 6 8 6 数组， 如果选取最右的6为中点，那么一轮划分后为 1 4 和 6 6 6 6 6 和 7 8 7</li>
</ul>
</li>
<li>双轴心快排 <code>DualPivotQuicksort</code><ul>
<li><strong>Java Arrays.sort的标准实现java.util.DualPivotQuicksort</strong></li>
<li>个人认为是泛化了相同的值做合并，并结合小规模换插入排序</li>
<li>大规模下每次设置两个轴点，分成3块 ，小规模下做插入排序，</li>
<li>有兴趣可以阅读<a href="https://github.com/frohoff/jdk8u-dev-jdk/blob/master/src/share/classes/java/util/DualPivotQuicksort.java">源码</a>。</li>
</ul>
</li>
<li>多线程下的快排优化<ul>
<li>TODO</li>
</ul>
</li>
</ul>
<p>我目前理解不够，以后有时间单独开一篇文章来讲快排各种优化与适用场景的理论和测试对比。</p>
<h2 id="堆排序-Heap-Sort"><a href="#堆排序-Heap-Sort" class="headerlink" title="堆排序 Heap Sort"></a>堆排序 Heap Sort</h2><p>借助堆不断输出堆顶元素来实现排序</p>
<h3 id="堆结构-（优先队列）"><a href="#堆结构-（优先队列）" class="headerlink" title="堆结构 （优先队列）"></a>堆结构 （优先队列）</h3><p>堆是一棵完全二叉树，要求树根就是所有元素中的最值。以大根堆为例，要求对于任意节点，其值 ≤ 左子树的值和右子树的值，即任意节点是其所在子树的最值。如下图：<br><img src="/2016/08/22/Programming/Algorithm/sort/big_heap.png" loading="lazy"><br>常以<code>树状数组</code>存储，若数组索引以1开始,则对应要求可以书写为 a[i] &gt;&#x3D; a[i * 2], a[i] &gt;&#x3D; a[i*2]。如下图：<br><img src="/2016/08/22/Programming/Algorithm/sort/heap_array.png" loading="lazy"></p>
<h4 id="结构定义"><a href="#结构定义" class="headerlink" title="结构定义"></a>结构定义</h4><blockquote>
<p>以下  <code>*2</code> <code>/2 </code>操作建议用位移操作加速，在这里为了方便理解就不用位移操作取代了</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Item&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MaxHeap</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Item *data;</span><br><span class="line">    <span class="type">int</span> count;</span><br><span class="line">    <span class="type">int</span> capacity;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">shiftDown</span><span class="params">(<span class="type">int</span> k)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">shiftUp</span><span class="params">(<span class="type">int</span> k)</span></span>;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MaxHeap</span>(<span class="type">int</span> capacity)&#123;</span><br><span class="line">        data = <span class="keyword">new</span> Item[capacity+<span class="number">1</span>]; count = <span class="number">0</span>;<span class="keyword">this</span>-&gt;capacity = capacity;</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">MaxHeap</span>()&#123;</span><br><span class="line">        <span class="keyword">delete</span>[] data;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">MaxHeap</span>(Item arr[], <span class="type">int</span> n);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(Item item)</span></span>;</span><br><span class="line">    <span class="function">Item <span class="title">extract</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 其他有关于获取顶端、获取count操作就不列举了</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="添加元素-O-logN"><a href="#添加元素-O-logN" class="headerlink" title="添加元素 O(logN)"></a>添加元素 O(logN)</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">MaxHeap::insert</span><span class="params">(Item item)</span></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>( count + <span class="number">1</span> &lt;= capacity );</span><br><span class="line">    data[++count] = item;</span><br><span class="line">    <span class="comment">//通过shiftup保持堆的定义</span></span><br><span class="line">    <span class="built_in">shiftUp</span>(count);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//将位置k的元素尝试向根移动，不断替换比自己小的父亲节点</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MaxHeap::shiftUp</span><span class="params">(<span class="type">int</span> k)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>( k &gt; <span class="number">1</span> &amp;&amp; data[k/<span class="number">2</span>] &lt; data[k] )&#123;</span><br><span class="line">        <span class="built_in">swap</span>( data[k/<span class="number">2</span>], data[k] );</span><br><span class="line">        <span class="comment">//交换过之后考虑当前节点，就是上次节点交换后的位置</span></span><br><span class="line">        k /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="弹出顶端元素-O-logN"><a href="#弹出顶端元素-O-logN" class="headerlink" title="弹出顶端元素 O(logN)"></a>弹出顶端元素 O(logN)</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Item MaxHeap::  <span class="built_in">extract</span>()&#123;</span><br><span class="line">    <span class="built_in">assert</span>( count &gt; <span class="number">0</span> );</span><br><span class="line">    Item ret = data[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">//最后一个元素和第一个元素进行互换</span></span><br><span class="line">    <span class="built_in">swap</span>( data[<span class="number">1</span>] , data[count] );</span><br><span class="line">    count --;</span><br><span class="line">    <span class="built_in">shiftDown</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从根向下不断替换比自己大的 且 最大的子节点</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">shiftDown</span><span class="params">(<span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//是否有左孩子存在孩子的判定</span></span><br><span class="line">    <span class="keyword">while</span>( <span class="number">2</span>*k &lt;= count )&#123;</span><br><span class="line">        <span class="type">int</span> j = <span class="number">2</span>*k; <span class="comment">// 在此轮循环中,data[k]和data[j]交换位置</span></span><br><span class="line">        <span class="comment">//有右孩子并且右孩子大于左孩子</span></span><br><span class="line">        <span class="keyword">if</span>( j+<span class="number">1</span> &lt;= count &amp;&amp; data[j+<span class="number">1</span>] &gt; data[j] )</span><br><span class="line">            <span class="comment">//因为右孩子更大，所以将j更新为j+1</span></span><br><span class="line">            j ++;</span><br><span class="line">        <span class="comment">// data[j] 是 data[2*k]和data[2*k+1]中的最大值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>( data[k] &gt;= data[j] ) <span class="keyword">break</span>;</span><br><span class="line">        <span class="built_in">swap</span>( data[k] , data[j] );</span><br><span class="line">        <span class="comment">//新的变到了j的位置</span></span><br><span class="line">        k = j;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>



<h4 id="初始化-O-n"><a href="#初始化-O-n" class="headerlink" title="初始化 O(n)"></a>初始化 O(n)</h4><p>对于所有非叶子节点做shiftDown</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">MaxHeap::<span class="built_in">MaxHeap</span>(Item arr[], <span class="type">int</span> n)&#123;</span><br><span class="line">       data = <span class="keyword">new</span> Item[n+<span class="number">1</span>];</span><br><span class="line">       capacity = n;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span>( <span class="type">int</span> i = <span class="number">0</span> ; i &lt; n ; i ++ )</span><br><span class="line">           data[i+<span class="number">1</span>] = arr[i]; <span class="comment">//下标从1开始</span></span><br><span class="line">       count = n;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span>( <span class="type">int</span> i = count/<span class="number">2</span> ; i &gt;= <span class="number">1</span> ; i -- )</span><br><span class="line">           <span class="built_in">shiftDown</span>(i);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>误区： 不要以为N&#x2F;2次shiftDown复杂度就是O(NlogN)，因为不同层的运算次数不一样，可以做如下证明</li>
<li>复杂度证明：总高度为$h&#x3D;logN$，第x层元素的计算量为$2^x * (h-x)$<br>$S &#x3D; 2^{h-1} × 1 + 2^{h-2} × 2 + …… + 1 × (h-1) &#x3D; 2^h × 1 - h +1 &#x3D; N -logN +1 &#x3D; O(N)$</li>
</ul>
<h3 id="如何排序"><a href="#如何排序" class="headerlink" title="如何排序"></a>如何排序</h3><p>就是初步初始化后，然后不断extract。第i次extract的数就是第i大的数，就完成了排序。</p>
<p>其实堆常见的不是用在排序，更多是用在动态维护最值的场合，作为优先队列，比如多个有序数列合并(多路归并)、dijstra的堆优化。</p>
<h3 id="复杂度-2"><a href="#复杂度-2" class="headerlink" title="复杂度"></a>复杂度</h3><ul>
<li><p>最好、最差、平均： O(NlogN) 即与快排相比，堆排<strong>没有最好最坏情况</strong>，每个情况都差不多。</p>
</li>
<li><p>为什么一般比快排慢： 几乎没有最好情况。在堆排序的时候，每次extract总是将堆顶元素移除，然后将最后的元素放到堆顶，再让其自我调整。这两个元素往往差距很大，所以每轮的调整次数几乎每次都就近于高度。</p>
</li>
</ul>
<h2 id="归并排序-Merge-Sort"><a href="#归并排序-Merge-Sort" class="headerlink" title="归并排序 Merge Sort"></a>归并排序 Merge Sort</h2><p>这个思路是最简单的，是将排序分而治之的最直观算法，就是每次划分时保证左右子树个数接近甚至相等。 常用的 2 路归并排序假设初始序列有 n 个元素，可以看成是 n 个长度为 1 的子序列，进行两两归并，可以得到 n &#x2F; 2 个长度为 2 或 1 的子序列；再两两归并，直到得到一个长度为 n 的有序序列为止。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>以下是便于理解的递归版本实现，每次将当前数组拆成两等分, 每一等分自己先完成排序，然后再通过merge操作将两个有序子序列成一个大的有序序列。<br>(在下面的代码中，end是无效索引，最后一个元素是A[end-1])</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">merge</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; A, <span class="type">int</span> start, <span class="type">int</span> mid, <span class="type">int</span> end)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> n1 = (mid - start);</span><br><span class="line">    <span class="type">int</span> n2 = (end - mid);</span><br><span class="line">    <span class="type">int</span> L[n1], R[n2];</span><br><span class="line"></span><br><span class="line">    <span class="built_in">memcpy</span>(L, &amp;A[start], <span class="built_in">sizeof</span>(<span class="type">int</span>) * n1);</span><br><span class="line">    <span class="built_in">memcpy</span>(R, &amp;A[mid], <span class="built_in">sizeof</span>(<span class="type">int</span>) * n2);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = start; k &lt; end; k++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (j &gt;= n2 || (i &lt; n1 &amp;&amp; L[i] &lt;= R[j]))</span><br><span class="line">            A[k] = L[i++];</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            A[k] = R[j++];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mergesort</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; A, <span class="type">int</span> start, <span class="type">int</span> end)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (start &lt; end<span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="type">int</span> mid = (start + end) / <span class="number">2</span>;</span><br><span class="line">        <span class="built_in">mergesort</span>(A, start, mid);</span><br><span class="line">        <span class="built_in">mergesort</span>(A, mid, end);</span><br><span class="line">        <span class="built_in">merge</span>(A, start, mid, end);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="复杂度-3"><a href="#复杂度-3" class="headerlink" title="复杂度"></a>复杂度</h3><ul>
<li>最好、最差、平均： O(NlogN)</li>
<li>为什么一般比快排慢：需要额外的空间做<strong>数组复制</strong>，额外空间复杂度为O(N)</li>
</ul>
<h3 id="归并排序相关问题"><a href="#归并排序相关问题" class="headerlink" title="归并排序相关问题"></a>归并排序相关问题</h3><ul>
<li>题目小练<ul>
<li>逆序对个数统计 <a href="https://leetcode.com/problems/reverse-pairs/">LeetCode 493 Reverse Pairs</a></li>
</ul>
</li>
</ul>
<h2 id="非比较排序"><a href="#非比较排序" class="headerlink" title="非比较排序"></a>非比较排序</h2><p>不基于比较，与其说像排序，更不如说像统计。都是拿空间换时间的策略，只适合元素范围较小的场合。</p>
<h3 id="计数排序-Counting-Sort"><a href="#计数排序-Counting-Sort" class="headerlink" title="计数排序 Counting Sort"></a>计数排序 Counting Sort</h3><p>统计每个元素出现个数，然后按元素从小到大遍历输出。<br>复杂度O(N+M), M是元素大小的范围(MAX-MIN)</p>
<h3 id="桶排序-Bucket-Sort"><a href="#桶排序-Bucket-Sort" class="headerlink" title="桶排序 Bucket Sort"></a>桶排序 Bucket Sort</h3><p>是计数排序的变种，把计数排序中相邻的m个”小桶”放到一个”大桶”中，在分完桶后，对每个桶进行排序（一般用快排），然后合并成最后的结果。</p>
<ul>
<li>平均时间复杂度为线性的O(N+C), C为桶内快排的时间复杂度。 </li>
<li>如果刚好所有数据到一个桶里了，就是最差情况</li>
</ul>
<h3 id="基数排序-Radix-Sort"><a href="#基数排序-Radix-Sort" class="headerlink" title="基数排序 Radix Sort"></a>基数排序 Radix Sort</h3><p>可以理解多级桶排序，基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。<br>过程：</p>
<ol>
<li>取得数组中的最大数，并取得位数；</li>
<li>arr为原始数组，从最低位开始取每个位组成radix数组；</li>
<li>对radix进行计数排序（利用计数排序适用于小范围数的特点）；</li>
</ol>
<p>演示：<br><img src="/2016/08/22/Programming/Algorithm/sort/radix_sort.gif" loading="lazy"></p>
<h2 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h2><ul>
<li><p>定义： 待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]&#x3D;r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的；否则称为不稳定的。 </p>
</li>
<li><p>稳定算法：<br>基数（桶）、冒泡、插入、归并</p>
</li>
<li><p>不稳定算法<br>快速、堆、希尔、选择</p>
</li>
</ul>
<h2 id="证明基于比较的排序复杂度不可能低于O-NlogN"><a href="#证明基于比较的排序复杂度不可能低于O-NlogN" class="headerlink" title="证明基于比较的排序复杂度不可能低于O(NlogN)"></a>证明基于比较的排序复杂度不可能低于O(NlogN)</h2><p>所有基于<strong>比较</strong>的排序算法，都可以抽象成一个决策数模型，为一个完全二叉树。<br><img src="/2016/08/22/Programming/Algorithm/sort/sort_prove.png" loading="lazy"><br>N个数的原始排列情况一共$n!$种情况，那么这棵能区分这$n!$种情况的决策树深度<br>$$ h \geq log(n!)$$<br>由于斯特林公式<br>$$n! \approx \sqrt{2\pi n}, \left(\frac{n}{e}\right)^{n} $$<br>最后得出<br>$$h \geq log(\sqrt{2\pi n}, \left(\frac{n}{e}\right)^{n} ) &#x3D; log(\sqrt{2\pi n}) + nlog(n&#x2F;e) &#x3D; O(nlogn)$$</p>
<h2 id="最后小小的总结"><a href="#最后小小的总结" class="headerlink" title="最后小小的总结"></a>最后小小的总结</h2><!-- ![](sort/summary.png) -->

<table>
<thead>
<tr>
<th>排序算法</th>
<th align="center">空间复杂度(平均)</th>
<th align="center">时间复杂度（平均）</th>
<th align="center">时间复杂度（最坏）</th>
<th align="center">时间复杂度（最好）</th>
<th align="center">是否稳定</th>
</tr>
</thead>
<tbody><tr>
<td>冒泡</td>
<td align="center">$O(1)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n)$</td>
<td align="center">稳定</td>
</tr>
<tr>
<td>选择</td>
<td align="center">$O(1)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">不稳定</td>
</tr>
<tr>
<td>(直接)插入</td>
<td align="center">$O(1)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">稳定</td>
</tr>
<tr>
<td>希尔</td>
<td align="center">$O(1)$</td>
<td align="center">$O(n^{1.3})$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n)$</td>
<td align="center">不稳定</td>
</tr>
<tr>
<td>快速</td>
<td align="center">$O(logn)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">不稳定</td>
</tr>
<tr>
<td>归并</td>
<td align="center">$O(n)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">稳定</td>
</tr>
<tr>
<td>堆</td>
<td align="center">$O(1)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">$O(nlogn)$</td>
<td align="center">不稳定</td>
</tr>
<tr>
<td>计数</td>
<td align="center">$O(n+k)$</td>
<td align="center">$O(n+k)$</td>
<td align="center">$O(n+k)$</td>
<td align="center">$O(n+k)$</td>
<td align="center">稳定</td>
</tr>
<tr>
<td>桶</td>
<td align="center">$O(n+k)$</td>
<td align="center">$O(n+k)$</td>
<td align="center">$O(n^2)$</td>
<td align="center">$O(n)$</td>
<td align="center">稳定</td>
</tr>
<tr>
<td>基数</td>
<td align="center">$O(n+k)$</td>
<td align="center">$O(n*k)$</td>
<td align="center">$O(n*k)$</td>
<td align="center">$O(n*k)$</td>
<td align="center">稳定</td>
</tr>
</tbody></table>
<p>对于非比较排序，空间复杂度存在争议，因为有些排序在桶内会额外存储原值，有些不存。该表中空间复杂度是针对存原值的。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://www.codeproject.com/Articles/1023591/Cplusplus-Implementations-of-Quicksort-Methods-for">C++ Implementations of Quicksort Methods for Sorting Arrays with Lots of Duplicates</a><br><a href="http://www.codeceo.com/article/10-sort-algorithm-interview.html#0-tsina-1-10490-397232819ff9a47a7b7e80a40613cfe1">面试10大排序算法总结</a><br><a href="https://zhuanlan.zhihu.com/p/34421623">九种排序算法的可视化及比较</a><br><a href="https://www.cnblogs.com/chengxiao/p/6104371.html">图解排序算法(二)之希尔排序</a><br><a href="https://www.kancloud.cn/digest/pieces-algorithm/163612">快速排序的几种常见实现及其性能对比 - 点滴算法</a><br><a href="https://cloud.tencent.com/developer/article/1114673">算法与数据结构（四）堆排序：优先队列实现 - 腾讯云社区</a><br><a href="https://www.cnblogs.com/onepixel/articles/7674659.html">十大经典排序算法（动图演示）</a></p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>从KMP到AC自动机</title>
    <url>/2018/12/12/Programming/Algorithm/string_find/</url>
    <content><![CDATA[<h2 id="为什么要KMP"><a href="#为什么要KMP" class="headerlink" title="为什么要KMP"></a>为什么要KMP</h2><p>本文以一个非常常见的字符串匹配问题讲述字符串匹配的几种理解角度。即在字符串<code>S</code>(长为<code>N</code>)中找到模式串<code>T</code>(长为<code>M</code>)出现的第一个位置。</p>
<p>首先字符串匹配查找的方法大家都能想到一个暴力解法,复杂度是O(NM)，显然是太慢了的。希望能找到一个O(M+N)的方法，那就是KMP算法</p>
<p>本质是利用子串内部的信息加快检索。</p>
<ul>
<li>比如当如下不匹配发生时：<br><img src="/2018/12/12/Programming/Algorithm/string_find/demo1.png" loading="lazy"></li>
<li>暴力枚举法是让T串移动1格，重新枚举<br><img src="/2018/12/12/Programming/Algorithm/string_find/demo2.png" loading="lazy"></li>
<li>而KMP则是移动4格，因为ABCDAB后缀和前缀有两个相同<br><img src="/2018/12/12/Programming/Algorithm/string_find/demo3.png" loading="lazy"></li>
</ul>
<h2 id="next数组法"><a href="#next数组法" class="headerlink" title="next数组法"></a>next数组法</h2><h3 id="跳转数组定义"><a href="#跳转数组定义" class="headerlink" title="跳转数组定义"></a>跳转数组定义</h3><p>KMP算法需要首先设置一个跳转数组next，其<code>next[i]</code>代表以<code>[0, j-1]</code>区间后缀与前缀最大相同长度。<br>其本质是 <code>next</code>整体[0, j-1]是后缀与前缀最大相同长度整体向右平移一位，然后首位补-1 </p>
<table>
<thead>
<tr>
<th align="center">i</th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
</tr>
</thead>
<tbody><tr>
<td align="center">模式串</td>
<td align="center">A</td>
<td align="center">B</td>
<td align="center">C</td>
<td align="center">D</td>
<td align="center">A</td>
<td align="center">B</td>
<td align="center">D</td>
</tr>
<tr>
<td align="center">next</td>
<td align="center">-1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2</td>
</tr>
</tbody></table>
<h3 id="根据跳转数组的KMP"><a href="#根据跳转数组的KMP" class="headerlink" title="根据跳转数组的KMP"></a>根据跳转数组的KMP</h3><p>KMP算法是一种母串指针不倒退，而去调整模式串位置的检索方法。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 在 S 中找到 P 第一次出现的位置 */</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">KMP</span><span class="params">(string S, string P, <span class="type">int</span> next[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">GetNext</span>(P, next);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>;  <span class="comment">// S 的下标</span></span><br><span class="line">    <span class="type">int</span> j = <span class="number">0</span>;  <span class="comment">// P 的下标，表示成功匹配j个字符</span></span><br><span class="line">    <span class="type">int</span> s_len = S.<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">int</span> p_len = P.<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (i &lt; s_len &amp;&amp; j &lt; p_len)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (j == <span class="number">-1</span> || S[i] == P[j])  <span class="comment">// P 的第一个字符不匹配或 S[i] == P[j]</span></span><br><span class="line">        &#123;</span><br><span class="line">            i++;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            j = next[j];  <span class="comment">// 当前字符匹配失败，进行跳转</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (j == p_len)  <span class="comment">// 匹配成功</span></span><br><span class="line">        <span class="keyword">return</span> i - j;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">//未找到</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="跳转数组实现"><a href="#跳转数组实现" class="headerlink" title="跳转数组实现"></a>跳转数组实现</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* P 为模式串，下标从 0 开始 */</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">GetNext</span><span class="params">(string P, <span class="type">int</span> next[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> p_len = P.<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>;   <span class="comment">// 后缀末尾index</span></span><br><span class="line">    <span class="type">int</span> j = <span class="number">-1</span>;  <span class="comment">// 前缀末尾index</span></span><br><span class="line">    next[<span class="number">0</span>] = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (i &lt; p_len - <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (j == <span class="number">-1</span> || P[i] == P[j])  <span class="comment">//匹配</span></span><br><span class="line">        &#123;</span><br><span class="line">            i++;</span><br><span class="line">            j++;</span><br><span class="line">            next[i] = j;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            j = next[j];   <span class="comment">//当前缀不匹配时，前缀退回到上一个长度</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="next优化"><a href="#next优化" class="headerlink" title="next优化"></a>next优化</h3><p>以上next初始化仍旧存在无用功。比如一下模式串，匹配到最后一个B不同时，未优化的做法是回退到<code>next[5]=1</code>，也就是第一个B的位置，而实际上B已经比较过了，这个B 100%是不符合的，肯定在KMP里调用<code>j=next[j]</code>，所以我们干脆优化数组，如果发现不符合，提前在next数组就初始化好结果，降低KMP运行过程中<code>j=next[j]</code>的调用次数。</p>
<table>
<thead>
<tr>
<th align="center">i</th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
</tr>
</thead>
<tbody><tr>
<td align="center">模式串</td>
<td align="center">A</td>
<td align="center">B</td>
<td align="center">C</td>
<td align="center">D</td>
<td align="center">A</td>
<td align="center">B</td>
<td align="center">D</td>
</tr>
<tr>
<td align="center">next(未优化)</td>
<td align="center">-1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center">next(优化)</td>
<td align="center">-1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">-1</td>
<td align="center">0</td>
<td align="center">2</td>
</tr>
</tbody></table>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* P 为模式串，下标从 0 开始 */</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">GetNext</span><span class="params">(string P, <span class="type">int</span> next[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> p_len = P.<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>;   <span class="comment">// 后缀末尾index</span></span><br><span class="line">    <span class="type">int</span> j = <span class="number">-1</span>;  <span class="comment">// 前缀末尾index</span></span><br><span class="line">    next[<span class="number">0</span>] = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; p_len - <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (j == <span class="number">-1</span> || P[i] == P[j])</span><br><span class="line">        &#123;</span><br><span class="line">            i++;</span><br><span class="line">            j++;</span><br><span class="line">            <span class="keyword">if</span> (P[i] != P[j])</span><br><span class="line">                next[i] = j;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                next[i] = next[j];  <span class="comment">// 既然相同就继续往前找真前缀</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            j = next[j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="状态机DFA理解"><a href="#状态机DFA理解" class="headerlink" title="状态机DFA理解"></a>状态机DFA理解</h2><p>如果难以理解跳转数组，其实还有一种容易理解的实现是借助有限状态机的思想，模式串构成了一个有限状态自动机，共有len(pattern) + 1个状态。<br>其本质是用DFA去实现前缀指针。<br>状态的转移是KMP算法可以达到O(len(text))的时间复杂度的关键。如下<br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_1.png" loading="lazy"></p>
<p>穷举模式pat的所有可能情况，将这些情况用状态图表示。其中X记录匹配失败时重启的索引位置。<br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_constr2.png" loading="lazy"><br>其代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> R;       <span class="comment">// the radix</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span>[][] dfa;       <span class="comment">// the KMP automoton</span></span><br><span class="line"><span class="keyword">private</span> String pat;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">build_DFA</span><span class="params">(String pat)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.R = <span class="number">256</span>;   <span class="comment">//假设字典大小为256</span></span><br><span class="line">    <span class="keyword">this</span>.pat = pat;</span><br><span class="line">    <span class="comment">//构造pat对应的dfa</span></span><br><span class="line">    <span class="type">int</span> M = pat.<span class="built_in">length</span>();</span><br><span class="line">    dfa = <span class="keyword">new</span> <span class="type">int</span>[R][M];</span><br><span class="line">    dfa[pat.<span class="built_in">charAt</span>(<span class="number">0</span>)][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> X = <span class="number">0</span>, j = <span class="number">1</span>; j &lt; M; j++) &#123;  <span class="comment">//X记录匹配失败时的索引位置,j指向pat</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; R; c++) &#123;   <span class="comment">//对于匹配失败的情况，直接复制重启状态</span></span><br><span class="line">            dfa[c][j] = dfa[c][X];</span><br><span class="line">        &#125;</span><br><span class="line">        dfa[pat.<span class="built_in">charAt</span>(j)][j] = j + <span class="number">1</span>;           <span class="comment">//匹配成功的指向下一个状态</span></span><br><span class="line">        X = dfa[pat.<span class="built_in">charAt</span>(j)][X]; <span class="comment">//更新重启位置X</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="type">int</span> <span class="title">search</span><span class="params">(String txt)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> M = pat.<span class="built_in">length</span>();</span><br><span class="line">    <span class="type">int</span> N = txt.<span class="built_in">length</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i, j;  <span class="comment">//i指向txt，j指向pat</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; N &amp;&amp; j &lt; M; i++) &#123;</span><br><span class="line">        j = dfa[txt.<span class="built_in">charAt</span>(i)][j];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (j == M) <span class="keyword">return</span> i - M;   <span class="comment">//匹配</span></span><br><span class="line">    <span class="keyword">return</span> N;                   <span class="comment">//不匹配</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其迭代过程如下：<br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_ITER.png" loading="lazy"><br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_iter2.png" loading="lazy"><br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_ITER3.png" loading="lazy"><br><img src="/2018/12/12/Programming/Algorithm/string_find/dfa_iter4.png" loading="lazy"><br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_ITER5.png" loading="lazy"><br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_ITER6.png" loading="lazy"></p>
<h2 id="AC自动机：多个子串匹配"><a href="#AC自动机：多个子串匹配" class="headerlink" title="AC自动机：多个子串匹配"></a>AC自动机：多个子串匹配</h2><p>其实对于这种AC自动机的理解一点也不喜欢。</p>
<p>针对一个问题：给一个很长很长的母串 长度为n，然后给m个小的模式串。求这m个模式串里边有多少个是母串的字串。<br>该问题在搜索引擎内的词频统计、敏感词排除等场景非常常见。</p>
<h3 id="在字典树-trie树-上检索"><a href="#在字典树-trie树-上检索" class="headerlink" title="在字典树(trie树)上检索"></a>在字典树(trie树)上检索</h3><p>AC自动机的基础是Trie树。和Trie树不同的是，树中的每个结点除了有指向孩子的指针（或者说引用），还有一个fail指针，它表示输入的字符与当前结点的所有孩子结点都不匹配时(注意，不是和该结点本身不匹配)，自动机的状态应转移到的状态（或者说应该转移到的结点）。fail指针的功能可以类比于KMP算法中next数组的功能。</p>
<p>我们现在来看一个用目标字符串集合{abd,abdk, abchijn, chnit, ijabdf, ijaij}构造出来的AC自动机<br><img src="/2018/12/12/Programming/Algorithm/string_find/trie.png" loading="lazy"><br>检索过程如下（设文本串abchnijabdfk)：<br><img src="/2018/12/12/Programming/Algorithm/string_find/trie_search.png" loading="lazy"><br>详见代码<code>search(char *st)</code></p>
<h3 id="构造AC自动机方法"><a href="#构造AC自动机方法" class="headerlink" title="构造AC自动机方法"></a>构造AC自动机方法</h3><h4 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h4><ol>
<li>先构造字典树： 将所有的目标字符串插入到Trie树中，用简单的数组法存储</li>
<li>然后通过广度优先遍历为每个结点的所有孩子节点的fail指针找到正确的指向。<br>  每个结点fail指向的解决顺序是按照广度优先遍历的顺序完成的，或者说层序遍历的顺序进行的，也就是说我们是在解决当前结点的孩子结点fail的指向时，当前结点的fail指针一定已指向了正确的位置。详情见<code>buildDFA()</code>函数</li>
</ol>
<h4 id="过程图示"><a href="#过程图示" class="headerlink" title="过程图示"></a>过程图示</h4><ul>
<li>完成了3层构造，<br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_build_demo.png" loading="lazy"></li>
<li>完成了4层构造<br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_BUILD_4.png" loading="lazy"></li>
<li>完成了5层构造<br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_BUILD_5.png" loading="lazy"></li>
<li>完成了6层构造<br><img src="/2018/12/12/Programming/Algorithm/string_find/DFA_BUILD%E2%80%94%E2%80%946.png" loading="lazy"></li>
</ul>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>代码并非直接copy他人博客内的代码，我根据可读性做了一些修改。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;deque&gt;</span></span></span><br><span class="line"><span class="comment">//#include &lt;queue&gt;</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Node</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Node *fail;</span><br><span class="line">    Node *next[<span class="number">26</span>]; <span class="comment">//only lower case</span></span><br><span class="line">    <span class="type">int</span> cnt; <span class="comment">// 以该node为结尾的单词有几个</span></span><br><span class="line">    <span class="type">int</span> depth;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Node</span>(Node *_fail = <span class="literal">nullptr</span>, <span class="type">int</span> _depth = <span class="number">0</span>) : <span class="built_in">fail</span>(_fail), <span class="built_in">cnt</span>(<span class="number">0</span>), <span class="built_in">depth</span>(_depth)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">memset</span>(next, <span class="number">0</span>, <span class="built_in">sizeof</span>(next));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~<span class="built_in">Node</span>()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">26</span>; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (next[i] != <span class="literal">nullptr</span>)</span><br><span class="line">                <span class="keyword">delete</span> next[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Node* q[10000000];</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AC_automaton</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Node *root;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">AC_automaton</span>() : <span class="built_in">root</span>(<span class="keyword">new</span> <span class="built_in">Node</span>(<span class="literal">nullptr</span>)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">char</span> *st)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        Node *p = root;</span><br><span class="line">        <span class="type">int</span> len = <span class="built_in">strlen</span>(st);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; len; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> c = st[i] - <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;next[c] == <span class="literal">nullptr</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                p-&gt;next[c] = <span class="keyword">new</span> <span class="built_in">Node</span>(root, i + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            p = p-&gt;next[c];</span><br><span class="line">        &#125;</span><br><span class="line">        p-&gt;cnt++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">buildDFA</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        deque&lt;Node *&gt; q;</span><br><span class="line">        q.<span class="built_in">push_back</span>(root);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (!q.<span class="built_in">empty</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//判断当前这个节点和其fail节点是否存在相同儿子，如果存在</span></span><br><span class="line">            Node *curr = q.<span class="built_in">front</span>();</span><br><span class="line">            Node *fail = <span class="literal">nullptr</span>;</span><br><span class="line">            q.<span class="built_in">pop_front</span>();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">26</span>; ++i)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span> (curr-&gt;next[i] != <span class="literal">nullptr</span>)</span><br><span class="line">                &#123;  <span class="comment">//存在相同儿子</span></span><br><span class="line">                    <span class="comment">// 更新从根到当前节点儿子curr-&gt;next[i]的fail，</span></span><br><span class="line">                    q.<span class="built_in">push_back</span>(curr-&gt;next[i]);</span><br><span class="line">                    <span class="keyword">for</span> (Node *fail = curr-&gt;fail; fail != <span class="literal">nullptr</span>; fail = fail-&gt;fail) <span class="comment">// 遍历所有可能的前缀</span></span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="keyword">if</span> (fail-&gt;next[i] != <span class="literal">nullptr</span>)</span><br><span class="line">                        &#123; <span class="comment">//某个前缀相同</span></span><br><span class="line">                            curr-&gt;next[i]-&gt;fail = fail-&gt;next[i];</span><br><span class="line">                            <span class="keyword">break</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 统计所有st内模式串匹配的个数，以及每个模式串第一次匹配的位置</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">search</span><span class="params">(<span class="type">char</span> *st)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="type">int</span> cnt = <span class="number">0</span>;</span><br><span class="line">        Node *p = root;</span><br><span class="line">        <span class="type">int</span> len = <span class="built_in">strlen</span>(st);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; len; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> t = st[i] - <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">            <span class="comment">// 不能再往下时转移到fail节点</span></span><br><span class="line">            <span class="keyword">while</span> (p-&gt;next[t] == <span class="literal">nullptr</span> &amp;&amp; p != root)</span><br><span class="line">            &#123;</span><br><span class="line">                p = p-&gt;fail;</span><br><span class="line">            &#125;</span><br><span class="line">            p = p-&gt;next[t];</span><br><span class="line">            <span class="keyword">if</span> (p == <span class="literal">nullptr</span>) p = root;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//遍历以当前子树后缀内是否等同其他模式串</span></span><br><span class="line">            <span class="keyword">for</span> (Node *tmp = p; tmp != root &amp;&amp; tmp-&gt;cnt != <span class="number">-1</span>; tmp = tmp-&gt;fail)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span> (tmp-&gt;cnt &gt; <span class="number">0</span>) <span class="comment">// 匹配了某个模式串</span></span><br><span class="line">                &#123;</span><br><span class="line">                    cnt += tmp-&gt;cnt;</span><br><span class="line">                    <span class="comment">// 输出第一次匹配的位置</span></span><br><span class="line">                    cout &lt;&lt; <span class="string">&quot;start:&quot;</span> &lt;&lt; (i - tmp-&gt;depth + <span class="number">1</span>) &lt;&lt; <span class="string">&quot;\t\tlen:&quot;</span> &lt;&lt; tmp-&gt;depth + <span class="number">1</span> &lt;&lt; <span class="string">&quot;\t\tcount:&quot;</span> &lt;&lt; tmp-&gt;cnt</span><br><span class="line">                         &lt;&lt; endl;</span><br><span class="line">                &#125;</span><br><span class="line">                tmp-&gt;cnt = <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> cnt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; AC;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    AC.<span class="built_in">insert</span>(<span class="string">&quot;ababacd&quot;</span>);</span><br><span class="line">    AC.<span class="built_in">insert</span>(<span class="string">&quot;ababc&quot;</span>);</span><br><span class="line">    AC.<span class="built_in">insert</span>(<span class="string">&quot;ababc&quot;</span>);</span><br><span class="line">    AC.<span class="built_in">insert</span>(<span class="string">&quot;babc&quot;</span>);</span><br><span class="line">    AC.<span class="built_in">insert</span>(<span class="string">&quot;abab&quot;</span>);</span><br><span class="line">    AC.<span class="built_in">buildDFA</span>();</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; AC.<span class="built_in">search</span>(<span class="string">&quot;ababacdababcababacd&quot;</span>) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="用AC自动机思想回看next数组"><a href="#用AC自动机思想回看next数组" class="headerlink" title="用AC自动机思想回看next数组"></a>用AC自动机思想回看next数组</h3><p>对于AC自动机只有单条pattern的特殊情况，其实next数组 等同于 树上一条链的所有fail指针的数组。<br>我也按照AC自动机的理解思路写了一版代码，只不过为了节省空间，去掉了字典树。看上去比next数组版本复杂，但实质是一样的。<br>对应[leetcode &#96;8. Implement strStr()](<a href="https://leetcode.com/problems/implement-strstr/">https://leetcode.com/problems/implement-strstr/</a>)</p>
<p>代码中fails数组代表不同状态下的fail指针指向，0表示root状态</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"> <span class="type">int</span>* fails = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">strStr</span><span class="params">(string haystack, string needle)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = needle.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">if</span> (n ==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//build DFA</span></span><br><span class="line">    fails = <span class="keyword">new</span> <span class="type">int</span>[needle.<span class="built_in">size</span>()+<span class="number">1</span>];  <span class="comment">//index = state</span></span><br><span class="line">    <span class="built_in">memset</span>(fails, <span class="number">0</span>, <span class="built_in">sizeof</span>(<span class="type">int</span>) * (needle.<span class="built_in">size</span>()+<span class="number">1</span>));</span><br><span class="line">    </span><br><span class="line">    fails[<span class="number">0</span>] = <span class="number">-1</span>; <span class="comment">//0 = root(start) state, -1 = null state</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> curr = i;</span><br><span class="line">        <span class="type">int</span> curr_next = i+<span class="number">1</span>;</span><br><span class="line">        <span class="type">int</span> fail = fails[i];</span><br><span class="line">        <span class="type">int</span> fail_next = fails[i]+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (fail != <span class="number">-1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> ( needle[fail] == needle[curr])</span><br><span class="line">            &#123;</span><br><span class="line">                fails[curr_next] = fail_next;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            fail = fails[fail];</span><br><span class="line">            fail_next = fail+<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// find</span></span><br><span class="line">    <span class="type">int</span> state = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i =<span class="number">0</span>; i &lt; haystack.<span class="built_in">size</span>(); i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (haystack[i] == needle[state])</span><br><span class="line">        &#123;</span><br><span class="line">            state ++;</span><br><span class="line">            <span class="keyword">if</span> (state == n)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">delete</span> [] fails;</span><br><span class="line">                <span class="keyword">return</span> i - n + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            state = fails[state];</span><br><span class="line">            <span class="keyword">while</span> (state != <span class="number">-1</span> &amp;&amp; haystack[i] != needle[state] )</span><br><span class="line">            &#123;</span><br><span class="line">                state = fails[state];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (state == <span class="number">-1</span>)</span><br><span class="line">                state = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">else</span> state ++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">delete</span> [] fails;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我个人还是认为对于KMP AC自动机版本最容易理解，状态机其次，最难的是直接去理解网上广为流传的KMP算法。我只是做个整理和写点自己的理解，其实引用内的博客已经写得详细了。</p>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p><a href="https://segmentfault.com/a/1190000008575379">KMP算法（1）：如何理解KMP</a><br><a href="http://wiki.jikexueyuan.com/project/kmp-algorithm/define.html">KMP 算法 v_JULY_v</a><br><a href="KMP%E5%AD%90%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95">KMP子字符串查找算法</a><br><a href="https://www.cnblogs.com/nullzx/p/7499397.html">多模字符串匹配算法之AC自动机—原理与实现</a></p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>C/C++ Concurrency and Parallelism</title>
    <url>/2018/04/20/Programming/C,C++/CPP_multithreading/</url>
    <content><![CDATA[<h2 id="Concurrency-and-Parallelism"><a href="#Concurrency-and-Parallelism" class="headerlink" title="Concurrency and Parallelism"></a>Concurrency and Parallelism</h2><p>Parallelism ∈ Concurrency<br>Concurrency: two or more actions(workflows) exists at the same time<br>Parallelism: two or more actions(workflows) is running at the same time</p>
<h2 id="Why-Multithreading"><a href="#Why-Multithreading" class="headerlink" title="Why Multithreading?"></a>Why Multithreading?</h2><ul>
<li>to achive Concurrency</li>
<li>maximize (hardware)resource usage</li>
</ul>
<h2 id="Process-vs-Thread-vs-Coroutine"><a href="#Process-vs-Thread-vs-Coroutine" class="headerlink" title="Process vs Thread vs Coroutine"></a>Process vs Thread vs Coroutine</h2><ul>
<li>Process:<ul>
<li>is a program</li>
<li>is a unit for resource distribution</li>
<li>process has at least one thread, each process has isolated resources, such as address space. </li>
<li>heavyWeight, it takes more to create a process<!-- - TODO what --></li>
</ul>
</li>
<li>Thread:<ul>
<li>is a workflow, a subset of process</li>
<li>is a unit for schedule and program executing. </li>
<li>threads within a process share the same fate(false) and resources: memory(address space, stack), file descriptors, and other process related attributes.</li>
<li>unique resources: stack, stack &amp; stack pointer, program counter(<code>%rip</code>: the address of the next instruction)</li>
</ul>
</li>
<li>Coroutine(fiber, lightweight thread)<ul>
<li>used for asynchronous IO or generator</li>
<li><strong>a context switch technique in user mode</strong><!-- - TODO 只需要存rip吗--></li>
</ul>
</li>
</ul>
<!-- ### state
- process
-  -->
<h3 id="Kernel-Thread-vs-Kernel-level-thread-LWP-vs-User-level-thread"><a href="#Kernel-Thread-vs-Kernel-level-thread-LWP-vs-User-level-thread" class="headerlink" title="Kernel Thread vs Kernel-level thread(LWP) vs User-level thread"></a>Kernel Thread vs Kernel-level thread(LWP) vs User-level thread</h3><ul>
<li>kernel thread <ul>
<li>only run on kernel</li>
<li>used for asynchronous operation(IO)</li>
</ul>
</li>
<li>kernel-level thread (LWP 轻量进程, 或者叫内核支持的线程)<ul>
<li>created by <code>clone()</code> systemcall</li>
</ul>
</li>
</ul>
<p><img src="/2018/04/20/Programming/C,C++/CPP_multithreading/kernel_thread.png" loading="lazy"></p>
<ul>
<li>user-level thread<ul>
<li>manage thread (creation,sechduling,destory) under user mode</li>
</ul>
</li>
</ul>
<p><img src="/2018/04/20/Programming/C,C++/CPP_multithreading/user-level-thread.png" loading="lazy"></p>
<h3 id="Context-Switch"><a href="#Context-Switch" class="headerlink" title="Context Switch"></a>Context Switch</h3><ul>
<li>process switch   <ul>
<li>the memory address space: memory addresses, mappings, page tables, and kernel resources, TLB and even L1 cache(some ARM processor)</li>
<li>processor state</li>
</ul>
</li>
<li>thread switch<ul>
<li>processor state (such as the program counter and register contents) is generally very efficient.</li>
</ul>
</li>
</ul>
<h2 id="Linux-Process-Communication"><a href="#Linux-Process-Communication" class="headerlink" title="Linux Process Communication"></a>Linux Process Communication</h2><ol>
<li>pipe<!-- TODO --></li>
<li>Semophore</li>
<li>Signal</li>
<li>Message Queue</li>
<li>Share memory</li>
<li>Socket, could cross-machine</li>
</ol>
<h2 id="Mutex-vs-Condition-Variable-vs-semaphore-vs-CAS"><a href="#Mutex-vs-Condition-Variable-vs-semaphore-vs-CAS" class="headerlink" title="Mutex vs Condition Variable vs semaphore vs CAS"></a>Mutex vs Condition Variable vs semaphore vs CAS</h2><ul>
<li><p>Mutual Lock</p>
<ul>
<li>used for resource protection, the operation of this resource must be serial</li>
<li>emphasize resource ownership, only owner can release the lock</li>
<li><strong>Mutex</strong> sleep-wait<ul>
<li>call <code>system_wait()</code> to start a context switch</li>
</ul>
</li>
<li><strong>Spin Lock</strong> busy-waiting<ul>
<li>take more user time to get lock as early as possible</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Semaphore</strong></p>
<ul>
<li>mainly used for schedule</li>
<li>stands for the number of resource</li>
<li>binary semaphore is simliar to mutex, but **<strong>semaphore does not record owner</strong></li>
<li>atomic operations: P(+1),V(-1)</li>
<li>e.g. record the number of items of producer-consumer pro</li>
</ul>
</li>
<li><p><strong>Conditional variable</strong>:</p>
<ul>
<li>optmize such situation: lock -&gt; check condition -&gt; unlock</li>
<li>to avoid frequent checking before condition satisfied</li>
<li>it requires another thread to wake up when locked</li>
</ul>
</li>
<li><p>other</p>
<ul>
<li><strong>critical section</strong><ul>
<li>a small code section only allows at most one thread access it at any moment. </li>
<li>is more efficient</li>
</ul>
</li>
<li>read-write lock <ul>
<li>for high frequency reading and low frequency writing</li>
</ul>
</li>
<li>recursive mutex<ul>
<li>thread could lock its own clocked mutex repeatedly</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="deadlock"><a href="#deadlock" class="headerlink" title="deadlock"></a>deadlock</h2><h3 id="necessary-condition"><a href="#necessary-condition" class="headerlink" title="necessary condition"></a>necessary condition</h3><ol>
<li>Mutual Exclusion (互斥):<br> at least one resource can be used by only one process at a time.</li>
<li>Hold and Wait (持有且等待):<br> There must exist a thread which holds some thread and waits for another resource held by some other thread.</li>
<li>No preemption (无法强制取得):<br>Once the resource has been allocated to the process, it can not be preempted(强制取得).</li>
<li>Circular wait (循环等待):<br>All the threads must wait for the resource in a cyclic manner where the last process waits for the resource held by the first thread.<br><img src="/2018/04/20/Programming/C,C++/CPP_multithreading/circular_wait.png" loading="lazy"></li>
</ol>
<h3 id="detect-deadlock"><a href="#detect-deadlock" class="headerlink" title="detect deadlock"></a>detect deadlock</h3><ul>
<li>gdb </li>
<li>kernel tracing: Valgrind, Lockdep, bcc(Linux BPF-based)</li>
</ul>
<h2 id="producer-comsumer-problem"><a href="#producer-comsumer-problem" class="headerlink" title="producer-comsumer problem"></a>producer-comsumer problem</h2><h3 id="mutex-cond-var-linked-list"><a href="#mutex-cond-var-linked-list" class="headerlink" title="mutex + cond var (linked list)"></a>mutex + cond var (linked list)</h3><ul>
<li>mutex + cond var<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">msg</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">msg</span> *next;</span><br><span class="line">        <span class="type">int</span> num;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">msg</span> *head;       <span class="comment">//queue header pointer</span></span><br><span class="line"><span class="type">pthread_cond_t</span> has_product = PTHREAD_COND_INITIALIZER;  <span class="comment">//cond var</span></span><br><span class="line"><span class="type">pthread_mutex_t</span> lock = PTHREAD_MUTEX_INITIALIZER;       <span class="comment">//mutex</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> *<span class="title">consumer</span><span class="params">(<span class="type">void</span> *p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">msg</span> *mp;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(;;) &#123;</span><br><span class="line">                <span class="built_in">pthread_mutex_lock</span>(&amp;lock);  <span class="comment">//互斥量保护条件变量</span></span><br><span class="line">                <span class="keyword">while</span>(head == <span class="literal">NULL</span>) &#123;</span><br><span class="line">                        <span class="built_in">pthread_cond_wait</span>(&amp;has_product, &amp;lock);</span><br><span class="line">                &#125;</span><br><span class="line">                mp = head;</span><br><span class="line">                head = mp-&gt;next;</span><br><span class="line">                <span class="built_in">pthread_mutex_unlock</span>(&amp;lock);</span><br><span class="line"></span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Consume %d\n&quot;</span>, mp-&gt;num);</span><br><span class="line">                <span class="built_in">free</span>(mp);</span><br><span class="line">                <span class="built_in">sleep</span>(<span class="built_in">rand</span>() % <span class="number">5</span>);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> *<span class="title">producer</span><span class="params">(<span class="type">void</span> *p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">msg</span> *mp;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(;;) &#123;</span><br><span class="line">                mp = <span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(<span class="keyword">struct</span> msg));</span><br><span class="line">                mp-&gt;num = <span class="built_in">rand</span>() % <span class="number">1000</span> + <span class="number">1</span>;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Produce %d\n&quot;</span>, mp-&gt;num);</span><br><span class="line"></span><br><span class="line">                <span class="built_in">pthread_mutex_lock</span>(&amp;lock);</span><br><span class="line">                mp-&gt;next = head;</span><br><span class="line">                head = mp;      <span class="comment">//条件变化，要加锁</span></span><br><span class="line">                <span class="built_in">pthread_mutex_unlock</span>(&amp;lock);</span><br><span class="line"></span><br><span class="line">                <span class="built_in">pthread_cond_signal</span>(&amp;has_product);</span><br><span class="line"></span><br><span class="line">                <span class="built_in">sleep</span>(<span class="built_in">rand</span>() % <span class="number">5</span>);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Semaphore-ring-queue"><a href="#Semaphore-ring-queue" class="headerlink" title="Semaphore (ring queue)"></a>Semaphore (ring queue)</h3><p>这里blank_number是空位的意思，product_number是队列中的元素个数</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> NUM 5</span></span><br><span class="line"><span class="type">int</span> queue[NUM]; <span class="comment">//环形队列</span></span><br><span class="line"><span class="type">sem_t</span> blank_number, product_number;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> *<span class="title">producer</span><span class="params">(<span class="type">void</span> *arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="type">int</span> p = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">                <span class="built_in">sem_wait</span>(&amp;blank_number);    </span><br><span class="line">                queue[p] = <span class="built_in">rand</span>() % <span class="number">1000</span> + <span class="number">1</span>;   <span class="comment">//生产者生产1到1000随机值</span></span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;produce %d\n&quot;</span>, queue[p]);</span><br><span class="line">                <span class="built_in">sem_post</span>(&amp;product_number);</span><br><span class="line">                p = (p+<span class="number">1</span>) % NUM;</span><br><span class="line">                <span class="built_in">sleep</span>(<span class="built_in">rand</span>() % <span class="number">5</span>);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> *<span class="title">consumer</span><span class="params">(<span class="type">void</span> *arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="type">int</span> c = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">                <span class="built_in">sem_wait</span>(&amp;product_number);</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;consume %d\n&quot;</span>, queue[c]);</span><br><span class="line">                queue[c] = <span class="number">0</span>;   <span class="comment">//消费者将队列值置为零</span></span><br><span class="line">                <span class="built_in">sem_post</span>(&amp;blank_number);</span><br><span class="line">                c = (c + <span class="number">1</span>) % NUM;</span><br><span class="line">                <span class="built_in">sleep</span>(<span class="built_in">rand</span>() % <span class="number">5</span>);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="type">pthread_t</span> pid, cid;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">srand</span>(<span class="built_in">time</span>(<span class="literal">NULL</span>));</span><br><span class="line">        <span class="built_in">sem_init</span>(&amp;blank_number, <span class="number">0</span>, NUM);</span><br><span class="line">        <span class="built_in">sem_init</span>(&amp;product_number, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">pthread_create</span>(&amp;pid, <span class="literal">NULL</span>, producer, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="built_in">pthread_create</span>(&amp;cid, <span class="literal">NULL</span>, consumer, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">pthread_join</span>(pid, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="built_in">pthread_join</span>(cid, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">sem_destroy</span>(&amp;blank_number);</span><br><span class="line">        <span class="built_in">sem_destroy</span>(&amp;product_number);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="CAS-lock-free"><a href="#CAS-lock-free" class="headerlink" title="CAS (lock free)"></a>CAS (lock free)</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">EnQueue</span>(x) <span class="comment">//进队列</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//init new record</span></span><br><span class="line">    q = <span class="keyword">new</span> <span class="built_in">record</span>();</span><br><span class="line">    q-&gt;value = x;</span><br><span class="line">    q-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        p = tail; <span class="comment">//取链表尾指针的快照</span></span><br><span class="line">    &#125; <span class="keyword">while</span>( <span class="built_in">CAS</span>(p-&gt;next, <span class="literal">NULL</span>, q) != TRUE); <span class="comment">//如果没有把结点链在尾指针上，再试</span></span><br><span class="line"> </span><br><span class="line">    <span class="built_in">CAS</span>(tail, p, q); <span class="comment">//置尾结点</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">DeQueue</span>() <span class="comment">//出队列</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        p = head;</span><br><span class="line">        <span class="keyword">if</span> (p-&gt;next == <span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> ERR_EMPTY_QUEUE;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">while</span>( <span class="built_in">CAS</span>(head, p, p-&gt;next) != TRUE );</span><br><span class="line">    <span class="keyword">return</span> p-&gt;next-&gt;value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="ABA-problem"><a href="#ABA-problem" class="headerlink" title="ABA problem"></a>ABA problem</h4><p>1）一次用CAS检查双倍长度的值，前半部是指针，后半部分是一个计数器。<br>2）只有这两个都一样，才算通过检查，要吧赋新的值。并把计数器累加1。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">SafeRead</span>(q)</span><br><span class="line">&#123;</span><br><span class="line">    loop:</span><br><span class="line">        p = q-&gt;next;</span><br><span class="line">        <span class="keyword">if</span> (p == <span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="function">Fetch&amp;<span class="title">Add</span><span class="params">(p-&gt;refcnt, <span class="number">1</span>)</span></span>;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> (p == q-&gt;next)&#123;</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">Release</span>(p);</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">goto</span> loop;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://blog.csdn.net/men_wen/article/details/58332639">APUE笔记—线程同步之互斥锁、读写锁、条件变量、POSIX信号量</a></li>
<li><a href="https://coolshell.cn/articles/8239.html">无锁队列的实现</a></li>
<li><a href="https://blog.csdn.net/gatieme/article/details/51481863">内核线程、轻量级进程、用户线程三种线程概念解惑（线程≠轻量级进程）</a></li>
<li><a href="https://blog.csdn.net/gatieme/article/details/51892437">原线程的3种实现方式–内核级线程, 用户级线程和混合型线程</a></li>
</ul>
]]></content>
      <categories>
        <category>Programming</category>
        <category>C,C++</category>
      </categories>
  </entry>
  <entry>
    <title>C/C++ Language Basic</title>
    <url>/2018/03/17/Programming/C,C++/Cpp_basic/</url>
    <content><![CDATA[<h2 id="Simple-Concepts"><a href="#Simple-Concepts" class="headerlink" title="Simple Concepts"></a>Simple Concepts</h2><h3 id="Reference-amp-Pointer"><a href="#Reference-amp-Pointer" class="headerlink" title="Reference &amp; Pointer"></a>Reference &amp; Pointer</h3><ul>
<li>Reference &lt;&#x3D;&gt; alias, the variable stands for a address</li>
<li>Pointer, the variable save the address</li>
</ul>
<h3 id="Overload-amp-Override"><a href="#Overload-amp-Override" class="headerlink" title="Overload &amp; Override"></a>Overload &amp; Override</h3><ul>
<li>Overload: just same name with same return type.</li>
<li>Override：can only be done in derived class</li>
</ul>
<h3 id="What-will-run-before-calling-main"><a href="#What-will-run-before-calling-main" class="headerlink" title="What will run before calling main"></a>What will run before calling main</h3><ul>
<li>static or global constructor</li>
</ul>
<h3 id="Array-amp-Pointer"><a href="#Array-amp-Pointer" class="headerlink" title="Array &amp; Pointer"></a>Array &amp; Pointer</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span> a[] = “hello”;</span><br><span class="line"><span class="type">char</span> *b = <span class="string">&quot;world&quot;</span>;</span><br><span class="line"><span class="built_in">sizeof</span>(a) = length * <span class="built_in">sizeof</span>(<span class="type">char</span>) = <span class="number">6</span></span><br><span class="line"><span class="built_in">sizeof</span>(b) = <span class="built_in">sizeof</span>(<span class="type">char</span>*) = <span class="number">4</span>(<span class="number">32</span> bit os)/<span class="number">8</span>(<span class="number">64</span> bit os)</span><br></pre></td></tr></table></figure>

<h3 id="Function-Pointer"><a href="#Function-Pointer" class="headerlink" title="Function Pointer"></a>Function Pointer</h3><p><code>int (*s[10])(int)</code> stands for a function pointer array, each element is a pointer to a function with pattern <code>int func(int param)</code>  </p>
<h3 id="Direct-Address-Use"><a href="#Direct-Address-Use" class="headerlink" title="Direct Address Use"></a>Direct Address Use</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// assign 1234(int) on address 0x100000</span></span><br><span class="line">(<span class="type">unsigned</span> <span class="type">int</span>*)<span class="number">0x100000</span> = <span class="number">1234</span></span><br><span class="line"><span class="comment">// call functions on address 0x100000</span></span><br><span class="line">*((<span class="built_in">void</span> (*)())<span class="number">0x100000</span>)()</span><br><span class="line"><span class="comment">// (void (*)())0x100000 casts 0x100000 to function pointer</span></span><br></pre></td></tr></table></figure>

<h3 id="const-define-static-enum"><a href="#const-define-static-enum" class="headerlink" title="const , define, static, enum"></a>const , define, static, enum</h3><ul>
<li>const <ul>
<li>behavior：always let the right part to be fixed<ul>
<li><code>const char* p</code> &#x3D; <code>char const *p</code> &#x3D;&gt; can’t not modify <code>*p</code></li>
<li><code>char* cosnt p</code> &#x3D;&gt; can’t not modify <code>p</code></li>
</ul>
</li>
<li>storage：<ul>
<li>global constants &#x3D;&gt; read only data (generated by compiler)</li>
<li>local constants &#x3D;&gt; stack</li>
</ul>
</li>
<li>const function body implementation: take the <code>this</code> pointer as a const pointer.</li>
</ul>
</li>
<li>static<ul>
<li>determines the lifetime and linkage of the variable</li>
</ul>
</li>
<li>define<ul>
<li>preprocessing before compiling, replace the code</li>
</ul>
</li>
<li>define vs const<ul>
<li><code>const</code> provides type checking</li>
<li><code>define</code> no extra space</li>
</ul>
</li>
<li>enum<ul>
<li>Enum variable actually is a integer in memory. There is no enums when code runs. It’s just a semi-type-safe form of #define</li>
<li>Size: often 4 bytes, but the standard does not say what size it should be; only that it should be big enough to fit any enumerator.</li>
</ul>
</li>
</ul>
<h2 id="Object-Oriented-vs-Procedure-Oriented"><a href="#Object-Oriented-vs-Procedure-Oriented" class="headerlink" title="Object Oriented vs Procedure Oriented"></a>Object Oriented vs Procedure Oriented</h2><ul>
<li>POP:<ul>
<li>divides program into small parts called functions</li>
<li>separates data and method</li>
</ul>
</li>
<li>OOP:<ul>
<li>Encapsulation(class) &#x3D;&gt; Data hiding(private) and Bundling of data and methods together</li>
<li>Inheritance &#x3D;&gt; code reuse</li>
<li>Polymorphism</li>
</ul>
</li>
</ul>
<h2 id="static-vs-global"><a href="#static-vs-global" class="headerlink" title="static vs global"></a>static vs global</h2><h3 id="C"><a href="#C" class="headerlink" title="C"></a>C</h3><ul>
<li>sameness<ul>
<li>variables stay in .bss(uninitialized) or .data(initialized) segment</li>
<li>could be accessed if included</li>
</ul>
</li>
<li>difference<ul>
<li>static :  <ul>
<li>variables can be defined in function </li>
<li>has static (internel) linkage</li>
</ul>
</li>
<li>global:<ul>
<li>has externel linkage (other file could access by <code>externel</code>  )</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="C-1"><a href="#C-1" class="headerlink" title="C++"></a>C++</h3><ul>
<li>static could declared in class but must be initilized in out of calss.</li>
<li>static variable in class belong to the class.</li>
<li>static function can not use <code>this</code></li>
</ul>
<h2 id="Memory-new-delete-malloc-free"><a href="#Memory-new-delete-malloc-free" class="headerlink" title="Memory: new, delete, malloc, free"></a>Memory: new, delete, malloc, free</h2><ul>
<li><p><code>malloc</code>, <code>free</code></p>
<ul>
<li>What: std lib function</li>
<li>Behavior: only allocate&#x2F;free the space</li>
<li>Return: void* </li>
<li>Failure: return NULL</li>
<li>Memory allocated from: heap</li>
<li>Size: need a manual calculation</li>
</ul>
</li>
<li><p><code>new</code>, <code>delete</code> </p>
<ul>
<li>C++ operator, could be overrided</li>
<li>allocate&#x2F;free the space first, and call constructor and destructor</li>
<li>Return: a exact type pointer</li>
<li>Failure: throw a exception</li>
<li>Memory allocated from : free store</li>
<li>Size: calculated by compiler ( &#x3D; <code>sizeof(type)</code>, called with a TYPE-ID)</li>
<li>Reallocation: not provided (because of copy constructor)</li>
<li>Implementation<!--TODO sbrk  --></li>
</ul>
</li>
<li><p>some tricks:</p>
<ol>
<li><code>free store</code> and <code>heap</code> are the same thing from the machine’s point of view</li>
<li>in-place <code>new</code> to avoid operate memory<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">A* a = <span class="keyword">new</span> A;</span><br><span class="line">a.~<span class="built_in">A</span>() <span class="comment">// call destructor but not free the space</span></span><br><span class="line">a = <span class="built_in">new</span> (a) A;  <span class="comment">// call constructor on address a</span></span><br></pre></td></tr></table></figure></li>
<li>sizeof(empty struct) &#x3D; 1. Beacuase std define new could only</li>
</ol>
</li>
</ul>
<!-- TODO 内存分配策略 -->


<h2 id="Polymorphism-多态"><a href="#Polymorphism-多态" class="headerlink" title="Polymorphism 多态"></a>Polymorphism 多态</h2><p>There is a hierarchy of classed and they are related by inheritance.</p>
<ul>
<li>dependency: inheritance and function override</li>
<li>abstart: the ability of a object to be used in more than one form.</li>
<li>specific: a call to a member function will cause a different function to be executed depending on the type of object.</li>
</ul>
<h3 id="Compile-time-Polymorphism"><a href="#Compile-time-Polymorphism" class="headerlink" title="Compile time Polymorphism"></a>Compile time Polymorphism</h3><ul>
<li>early binding</li>
<li>designed for function reuse</li>
<li>sub(derived,child) class function replace the super(base) class function</li>
</ul>
<h4 id="Why-use-Constructor-member-initialization-list"><a href="#Why-use-Constructor-member-initialization-list" class="headerlink" title="Why use Constructor member initialization list"></a>Why use Constructor member initialization list</h4><p>init before running the function body</p>
<ol>
<li>Efficiency</li>
<li>Initialization of base class</li>
<li>Initialization of Subobjects which only have parameterized constructors</li>
<li>Initializing non-static const data members</li>
<li>Initialization of reference data members</li>
</ol>
<h3 id="Runtime-Polymorphism"><a href="#Runtime-Polymorphism" class="headerlink" title="Runtime Polymorphism"></a>Runtime Polymorphism</h3><ul>
<li>late binding</li>
<li>dependency: inheritance and virtual function override </li>
<li>call function of derived class </li>
<li>In many cases, deconstructor should be virtual<ul>
<li>To avoid memory leak, because deleting objects of base type will not call the deconstructor of derived class.</li>
</ul>
</li>
</ul>
<blockquote>
<p>Pure Virtual Functions &lt;&#x3D;&gt; interface </p>
</blockquote>
<h4 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h4><p>add a constant virtual table <code>vtable</code> and a member function pointer <code>vptr</code> for each class.</p>
<ul>
<li><p><code>vtable</code>: A table of function pointers. </p>
<ul>
<li>maintained per class by compiler.</li>
</ul>
</li>
<li><p><code>vptr</code>: A pointer to vtable. </p>
<ul>
<li>maintained per object.<br><img src="/CPP_basic/vtable.png" loading="lazy"></li>
</ul>
</li>
<li><p>Addition: What does compiler do?</p>
<ul>
<li>insert a code to every constructor: set <code>vptr</code> to <code>vtable</code> of the associated class  </li>
<li>change the function call to vitual function: first <code>vtable</code> according to <code>vptr</code>, and then access the target function.</li>
</ul>
</li>
</ul>
<p>so the virtual function call is a bit slower than the normal function</p>
<h2 id="STL"><a href="#STL" class="headerlink" title="STL"></a>STL</h2><h3 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h3><p>maintain a array with dynamic size inside</p>
<ul>
<li>you’d better reserve if you know the max size</li>
<li>will double capacity if the size is greater than capacity</li>
<li>access: <code>[]</code> do not check range, <code>at()</code> will check range</li>
<li><code>clear()</code> do not free space</li>
<li>space-optimization(bitmap) for bool, can use uint8_t to avoid space-optimization. 不考虑缓存的情况下空间优化会导致性能下降</li>
</ul>
<h3 id="map-red-black-tree"><a href="#map-red-black-tree" class="headerlink" title="map red-black tree"></a>map red-black tree</h3><h3 id="unordered-map-hash"><a href="#unordered-map-hash" class="headerlink" title="unordered_map hash"></a>unordered_map hash</h3><ul>
<li>structure array + bucket(link list to hanlde hash conflict)</li>
<li>enlarge capacity( need rehash) allocate a larger space and reinsert its items</li>
</ul>
<h3 id="When-Capacity-Change-for-C-11"><a href="#When-Capacity-Change-for-C-11" class="headerlink" title="When Capacity Change for C++11"></a>When Capacity Change for C++11</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if type of item defines the right value reference(&amp;&amp;) constuctor </span><br><span class="line">  use std::move </span><br><span class="line">else </span><br><span class="line">  use copy constuctor </span><br></pre></td></tr></table></figure>

<h2 id="Noteworthy-Features-of-C-11"><a href="#Noteworthy-Features-of-C-11" class="headerlink" title="Noteworthy Features of C++11"></a>Noteworthy Features of C++11</h2><h3 id="smart-pointer"><a href="#smart-pointer" class="headerlink" title="smart pointer"></a>smart pointer</h3><ul>
<li>shared_pointer<ul>
<li>use</li>
</ul>
</li>
<li>unique_pointer</li>
<li>weak_pointer<ul>
<li>not change reference counter</li>
<li>automatic release is not supported</li>
</ul>
</li>
</ul>
<h3 id="move-amp-rvalue-reference"><a href="#move-amp-rvalue-reference" class="headerlink" title="move &amp; rvalue reference"></a>move &amp; rvalue reference</h3><h3 id="Standard-Library"><a href="#Standard-Library" class="headerlink" title="Standard Library"></a>Standard Library</h3><p>x&#96;</p>
<h3 id="Grammar-Improvement"><a href="#Grammar-Improvement" class="headerlink" title="Grammar Improvement"></a>Grammar Improvement</h3><h4 id="lambda"><a href="#lambda" class="headerlink" title="lambda"></a>lambda</h4><ul>
<li>alias : anonymous function</li>
<li>format: <a href="parameters">capture</a>-&gt;return-type {body}</li>
<li></li>
</ul>
<h4 id="auto-amp-decltype"><a href="#auto-amp-decltype" class="headerlink" title="auto &amp; decltype"></a>auto &amp; decltype</h4><ul>
<li>Automatic Type Deduction</li>
<li>Auto<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">auto x=0; //x has type int because 0 is int</span><br><span class="line">auto c=&#x27;a&#x27;; //char</span><br><span class="line">auto d=0.5; //double</span><br><span class="line">auto national_debt=14400000000000LL;//long long</span><br><span class="line">vector&lt;int&gt; v;</span><br><span class="line">auto iter=v.begin(); //vector&lt;int&gt;::iterator </span><br></pre></td></tr></table></figure></li>
<li>Decltype (typedef according to the type of an object or an expression)<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const vector&lt;int&gt; vi;</span><br><span class="line">typedef decltype (vi.begin()) CIT;</span><br><span class="line"></span><br><span class="line">CIT iter2;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="Deleted-and-Default-Functions"><a href="#Deleted-and-Default-Functions" class="headerlink" title="Deleted and Default Functions"></a>Deleted and Default Functions</h4><ul>
<li>often used with multiple constructors</li>
<li>could set default function or delete some function</li>
</ul>
<h4 id="nullptr"><a href="#nullptr" class="headerlink" title="nullptr"></a>nullptr</h4><p>replace NULL</p>
<h4 id="override"><a href="#override" class="headerlink" title="override"></a>override</h4><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><p><a href="https://stackoverflow.com/questions/240212/">What is the difference between new&#x2F;delete and malloc&#x2F;free?</a></p>
</li>
<li><p><a href="https://www.geeksforgeeks.org/virtual-functions-and-runtime-polymorphism-in-c-set-1-introduction/">Virtual Functions and Runtime Polymorphism in C++ | Set 1 (Introduction)</a></p>
</li>
<li><p><a href="https://blog.csdn.net/lihao21/article/details/50688337">C++虚函数表剖析</a></p>
</li>
<li><p><a href="https://stackoverflow.com/questions/8115550/what-is-the-size-of-an-enum-type-data-in-c">what is the size of an enum type data in C++?</a></p>
</li>
<li><p><a href="https://www.jianshu.com/p/56bb01df8ac7">C++ unordered_map</a></p>
</li>
<li><p><a href="https://stackoverflow.com/questions/926752/why-should-i-prefer-to-use-member-initialization-list">Why should I prefer to use member initialization list?</a></p>
</li>
<li><p>TODO What is the use of volatile qualifier in C? <a href="https://www.quora.com/What-is-the-use-of-volatile-qualifier-in-C">https://www.quora.com/What-is-the-use-of-volatile-qualifier-in-C</a>  <a href="https://barrgroup.com/Embedded-Systems/How-To/C-Volatile-Keyword">https://barrgroup.com/Embedded-Systems/How-To/C-Volatile-Keyword</a>~~</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Programming</category>
        <category>C,C++</category>
      </categories>
  </entry>
  <entry>
    <title>Data Structures for DB(External Disk) | B Tree, LSM Tree</title>
    <url>/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/</url>
    <content><![CDATA[<p>本文将探讨当存储介质是外部存储，比如磁盘、闪存时，有哪些主流的存储数据结构(传统的二叉树将不再适用)。 本文以key-value数据库为例讲述不同数据结构的差异。<br>其KV存储包含以下5个基本操作</p>
<ul>
<li>get(K) 查找key K对应的value</li>
<li>put(K,V) 插入键值对（K，V）</li>
<li>update(K,V) 查找key K对应的value更新为V</li>
<li>delete(K) 删除key K对应的条目</li>
<li>scan(K1,K2) 得到从K1到K2的所有key和value</li>
</ul>
<h1 id="B-系列"><a href="#B-系列" class="headerlink" title="B 系列"></a>B 系列</h1><h2 id="B-B-Tree"><a href="#B-B-Tree" class="headerlink" title="B ( B- ) Tree"></a>B ( B- ) Tree</h2><p>B树也称B-树,它是一颗多路平衡查找树。我们描述一颗B树时需要指定它的阶数，阶数表示了一个结点最多有多少个孩子结点，一般用字母m表示阶数。当m取2时，就是我们常见的二叉搜索树。</p>
<blockquote>
<p>应用的数据库 MongoDB</p>
</blockquote>
<h3 id="结构图示"><a href="#结构图示" class="headerlink" title="结构图示"></a>结构图示</h3><p>以一颗阶数为4的为例，图中数字对应key，data对应value<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B_structure.png" loading="lazy"></p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ol>
<li>每个结点最多有m-1个key。</li>
<li>根结点最少可以只有1个key。</li>
<li>非根结点至少有$⌈m&#x2F;2⌉-1$个key。（最差节点利用率为50%）</li>
<li>每个结点中的关键字都按照顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。</li>
<li>所有叶子结点都位于同一层，或者说根结点到每个叶子结点的长度都相同。</li>
<li>设某个节点含有n个元素，则 <ul>
<li>如果是叶子节点，该节点含有n个value</li>
<li>如果是非叶子节点，该节点不仅含有n个value，还存有n+1个子节点的地址（边）</li>
</ul>
</li>
</ol>
<h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p>即根据一个key，得到对应的value(data)，也可能找不到。</p>
<h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p>其步骤如下：</p>
<ol>
<li>从根节点开始</li>
<li>在当前节点内通过二分查找定位到一个最小且&gt;&#x3D;key的key</li>
<li>如果key已经命中（相等），则返回该key的值。 如果没有命中，则加载新的子节点，返回第二步继续查找（如果已经是叶子节点，就可以返回不存在）。</li>
</ol>
<h4 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h4><p>整个过程时间复杂度是 O(logMlogN),</p>
<ul>
<li>M是阶数， logM对应在节点内做二分查找，每次加载节点都要二分查找一次。</li>
<li>N是元素个数， logN对应加载节点的次数，即树的深度</li>
</ul>
<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>另外更新就是先查找，然后修改value。就不做多的赘述了。不会修改树的结构，但是可能会导致节点地址改动（比如当将一个很小的value替换成一个很大的value，原始节点的物理空间不够，就需要重新将这个节点写入其他地方）。</p>
<h3 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h3><p>插入就是查找定位到节点后，在指定位置插入。比较复杂的部分是当节点存在节点满了之后就需要分裂。</p>
<p>最开始插入会先插入到叶子节点。若满则以中值为划分分裂成两个，同时将中值加入到父节点中。如果父节点又满，则进行相同操作。直到分裂向上的节点中没有满。</p>
<h4 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h4><p>我们以图例来理解这个过程，</p>
<ol>
<li>初始： 存在一棵M为5的树,即最大元素个数是4。<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B_insert.png" loading="lazy"></li>
<li>插入成功，但是导致一个叶子节点满<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B_insert_2.png" loading="lazy"></li>
<li>按中值(27)分裂，并将中值插入到父亲节点<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B_insert_3.png" loading="lazy"></li>
<li>因为父亲节点满，继续分裂。因为是根节点，所以向上过程直接添加一个新的根节点。整个插入结束。<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b_insert_4.png" loading="lazy"></li>
</ol>
<h4 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h4><p>O(logNlogM + M )</p>
<ul>
<li>logNlogM : 访问代价</li>
<li>M : 插入造成的移位或者分裂</li>
</ul>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除过程相对复杂。 但是其基本原则是，当节点删除一个元素时，<br>优先从子节点找后继替代自己，如果做不到，就从兄弟节点找（完成一个兄弟到父亲，父亲到自己的转移。若兄弟也做不到，则和兄弟进行合并。（因为此时两个字节点个数都是$⌈m&#x2F;2⌉-1$）</p>
<h4 id="不同情况图示"><a href="#不同情况图示" class="headerlink" title="不同情况图示"></a>不同情况图示</h4><ol>
<li><p>初始，阶数为5，即一个节点最少2个元素<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b_delete_0.png" loading="lazy"></p>
</li>
<li><p>删除21，正常删除，因为删除后节点个数仍然&gt;2<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b_delete2.png" loading="lazy"></p>
</li>
<li><p>删除27，在非叶子节点,从子节点替换，</p>
<ol>
<li>这里默认优先从右子节点替换 (试探法，减少读取次数，因为大概率情况下不需要转移)<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b_delete_3.png" loading="lazy"></li>
<li>但是子节点不够，就需要从兄弟节点移动过来。<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b_delete_4.png" loading="lazy"></li>
</ol>
</li>
<li><p>删除32</p>
</li>
<li><p>叶子节点个数不够，但是兄弟节点也无法转移<br>  <img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b_delete5.png" loading="lazy"></p>
</li>
<li><p>合并两个兄弟节点元素和兄弟之间的元素<br>  <img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b_delete_6.png" loading="lazy"></p>
</li>
</ol>
<h4 id="复杂度-2"><a href="#复杂度-2" class="headerlink" title="复杂度"></a>复杂度</h4><p>O(logNlogM + M)</p>
<ul>
<li>logNlogM : 访问代价</li>
<li>M : 删除造成的移位或者合并 <!-- TODO 博客里面多节点合并 --></li>
</ul>
<h2 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+ Tree"></a>B+ Tree</h2><p>相比于b树，区别在于</p>
<ol>
<li>非叶子节点是索引节点，只存储部分key和子节点地址，不存储value</li>
<li>所有key和value都会存储在叶子节点中</li>
<li>叶子节点之间存在顺序指向</li>
</ol>
<p>查找和更新和B树类似，就不提了。插入和删除思想一致，但是略有差别。 </p>
<blockquote>
<p>应用的数据库 MySQL 的 innodb</p>
</blockquote>
<h3 id="结构图示-1"><a href="#结构图示-1" class="headerlink" title="结构图示"></a>结构图示</h3><p><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b+_structure.png" loading="lazy"></p>
<h3 id="插入-1"><a href="#插入-1" class="headerlink" title="插入"></a>插入</h3><p>插入思想不变。即数据插入到叶子节点，如果满，则分裂，将中值插入到父亲节点，直至某个节点不满。</p>
<ol>
<li>如初始<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B+_insert_0.png" loading="lazy"></li>
<li>插入18,叶子满，分裂，中值插入到父亲节点<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b+_insert_1.png" loading="lazy"><br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b+_insert_2.png" loading="lazy"></li>
</ol>
<h3 id="删除-1"><a href="#删除-1" class="headerlink" title="删除"></a>删除</h3><p>必须删除叶子节点上的元素，同时更新索引节点上的。由于父亲节点不存在记录，所以都是从从兄弟之间转移。 当无法转移的时候合并节点。</p>
<ol>
<li>如初始<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B+_delete0.png" loading="lazy"></li>
<li>删除7<ol>
<li>删除后发现不足，但是兄弟节点也无法转移<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B+_delete01.png" loading="lazy"></li>
<li>叶子合并<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/b+_delete1.png" loading="lazy"></li>
<li>索引节点合并<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/B+_delete2.png" loading="lazy"></li>
</ol>
</li>
</ol>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>快速查找</li>
<li>B+： <ul>
<li>对scan(range query，范围扫描 顺序访问)更加友好</li>
<li>索引节点内单个页存储元素个数可以更多，降低树的深度，尤其适合value较大的场景</li>
</ul>
</li>
<li>B： 查找更加快（不需要每次访问到子节点）</li>
<li>value热更新开销小</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>插入操作慢，写</li>
<li>空间放大率高（空间利用率不高）， 数据结构变更容易产生文件空洞</li>
<li>不同节点随机存储在磁盘上，会产生大量的随机IO。</li>
</ul>
<h1 id="LSM-Tree"><a href="#LSM-Tree" class="headerlink" title="LSM Tree"></a>LSM Tree</h1><!-- IndexFS将LSM当做索引。 -->
<p>将日志文件系统与树形数据结构结合适用的形式，提出一种延迟更新、批量写入硬盘的LSM-tree及其算法，</p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><ul>
<li>C0树（常驻内存） </li>
<li>C1-N 树(位于磁盘)<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/lsm_tree_structure.png" loading="lazy"></li>
</ul>
<h2 id="插入、更新、删除"><a href="#插入、更新、删除" class="headerlink" title="插入、更新、删除"></a>插入、更新、删除</h2><p>就是将新的键值对放入C0即算插入完成，通过compaction操作去异步维护C0-N之间的关系。</p>
<ol>
<li>待C0存储的内容大于一个阈值，就会将内容全部合并到C1中，然后清空C0</li>
<li>对于C1-N也同理，任何一个Ci查过其阈值后，就讲内容合并到Ci+1</li>
</ol>
<h2 id="查找-1"><a href="#查找-1" class="headerlink" title="查找"></a>查找</h2><p>由于compaction导致同一个key可能存在多层中，但是越上层的数据越新。<br>所以查找则变成从上至下的查询。过程如下</p>
<ol>
<li><code>i = 0</code> (从C0开始)</li>
<li>如果在Ci中找到了K，则返回value，否则<code>i++</code>然后回到第1步，</li>
</ol>
<h2 id="特性-1"><a href="#特性-1" class="headerlink" title="特性"></a>特性</h2><h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ul>
<li>大幅度提高插入（修改、删除）性能</li>
<li>空间放大率降低</li>
<li>访问新数据更快，适合时序、实时存储</li>
<li>数据热度分布和level相关</li>
</ul>
<h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>牺牲了读性能（一次可能访问多个层）</li>
<li>读、写放大率提升</li>
</ul>
<h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>LSM Tree对于C树的具体实现很多，理论上Ci树可以是任何允许索引的结构，比如B、hash、二叉树等结构，但是目前业界主流实现可以参考LevelDB和RocksDB。</p>
<h1 id="Bepsilon-ε-Tree-x2F-Fractal-Tree"><a href="#Bepsilon-ε-Tree-x2F-Fractal-Tree" class="headerlink" title="Bepsilon(ε) Tree &#x2F; Fractal Tree"></a>Bepsilon(ε) Tree &#x2F; Fractal Tree</h1><p>一个针对B树做写优化的结构。 可以看做是LSM树和B树的结合</p>
<h2 id="对应系统"><a href="#对应系统" class="headerlink" title="对应系统"></a>对应系统</h2><p>被TokuDB 和 the BetrFS 采用。<br>为了防止歧义，我也将论文中的原文粘贴在引用中。</p>
<h2 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h2><ul>
<li>每个node内置一个buffer，这个buffer是持久化存储的。</li>
<li>一个节点的大小为B， 那么存储原始数据的pivots部分大小为<code>Bε</code>和buffer部分大小为<code>B-Bε</code>, ε是0-1之间的一个数<br><img src="/2019/02/01/Programming/Data%20Structure/B_LSM_B-eplison_Tree/Be_structure.png" loading="lazy"><blockquote>
<p>The distinguishing feature of a Bε-tree is that in- ternal nodes also allocate some space for a buffer, as shown in Figure 1. The buffer in each internal node is used to store messages, which encode updates that will eventually be applied to leaves under this node. This buffer is not an in-memory data structure; it is part of the node and is written to disk, evicted from memory, etc., whenever the node is. The value of ε, which must be between 0 and 1, is a tuning parameter that selects how much space internal nodes use for pivots (≈ Bε) and how much space is used as a buffer (≈ B − Bε).</p>
</blockquote>
</li>
</ul>
<h2 id="写操作-（插入和删除）"><a href="#写操作-（插入和删除）" class="headerlink" title="写操作 （插入和删除）"></a>写操作 （插入和删除）</h2><ol>
<li>每个写操作和删除操作都会编码成<code>message</code>，每个buffer中的message会以二叉搜索树的方式组织（比如红黑树），</li>
<li>每次都是先写入root node的buffer</li>
<li>当一个节点的buffer满时，消息将会批量地写给一个子节点</li>
<li>最终buffer会传递到叶子节点，当叶子节点buffer满时，将改动应用到叶子节点，然后分裂或者合并node的过程就跟B树一样了<!-- 应该不是message里面的所有信息吧，毕竟一个子节点范围小于他的父亲节点 --></li>
</ol>
<blockquote>
<p>Insertions are encoded as “insert messages”, addressed to a particular key, and added to the buffer of the root node of the tree. When enough messages have been added to a node to fill the node’s buffer, a batch of messages are flushed to one of the node’s children. Generally, the child with the most pending messages is selected. Over the course of flushing, each message is ultimately delivered to the appropriate leaf node, and the new key and value are added to the leaf. When a leaf node becomes too full, it splits, just as in a B-tree. Similar to a B-tree, when an interior node gets too many children, it splits and the messages in its buffer are distributed between the two new nodes.</p>
</blockquote>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>从root到leaf先查询buffer，<br>buffer中没有再去leafnode里查看。 查询路径和B树相同。</p>
<!-- ## 一些优化 -->


<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.cnblogs.com/nullzx/p/8729425.html">B树和B+树的插入、删除图文详解</a></li>
<li><a href="https://www.cnblogs.com/siegfang/archive/2013/01/12/lsm-tree.html">日志结构的合并树 The Log-Structured Merge-Tree</a></li>
<li><a href="https://cloud.tencent.com/developer/news/340271">LSM-tree 基本原理及应用</a></li>
<li><a href="https://akumuli.org/akumuli/2017/08/01/storage-engine-design2/">Storage engine design(Part2)</a></li>
<li><a href="http://www3.cs.stonybrook.edu/~rob/papers/login15.pdf">An Introduction to Bε trees and Write-Optimization</a></li>
<li><a href="http://kernelmaker.github.io/Btree_LSM_FTI">B+ Tree、LSM、Fractal tree index 读写放大分析</a></li>
<li><a href="http://blog.omega-prime.co.uk/2016/07/05/datastructures-for-external-memory/">Data structures for external memory</a></li>
<li><a href="https://www.open-open.com/lib/view/open1420338434078.html">IndexFS: Scaling File System Metadata Performance</a></li>
<li><a href="http://openinx.github.io/2015/11/25/ft-index-implement/">TokuDB的索引结构–分形树的实现</a></li>
<li><a href="http://mysql.taobao.org/monthly/2017/07/04/">TokuDB · 引擎特性 · HybridDB for MySQL高压缩引擎TokuDB 揭秘</a></li>
<li><a href="https://www.biaodianfu.com/tokudb.html">MySQL 高性能存储引擎：TokuDB初探</a></li>
</ul>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Data Structure</category>
      </categories>
  </entry>
  <entry>
    <title>线段树</title>
    <url>/2017/05/22/Programming/Data%20Structure/segment_tree/</url>
    <content><![CDATA[<h1 id="线段树"><a href="#线段树" class="headerlink" title="线段树"></a>线段树</h1><h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>固定范围内区间统计，统计只能是可以合并的操作如：最值、求和</p>
<h2 id="树状数组"><a href="#树状数组" class="headerlink" title="树状数组"></a>树状数组</h2><p>在认识线段树之前，有个熟悉的结构，每一层分布跟归并排序过程类似，就是树状数组，如下：<br><img src="/2017/05/22/Programming/Data%20Structure/segment_tree/tree_array.png" loading="lazy"></p>
<ol>
<li>T的根结点代表整个数组所在的区间对应的信息，及arr[0:N]（不含N)所对应的信息。 </li>
<li>T的每一个叶结点存储对应于输入数组的每一个单个元素构成的区间arr[i]所对应的信息，此处0≤i&lt;N。 </li>
<li>T的每一个中间结点存储对应于输入数组某一区间arr[i:j]对应的信息，此处0≤i&lt;j&lt;N。</li>
</ol>
<p>其本质思想是分而治之。</p>
<h2 id="代码详解"><a href="#代码详解" class="headerlink" title="代码详解"></a>代码详解</h2><p>以如下问题为例来描述样例代码：</p>
<p>我们有一个长度为n的int数组，即A[0..n-1]</p>
<p>需要支持以下几种操作：</p>
<ul>
<li>找到区间[l..r]内的元素之和</li>
<li>对区间[l..r]内的所有元素都更新为一个新的值x，即a[l..r]&#x3D;x</li>
</ul>
<blockquote>
<p>理论也可以用链表实现，但是实际效率比如直接用数组实现慢许多。</p>
</blockquote>
<h3 id="构建-O-N"><a href="#构建-O-N" class="headerlink" title="构建 O(N)"></a>构建 O(N)</h3><p>可能有些人会当成N次更新，但是实际可以通过从树状数组尾部遍历来优化</p>
<ul>
<li>递归版<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">build</span><span class="params">(<span class="type">int</span> node, <span class="type">int</span> start, <span class="type">int</span> end)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(start == end)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// Leaf node will have a single element</span></span><br><span class="line">        tree[node] = A[start];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = (start + end) / <span class="number">2</span>;</span><br><span class="line">        <span class="comment">// Recurse on the left child</span></span><br><span class="line">        <span class="built_in">build</span>(<span class="number">2</span>*node, start, mid);</span><br><span class="line">        <span class="comment">// Recurse on the right child</span></span><br><span class="line">        <span class="built_in">build</span>(<span class="number">2</span>*node+<span class="number">1</span>, mid+<span class="number">1</span>, end);</span><br><span class="line">        <span class="comment">// Internal node will have the sum of both of its children</span></span><br><span class="line">        tree[node] = tree[<span class="number">2</span>*node] + tree[<span class="number">2</span>*node+<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>高效版<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// function to build the tree </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">build</span><span class="params">( <span class="type">int</span> arr[])</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="comment">// insert leaf nodes in tree </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;n; i++)     </span><br><span class="line">        tree[n+i] = arr[i]; </span><br><span class="line">      </span><br><span class="line">    <span class="comment">// build the tree by calculating parents </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n - <span class="number">1</span>; i &gt; <span class="number">0</span>; --i)      </span><br><span class="line">        tree[i] = tree[i&lt;&lt;<span class="number">1</span>] + tree[i&lt;&lt;<span class="number">1</span> | <span class="number">1</span>];     </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="查找-O-logN"><a href="#查找-O-logN" class="headerlink" title="查找 O(logN)"></a>查找 O(logN)</h3><ul>
<li>递归版<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> node, <span class="type">int</span> start, <span class="type">int</span> end, <span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(r &lt; start <span class="keyword">or</span> end &lt; l)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// range represented by a node is completely outside the given range</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(l &lt;= start <span class="keyword">and</span> end &lt;= r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// range represented by a node is completely inside the given range</span></span><br><span class="line">        <span class="keyword">return</span> tree[node];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// range represented by a node is partially inside and partially outside the given range</span></span><br><span class="line">    <span class="type">int</span> mid = (start + end) / <span class="number">2</span>;</span><br><span class="line">    <span class="type">int</span> p1 = <span class="built_in">query</span>(<span class="number">2</span>*node, start, mid, l, r);</span><br><span class="line">    <span class="type">int</span> p2 = <span class="built_in">query</span>(<span class="number">2</span>*node+<span class="number">1</span>, mid+<span class="number">1</span>, end, l, r);</span><br><span class="line">    <span class="keyword">return</span> (p1 + p2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>高效版<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// function to get sum on interval [l, r) </span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="type">int</span> res = <span class="number">0</span>; </span><br><span class="line">    <span class="comment">// loop to find the sum in the range </span></span><br><span class="line">    <span class="keyword">for</span> (l += n, r += n; l &lt; r; l &gt;&gt;= <span class="number">1</span>, r &gt;&gt;= <span class="number">1</span>) </span><br><span class="line">    &#123; </span><br><span class="line">        <span class="keyword">if</span> (l&amp;<span class="number">1</span>)  </span><br><span class="line">            res += tree[l++]; </span><br><span class="line">        <span class="keyword">if</span> (r&amp;<span class="number">1</span>)  </span><br><span class="line">            res += tree[--r]; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">return</span> res; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="更新-O-logN"><a href="#更新-O-logN" class="headerlink" title="更新 O(logN)"></a>更新 O(logN)</h3><ul>
<li><p>递归版</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> node, <span class="type">int</span> start, <span class="type">int</span> end, <span class="type">int</span> idx, <span class="type">int</span> val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(start == end)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// Leaf node</span></span><br><span class="line">        A[idx] += val;</span><br><span class="line">        tree[node] += val;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = (start + end) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(start &lt;= idx <span class="keyword">and</span> idx &lt;= mid)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// If idx is in the left child, recurse on the left child</span></span><br><span class="line">            <span class="built_in">update</span>(<span class="number">2</span>*node, start, mid, idx, val);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// if idx is in the right child, recurse on the right child</span></span><br><span class="line">            <span class="built_in">update</span>(<span class="number">2</span>*node+<span class="number">1</span>, mid+<span class="number">1</span>, end, idx, val);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Internal node will have the sum of both of its children</span></span><br><span class="line">        tree[node] = tree[<span class="number">2</span>*node] + tree[<span class="number">2</span>*node+<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>高效版<br>如果是更新一个区间，那么就必须使用类似上面的递归分治过程。<br>如果是只更新一个元素，那可以用如下方法。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// function to update a tree node </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">updateTreeNode</span><span class="params">(<span class="type">int</span> p, <span class="type">int</span> value)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="comment">// set value at position p </span></span><br><span class="line">    tree[p+n] = value; </span><br><span class="line">    p = p+n; </span><br><span class="line">      </span><br><span class="line">    <span class="comment">// move upward and update parents </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=p; i &gt; <span class="number">1</span>; i &gt;&gt;= <span class="number">1</span>) </span><br><span class="line">        tree[i&gt;&gt;<span class="number">1</span>] = tree[i] + tree[i^<span class="number">1</span>]; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="二维线段树"><a href="#二维线段树" class="headerlink" title="二维线段树"></a>二维线段树</h2><p>即矩阵（假设N行M列）下的线段树，应对矩形区间内的更新和查询，有三种实现方法</p>
<ol>
<li>基础的方法： 每一行当成一个一维线段树，那么更新和查询复杂度变成O(NlogM)</li>
<li>四分树： 即每次递归向下时分成四份 更新和查询复杂度变成(logM * logN)<br><img src="/2017/05/22/Programming/Data%20Structure/segment_tree/4-divided-segment-tree.png" loading="lazy"></li>
<li>分段线段树： 本质同四分树，时间复杂度也相同。 但是代码相对简单些。每次递归向下也是二分，只是对行二分和对列二分间隔进行（类似KD树），比如深度为偶数时对行二分，深度为奇数时对列二分。</li>
</ol>
<h2 id="小试牛刀"><a href="#小试牛刀" class="headerlink" title="小试牛刀"></a>小试牛刀</h2><ol>
<li><p>一维线段树<br> <a href="https://leetcode.com/problems/range-sum-query-mutable/">https://leetcode.com/problems/range-sum-query-mutable/</a></p>
</li>
<li><p>二维线段树 POJ2155<br> <a href="https://vjudge.net/contest/225622#problem/A">https://vjudge.net/contest/225622#problem/A</a></p>
</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://blog.csdn.net/Yaokai_AssultMaster/article/details/79599809">线段树（segment tree)，看这一篇就够了</a><br><a href="https://www.hackerearth.com/practice/data-structures/advanced-data-structures/segment-trees/tutorial/">Segment Trees from hackerearth</a><br><a href="https://www.geeksforgeeks.org/segment-tree-efficient-implementation/">Segment tree | Efficient implementation</a><br><a href="http://www.cppblog.com/menjitianya/archive/2015/10/06/211956.html">二维线段树</a></p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Data Structure</category>
      </categories>
  </entry>
  <entry>
    <title>JVM GC(1) | 内存结构与GC基础</title>
    <url>/2017/03/17/Programming/Java/Java_JVM_GC/</url>
    <content><![CDATA[<p>(下文内容都是针对HotSpot VM)</p>
<h1 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h1><h2 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h2><p><img src="/2017/03/17/Programming/Java/Java_JVM_GC/JVM_memory_structure.png" loading="lazy"></p>
<ul>
<li>线程间共享(绿)</li>
<li>线程间独立(蓝)</li>
</ul>
<p><img src="/2017/03/17/Programming/Java/Java_JVM_GC/java_memory_model.png" loading="lazy"></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="线程共享"><a href="#线程共享" class="headerlink" title="线程共享"></a>线程共享</h3><ul>
<li><p>1 方法区(<strong>永生代</strong>)</p>
<ul>
<li>存储已经被加载的类信息、static变量.</li>
<li>1.1 同时放置运行时常量，运行期间动态产生的常量也放在这</li>
<li>参数 <code>-XX:MaxPermSize</code> <blockquote>
<p>SE8后改为MetaSpace</p>
</blockquote>
</li>
</ul>
</li>
<li><p>2 堆<br> 较复杂，见<a href="#%E5%A0%86">下文</a></p>
</li>
</ul>
<h3 id="线程独立"><a href="#线程独立" class="headerlink" title="线程独立"></a>线程独立</h3><ul>
<li>栈<br>Sun Hotspot不区分虚拟机栈和方法栈<ul>
<li>3 虚拟机栈 （Java Virtual Machine Stacks）<ul>
<li>Java方法执行的内存模型，类似C++，每个方法调用都会在栈上留下局部变量表，操作数栈，动态链接，方法出口等， 调用完成就出栈</li>
</ul>
</li>
<li>4 本地方法栈 （Native Method Stacks）<ul>
<li>作用类似，区别在于为虚拟机执行native方法</li>
</ul>
</li>
</ul>
</li>
<li>5 程序计数器 （Program Counter Register）<ul>
<li>记录线程切换时原来代码段的地址</li>
<li>占空间很小</li>
</ul>
</li>
<li>6 直接内存<ul>
<li>不在JVM的范围内，就是不用经过JVM管理、映射的直接内存</li>
</ul>
</li>
</ul>
<h1 id="GC过程"><a href="#GC过程" class="headerlink" title="GC过程"></a>GC过程</h1><h2 id="四种引用类型"><a href="#四种引用类型" class="headerlink" title="四种引用类型"></a>四种引用类型</h2><p><img src="/2017/03/17/Programming/Java/Java_JVM_GC/reference.png" alt="2022-11-28T222315" loading="lazy"></p>
<ul>
<li><p><strong>强引用（Strong Reference）</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">object</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"><span class="comment">// 只要强引用存在，垃圾回收就不会回收该对象，内存不足时会抛出OOM。</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>软引用（Soft Reference）</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SoftReference&lt;Object&gt; softReference = <span class="keyword">new</span> <span class="title class_">SoftReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>());</span><br><span class="line"><span class="comment">//定义：非必须，但仍有用的对象。内存不足时才会回收。</span></span><br></pre></td></tr></table></figure>
<p><em><strong>further reading: 怎么定义内存不足</strong></em><br>Interval(该引用多少MS没访问过) &#x3D; clock - timesatmp &gt; heap_free_space_after_last_gc(MB) * SoftRefLRUPolicyMSPerMB(JVM paramrter, default value is 1000ms))<br><strong>Related Code</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// https://github.com/AdoptOpenJDK/openjdk-jdk12u/blob/master/src/java.base/share/classes/java/lang/ref/SoftReference.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SoftReference</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">Reference</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">long</span> clock; <span class="comment">//Timestamp clock, updated by the garbage collector</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> timestamp; <span class="comment">//Timestamp updated by each invocation of the get method. </span></span><br><span class="line">    <span class="keyword">public</span> T <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">T</span> <span class="variable">o</span> <span class="operator">=</span> <span class="built_in">super</span>.get();</span><br><span class="line">        <span class="keyword">if</span> (o != <span class="literal">null</span> &amp;&amp; <span class="built_in">this</span>.timestamp != clock)</span><br><span class="line">            <span class="built_in">this</span>.timestamp = clock;</span><br><span class="line">        <span class="keyword">return</span> o;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//https://code.googlesource.com/edge/openjdk/+/refs/heads/jdk8u111-b09/hotspot/src/share/vm/memory/referencePolicy.cpp</span></span><br><span class="line">bool LRUCurrentHeapPolicy::should_clear_reference(...) &#123;</span><br><span class="line">  <span class="type">jlong</span> <span class="variable">interval</span> <span class="operator">=</span> timestamp_clock - java_lang_ref_SoftReference::timestamp(p);</span><br><span class="line">  <span class="keyword">assert</span>(interval &gt;= <span class="number">0</span>, <span class="string">&quot;Sanity check&quot;</span>);</span><br><span class="line">  <span class="comment">// The interval will be zero if the ref was accessed since the last scavenge/gc.</span></span><br><span class="line">  <span class="keyword">if</span>(interval &lt;= _max_interval) &#123; <span class="keyword">return</span> <span class="literal">false</span>; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>弱引用（Weak Reference）</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">WeakReference&lt;Object&gt; weakReference = <span class="keyword">new</span> <span class="title class_">WeakReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>());</span><br><span class="line"><span class="comment">//定义：发生GC时就会被回收</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>虚引用（Phantom Reference）</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">ReferenceQueue</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReferenceQueue</span>();</span><br><span class="line">PhantomReference&lt;Object&gt; pReference = <span class="keyword">new</span> <span class="title class_">PhantomReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>()，queue);</span><br><span class="line"><span class="comment">//不影响对象的生命周期，初始化必须有队列 只是在对象释放后，虚引用会进ReferenceQueue队列。</span></span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>对于三种非强引用，一般都要结合referenceQueue使用，用于捕获哪些reference被释放了。如无必要，自己写代码请只用强引用。对该部分不理解也不影响对GC过程的理解。</p>
</blockquote>
<h2 id="垃圾标记算法"><a href="#垃圾标记算法" class="headerlink" title="垃圾标记算法"></a>垃圾标记算法</h2><h3 id="引用计数-Reference-Counting-Collector"><a href="#引用计数-Reference-Counting-Collector" class="headerlink" title="引用计数 Reference Counting Collector"></a>引用计数 Reference Counting Collector</h3><p>python默认采用的策略</p>
<ul>
<li>优： <ul>
<li>简单，就是类似C++的shared pointer。 早期做法。</li>
</ul>
</li>
<li>缺： <ul>
<li>无法鉴别循环引用，即 </li>
<li>效率变慢，每次指针操作可能修改计数。  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.next = b; </span><br><span class="line">b.next = a;</span><br><span class="line">a = b = null;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="根搜索算法-Root-Tracing-Collector"><a href="#根搜索算法-Root-Tracing-Collector" class="headerlink" title="根搜索算法 Root Tracing Collector"></a>根搜索算法 Root Tracing Collector</h3><p>Java和C#默认采用的策略</p>
<h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><ol>
<li>通过一系列名为“GC Roots”的对象作为起始点，寻找对应的引用节点。</li>
<li>找到这些引用节点后，从这些节点开始向下继续寻找它们的引用节点。</li>
<li>重复（2）。</li>
<li>搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，就证明此对象是不可用的。</li>
</ol>
<p><img src="/2017/03/17/Programming/Java/Java_JVM_GC/mark_accessed.png" loading="lazy"></p>
<h4 id="根集-Root-Set"><a href="#根集-Root-Set" class="headerlink" title="根集(Root Set)"></a>根集(Root Set)</h4><!-- 不想记，略了吧 -->
<p>就是正在执行的Java程序可以访问的引用变量（注意：不是对象)的集合(包括局部变量、参数、类变量)，包含</p>
<ul>
<li>虚拟机栈（栈帧中的本地变量表）中的引用的对象</li>
<li>方法区中的类静态属性引用的对象</li>
<li>方法区中的常量引用的对象</li>
<li>本地方法栈中JNI（Native方法）的引用对象</li>
</ul>
<h2 id="标记过程"><a href="#标记过程" class="headerlink" title="标记过程"></a>标记过程</h2><p>关键点： 高优先级别，全局暂停标记； 低优先级异步释放</p>
<h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h3><ul>
<li>标记只能在静态内存结构上运行，JVM需要首先达到safepoint，然后标记过程全局暂停<strong>Stop the World</strong>(STW)，</li>
<li>执行(暂停)时间是看存活对象的个数，与堆大小无关，对象大小无关。 <ul>
<li>至于待释放对象个数，一般不相关，只有标记-清理算法 时间复杂度和待释放对象个数有关。</li>
</ul>
</li>
</ul>
<blockquote>
<p>safepoint 是一个big topic，以后有空再另外写一篇吧。</p>
</blockquote>
<h3 id="从标记到删除"><a href="#从标记到删除" class="headerlink" title="从标记到删除"></a>从标记到删除</h3><p>至少需要两次标记</p>
<ol>
<li><p>是否需要finalize的标记： 根未搜索、第一次标记、到且有必要执行finalize的对象打上标记放入F-Queue等待释放队列。</p>
<ul>
<li>未执行过finalize</li>
<li>finalize未被重载</li>
</ul>
</li>
<li><p>虚拟机自动建立的、低优先级的Finalizer线程去执行对象的finalize()方法</p>
</li>
<li><p>对象执行finalize()如果仍旧没有被引用，就开始执行回收流程</p>
</li>
</ol>
<h3 id="为什么需要finalize-而不直接回收"><a href="#为什么需要finalize-而不直接回收" class="headerlink" title="为什么需要finalize()而不直接回收"></a>为什么需要finalize()而不直接回收</h3><p>因为不是所有内存都是JVM自己管理的，比如开辟的直接内存，就需要自己显式的申请和删除</p>
<h2 id="回收算法"><a href="#回收算法" class="headerlink" title="回收算法"></a>回收算法</h2><h3 id="标记-清除-mark-sweep"><a href="#标记-清除-mark-sweep" class="headerlink" title="标记-清除 mark-sweep"></a>标记-清除 mark-sweep</h3><p>标记后直接在内存中<strong>原地</strong>清除对象</p>
<ul>
<li>优：<ul>
<li>对象不需要移动</li>
<li>只操作不存活对象，存活对象多也不影响效率</li>
</ul>
</li>
<li>劣：<ul>
<li>标记清除效率低，因为需要维护一个空闲表<br><img src="/2017/03/17/Programming/Java/Java_JVM_GC/mark-delete.png" loading="lazy"></li>
<li>清除产生大量不连续的内存碎片<br><img src="/2017/03/17/Programming/Java/Java_JVM_GC/mark-sweep-fragments.png" loading="lazy"></li>
</ul>
</li>
<li>适合：<ul>
<li>希望暂停时间尽可能短的</li>
<li>存活比例高的</li>
</ul>
</li>
</ul>
<h3 id="标记-整理-mark-compact"><a href="#标记-整理-mark-compact" class="headerlink" title="标记-整理 mark-compact"></a>标记-整理 mark-compact</h3><p>不直接对回收对象进行清理，而是所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。<br><img src="/2017/03/17/Programming/Java/Java_JVM_GC/mark-compact.png" loading="lazy"></p>
<ul>
<li>优：<ul>
<li>整理后无碎片&#x3D;&gt;内存分配更加快速, 空闲大小和位置便于统计</li>
</ul>
</li>
<li>劣：<ul>
<li>因为要移动存活的变量，和重新引用赋值， 就需要执行<strong>暂停</strong>，使得GC时间延长</li>
</ul>
</li>
<li>适合：<ul>
<li>存活比例高</li>
<li>回收不频繁</li>
</ul>
</li>
</ul>
<h3 id="停止-拷贝-copying"><a href="#停止-拷贝-copying" class="headerlink" title="停止-拷贝 copying"></a>停止-拷贝 copying</h3><p>拿空间换时间，将内存按容量分为大小相等的两块，每次只使用其中的一块（对象面），当这一块的内存用完了，就将还存活着的对象复制到另外一块内存上面（空闲面）。<br>只有对象区与空闲区的切换过程中，程序暂停执行。<br><img src="/2017/03/17/Programming/Java/Java_JVM_GC/copy.png" loading="lazy"><br><img src="/2017/03/17/Programming/Java/Java_JVM_GC/copy_result.png" loading="lazy"></p>
<ul>
<li>优：<ul>
<li>无碎片同mark-compact</li>
<li>标记和复制可以同时执行</li>
<li>每次只对一块内存进行回收，高效</li>
<li>实现简单</li>
</ul>
</li>
<li>劣：<ul>
<li>额外空间，空间利用率降低</li>
<li>也需要<strong>暂停</strong></li>
</ul>
</li>
<li>适合：<ul>
<li>存活比例少</li>
<li>内存申请次数多</li>
<li>回收不频繁</li>
</ul>
</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><blockquote>
<p>Adaptive 算法:垃圾收集器就是监控当前堆的使用情况，并将选择适当算法的垃圾收集器。</p>
</blockquote>
<h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h1><p>所有new创建的对象都在堆中分配</p>
<h2 id="分代示意图"><a href="#分代示意图" class="headerlink" title="分代示意图"></a>分代示意图</h2><p><img src="/2017/03/17/Programming/Java/Java_JVM_GC/generation.png" loading="lazy"></p>
<h3 id="对象分配原则"><a href="#对象分配原则" class="headerlink" title="对象分配原则"></a>对象分配原则</h3><ul>
<li>对象优先在Eden分配。</li>
<li>大对象直接进入老年代。</li>
<li>S1满时，S1所有数据进入老年代。</li>
<li>长期存活（年龄超过15）的对象将进入老年代： 每次Minor GC使得Survivor区内的对象年龄+1</li>
</ul>
<h3 id="Minor-GC-和-Full-GC"><a href="#Minor-GC-和-Full-GC" class="headerlink" title="Minor GC 和 Full GC"></a>Minor GC 和 Full GC</h3><ul>
<li>新生、年轻代 Young Generation： 对象死亡率高，少量存活， 适合<code>停止-拷贝</code><ul>
<li>Eden区 80%： 大部分对象在此生成<ul>
<li>一般满时触发 <strong>Minor GC(Scavenge GC)</strong> : 从Eden<code>停止-拷贝</code>到Survivor0，直到Eden清空位置</li>
</ul>
</li>
<li>Survivor0 10%<ul>
<li>满时 交换S0和S1，(本质就是就是把数据从0转到1)，完成后S0和Eden都为空</li>
</ul>
</li>
<li>Survivor1 10%<ul>
<li>满时将数据转移到 老年代</li>
</ul>
</li>
</ul>
</li>
<li>年老:  对象存活率高，适合 <code>标记-整理</code>，如果希望暂停时间减少，也可考虑<code>标记-删除</code><ul>
<li>一般满时 触发 <strong>Full GC</strong> ： 新生代、老年代、永生代都进行回收</li>
</ul>
</li>
<li>永生： 不怎么需要管理<ul>
<li>写满时也会触发 <strong>Full GC</strong></li>
</ul>
</li>
</ul>
<blockquote>
<p>这个永生在JAVA SE8后被移除，改为MetaSpace，毕竟从意义上就是记录了程序的元信息。<br>各代各部分比例都可以通过参数调整<br>另外 Full GC可以通过System.gc()显示调用;</p>
</blockquote>
<!-- ## JDK 7的几种垃圾收集器
- 新生代
1. Serial（SerialMSC）（Copying算法）
2. ParNew （Copying算法）
3. Parallel Scavenge （Copying算法）

- 老生代
1. Serial Old （标记—整理算法）
2. Parallel Old（ParallelMSC）（标记—整理算法）
3. CMS  （标记—整理算法）
4. G1 新的，听说很吊，以后有时间看看 -->
<!-- ## G1
### 为简单调优而生
首先来看G1垃圾回收，其设计原则是`简单可行的性能调优` 。即开发人员只需要调整以下两个参数就可以了
- `-Xmx32g` 最大使用内存 （无需设置各个代的大小，无需担心内存分配不平衡）
- `-XX:MaxGCPauseMillis=200` 最大GC暂停时间

### 内存结构
G1将新生代，老年代的**物理空间划分取消**了。这样我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。
![](Java_JVM_GC/G1_structure.png) 

取而代之的是，G1算法将堆划分为若干个细粒度的区域（Region）。
![](Java_JVM_GC/G1_structure2.png)
Humongous区域是一个特殊的区域。 它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。(如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，)


但是其他部分仍然和CMS类似：
1. 它**仍然属于分代收集器**。不过，只是新生代和老生代更小粒度地保存在同一个内存中。
2. 新生代的垃圾收集依然采用暂停所有应用线程(STW)的方式，将存活对象拷贝(`标记-拷贝`)到老年代或者Survivor空间。

### 对象空间申请策略
对象的申请会有三个去向：
1. TLAB(Thread Local Allocation Buffer)线程本地分配缓冲区
  在Eden空间中，每一个线程都有一个固定的分区用于分配对象，即一个TLAB（大小一般是eden的1%）。分配对象时，线程之间不再需要进行任何的同步。主要用来分配小对象、临时变量等，降低GC开销。
  > 注意区分java每个线程自己的工作内存`Working Memory`（常与可见性一起讨论）, TLAB只是用于分配空间的。
2. Eden区
  对TLAB空间中无法分配的对象，JVM会尝试在Eden空间中进行分配。如果Eden空间无法容纳该对象，就只能在老年代中进行分配空间。
3. Humongous区
  巨星对象

### 两种GC模式
都是STW的GC方式
#### Young GC
Young GC主要是对Eden区进行GC，它在Eden空间耗尽时会被触发。在这种情况下，Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到年老代空间。Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。最终Eden空间的数据为空，GC停止工作，应用线程继续执行。
![](Java_JVM_GC/G1_Y_1.png)
![](Java_JVM_GC/G1_Y_2.png)

#### Mixed GC



## ZGC -->
 <!-- TODO -->

<h1 id="一些经验"><a href="#一些经验" class="headerlink" title="一些经验"></a>一些经验</h1><h2 id="减少GC开销的技巧"><a href="#减少GC开销的技巧" class="headerlink" title="减少GC开销的技巧"></a>减少GC开销的技巧</h2><ul>
<li>没经验不要显式调用System.gc()，因为增加了暂停次数</li>
<li>减少临时对象的使用</li>
<li>对象不用时最好显式置为Null，手动悬空，加快GC</li>
<li>使用StringBuffer,而不用String来累加字符串</li>
<li>能用基本类型如Int,Long,就不用Integer,Long对象</li>
<li>尽量少用静态对象变量： 静态变量属于全局变量,不会被GC回收,它们会一直占用内存</li>
<li>散对象创建或删除的时间：  集中在短时间内大量创建新对象,特别是大对象,会导致突然需要大量内存,JVM在面临这种情况时,只能进行主GC,以回收内存或整合内存碎片,从而增加主GC的频率。集中删除对象，也是类似的。</li>
</ul>
<h2 id="Java-可能出现内存泄露的情况"><a href="#Java-可能出现内存泄露的情况" class="headerlink" title="Java 可能出现内存泄露的情况"></a>Java 可能出现内存泄露的情况</h2><p>即使根搜索看起来天衣无缝，依旧存在问题，如下：</p>
<ol>
<li>各种连接，数据库连接，网络连接，IO连接等没有显示调用close关闭，不被GC回收导致内存泄露。</li>
<li>监听器的使用，在释放对象的同时没有相应删除监听器的时候也可能导致内存泄露。</li>
</ol>
<h2 id="GC性能调优-和-主流GC对比分析"><a href="#GC性能调优-和-主流GC对比分析" class="headerlink" title="GC性能调优 和 主流GC对比分析"></a>GC性能调优 和 主流GC对比分析</h2><p>建议看我的下一篇</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://blog.csdn.net/l540675759/article/details/73733763">Java四种引用—强、软、弱、虚的知识点总结</a>)</li>
<li><a href="https://icyfenix.iteye.com/blog/715301">一个面试官对面试问题的分析</a></li>
<li><a href="https://www.zhihu.com/question/35164211/answer/68265045">怎么在面试时回答Java垃圾回收机制（GC）相关问题？ - wuxinliulei的回答</a></li>
<li><a href="https://www.jianshu.com/p/5261a62e4d29">浅析JAVA的垃圾回收机制</a></li>
<li><a href="http://www.charles-xiao.site/2015/07/29/%E6%B5%85%E6%9E%90java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/">浅析java内存管理机制</a></li>
<li><a href="https://juejin.im/post/5a14de6751882555cc417df7">JVM系列之Java内存结构详解</a>’</li>
<li><a href="http://blog.jobbole.com/109170/">深入理解 Java G1 垃圾收集器</a></li>
<li><a href="https://liuzhengyang.github.io/2017/06/07/garbage-first-collector/">Garbage First G1收集器 理解和原理分析</a></li>
<li><a href="https://tech.meituan.com/2016/09/23/g1.html">Java Hotspot G1 GC的一些关键技术</a></li>
</ul>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM GC(2) | Modern Garbage Collectors - CMS, G1, ZGC, Shenandoah GC</title>
    <url>/2022/05/21/Programming/Java/ModernGC/</url>
    <content><![CDATA[<h1 id="WarmUp"><a href="#WarmUp" class="headerlink" title="WarmUp"></a>WarmUp</h1><h2 id="Basic-operations-in-GC"><a href="#Basic-operations-in-GC" class="headerlink" title="Basic operations in GC"></a>Basic operations in GC</h2><ul>
<li>Mark: mark the reachable objects</li>
<li>Sweep: clear the unreachable objects</li>
<li>Copy-Move: Copy the reachable objects to another space</li>
<li>Compaction: Compact the reachable objects in-place<blockquote>
<p>Some GC docs regard the Copy-Move operation as Compaction as well.</p>
</blockquote>
</li>
</ul>
<h2 id="Parallel-vs-Concurrent"><a href="#Parallel-vs-Concurrent" class="headerlink" title="Parallel vs Concurrent"></a>Parallel vs Concurrent</h2><ul>
<li>Parallel: GC process runs multiple threads in parallel with STW.</li>
<li>Concurrent: GC runs concurrently with the application <strong>without STW</strong>.</li>
</ul>
<h2 id="Why-STW-GC-races"><a href="#Why-STW-GC-races" class="headerlink" title="Why STW? - GC races"></a>Why STW? - GC races</h2><p>GC races with Application:</p>
<ul>
<li>Change object reference when marking</li>
<li>Access object when reference is changing (Compact, Copy&amp;Move)</li>
</ul>
<h2 id="GC-barriers"><a href="#GC-barriers" class="headerlink" title="GC barriers"></a>GC barriers</h2><p>ZGC and Shenandoah GC inject GC-related code before loading&#x2F;storing the object on the assembly code.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0. loading: f = obj.field  /   storing: obj.f = o</span><br><span class="line">// ------ barrier -------</span><br><span class="line">1. get the state of address(obejct)  </span><br><span class="line">2. if the state indicates a possible GC race, then STW and do something</span><br><span class="line">// ------ barrier -------</span><br></pre></td></tr></table></figure>

<h1 id="Garbage-Collector-Landscape"><a href="#Garbage-Collector-Landscape" class="headerlink" title="Garbage Collector Landscape"></a>Garbage Collector Landscape</h1><p><img src="/2022/05/21/Programming/Java/ModernGC/GC_landscape.png" loading="lazy"></p>
<h2 id="Parallel-New-Parallel-Old"><a href="#Parallel-New-Parallel-Old" class="headerlink" title="Parallel New + Parallel Old"></a>Parallel New + Parallel Old</h2><p>The ParallelOld GC is a <strong>two-generational parallel STW</strong> garbage collector, which means that whenever a garbage collection occurs in either generation, all application threads are stopped, and the GC work is performed using multiple threads.</p>
<ul>
<li>new generation: <code>copy</code></li>
<li>old generation: <code>compaction</code><br><img src="/2022/05/21/Programming/Java/ModernGC/parallel_GC.png" loading="lazy"></li>
</ul>
<h2 id="Parallel-New-CMS-Concurrent-Mark-Sweep"><a href="#Parallel-New-CMS-Concurrent-Mark-Sweep" class="headerlink" title="Parallel New + CMS(Concurrent Mark Sweep)"></a>Parallel New + CMS(Concurrent Mark Sweep)</h2><p>CMS was developed in response to a growing number of applications that demanded a collector with lower worst-case pause.<br><img src="/2022/05/21/Programming/Java/ModernGC/GC_CMS.png" alt="2022-12-08T211550" loading="lazy"></p>
<h3 id="major-change-against-Parallel-Old"><a href="#major-change-against-Parallel-Old" class="headerlink" title="major change against Parallel Old"></a>major change against Parallel Old</h3><ul>
<li><p>use <code>sweep</code> to achieve concurrent processing</p>
<ul>
<li><p>because the object to be released will not be accessed by the application threads.</p>
</li>
<li><p><strong>Cons</strong>: more memory fragments(holes)</p>
<ul>
<li><strong>How CMS handles fragments?</strong> CMS FGC sometimes triggers compaction. (Related parameters about when to trigger compaction: <code>-XX：+UseCMS-CompactAtFullCollection</code>, <code>-XX：CMSFullGCsBefore-Compaction</code>)</li>
<li>So the worst pause of CMS is decided by compaction instead of sweep.</li>
</ul>
</li>
</ul>
</li>
<li><p>introduce multi-stage mark</p>
<ol>
<li>mark alive objects concurrently </li>
<li>remark fewer objects which have changed reference at <code>concurrent mark</code></li>
</ol>
</li>
</ul>
<h2 id="G1-Garbage-first"><a href="#G1-Garbage-first" class="headerlink" title="G1 (Garbage-first)"></a>G1 (Garbage-first)</h2><p>Young and old generation are never a contiguous chunk of memory. Both the young and old generations are a set of <code>regions</code> where most GC operations can be applied individually to each region. Also, regions that belong to the same set and therefore same generation do not need to be contiguous in memory.<br><img src="/2022/05/21/Programming/Java/ModernGC/G1_region.png" alt="2022-12-08T214448" loading="lazy"></p>
<h3 id="Optimization-of-region"><a href="#Optimization-of-region" class="headerlink" title="Optimization of region"></a>Optimization of region</h3><ol>
<li>Use fine-grained(region by region) copy to replace entire generation compaction&#x2F;copy. </li>
<li>Regions filled with all alive objects skip compaction and copying.<ul>
<li>it’s really fast when changing the color(generation) of the region, e.g. survivor-&gt;old</li>
</ul>
</li>
<li>Make GC pauses to achieve predictability, namely, the <strong>maximum pause time of GC could be controlled</strong> by GC could be stopped at any stage with completing a part of regions and the size of generations could be adjusted.</li>
</ol>
<h2 id="Shenandoah-GC-SGC-2-0"><a href="#Shenandoah-GC-SGC-2-0" class="headerlink" title="Shenandoah GC (SGC) 2.0"></a>Shenandoah GC (SGC) 2.0</h2><p>Work for all JDK LTS version(8,11,17) and 32&#x2F;64 bits system!!!</p>
<h3 id="Compared-with-G1"><a href="#Compared-with-G1" class="headerlink" title="Compared with G1"></a>Compared with G1</h3><ul>
<li>Scalable Low Latency GC</li>
<li>All regions in single Generations<ul>
<li>It prefers to relocate region with most garbage&#x2F; least live object first.</li>
</ul>
</li>
<li>Concurrent Compaction&amp;mark<br><img src="/2022/05/21/Programming/Java/ModernGC/SGC_workflow.png" loading="lazy"></li>
<li><strong>How to reduce GC races</strong><ul>
<li><strong>Postpone Remark</strong>:  SGC postponed the remark(remap) to next GC mark. Remark is a step to remap the reference which is changed by application threads in-or-after the latest concurrent mark.<br><img src="/2022/05/21/Programming/Java/ModernGC/SGC_ZGC_POSTPONE_REMAP.png" alt="2022-12-11T213732" loading="lazy"></li>
<li><strong>Barrier</strong>: Uses load&#x2F;store barrier to do tiny relocation with STW. <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Load Barrier(LRB - Load Reference Barrier)</span></span><br><span class="line"><span class="type">Object</span> <span class="variable">f</span> <span class="operator">=</span> obj.f;</span><br><span class="line"><span class="keyword">if</span> (in_evac_phase &amp;&amp; in_collection_set(obj) &amp;&amp; !is_forwarded(obj))</span><br><span class="line">  slow_path(); <span class="comment">//do something with STW to handle GC races</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<blockquote>
<p>Load Barrier example: What if GC barrier hit conflict with normal GC relocation? GC relocation skip it, since GC barrier did relocation of the page.</p>
<ol>
<li>Object is in Evacuation (GC Copy),<br> <img src="/2022/05/21/Programming/Java/ModernGC/SGC_01.png" alt="SGC_01" loading="lazy"></li>
<li>Application tries to load the object and triggers LRB, the <code>slow_path</code> clones a new object<br> <img src="/2022/05/21/Programming/Java/ModernGC/SGC_02.png" alt="SGC_02" loading="lazy"></li>
<li>Application updates the forward pointer, the ongoing GC copy will skip resetting forward pointer when finding the forward pointer set already.<br> <img src="/2022/05/21/Programming/Java/ModernGC/SGC_03.png" alt="SGC_03" loading="lazy"></li>
<li>Application update reference automatically when meeting a valid forward pointer<br> <img src="/2022/05/21/Programming/Java/ModernGC/SGC_04.png" alt="SGC_04" loading="lazy"></li>
</ol>
</blockquote>
<h2 id="ZGC-Production-X64-JDK17"><a href="#ZGC-Production-X64-JDK17" class="headerlink" title="ZGC (Production X64 JDK17)"></a>ZGC (Production X64 JDK17)</h2><p>(Introduced in JDK11, production in <code>64bits</code> JDK17)</p>
<p>ZGC and SGC are like a twin, but ZGC works different on managing the object state. Since 64 bits system has some reserved bits, ZGC could involve more efficient methods.</p>
<blockquote>
<p>ZGC is not the upgraded version of SGC. Actually, ZGC was introduced before SGC and they are maintained by different teams(ZGC - ORCALE, SGC - RedHat). ZGC and SGC share the similar design and we could regard SGC as a adaptable version for 32bit and legacy JDK.</p>
</blockquote>
<h3 id="Compared-with-SGC"><a href="#Compared-with-SGC" class="headerlink" title="Compared with SGC"></a>Compared with SGC</h3><ul>
<li><p>Fine-grained Region ~ ZPages </p>
<ul>
<li>Small (2 MiB - object size up to 256 KiB)</li>
<li>Medium (32 MiB - object size up to 4 MiB)</li>
<li>Large (4+ MiB - object size &gt; 4 MiB)</li>
</ul>
</li>
<li><p>Mark objects with colored pointers:<br>Uses 4 reserved bits from 64-bits address to represent the state of the object.<br><img src="/2022/05/21/Programming/Java/ModernGC/color_bits.png" alt="x" loading="lazy"></p>
<ul>
<li>MultiMapping<br><img src="/2022/05/21/Programming/Java/ModernGC/multi_mapping.png" alt="multi_mapping" loading="lazy"><blockquote>
<p>Note: some memory indicators(<code>RSS</code>) may get several times size as it takes 3 virtual address. We’d better use PSS to track memory usage.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Load barrier with color bits</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">f</span> <span class="operator">=</span> obj.field;</span><br><span class="line"><span class="keyword">if</span> (addr_of(f) &amp; wrong_gc_color) &#123; <span class="comment">//Wrong color =&gt; take action</span></span><br><span class="line">  slow_path() <span class="comment">// do something with STW to handle GC races</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="How-to-Choose-GC"><a href="#How-to-Choose-GC" class="headerlink" title="How to Choose GC"></a>How to Choose GC</h1><h2 id="Compatibility"><a href="#Compatibility" class="headerlink" title="Compatibility"></a>Compatibility</h2><ul>
<li>Parallel: default for JDK (&lt;&#x3D;)8</li>
<li>CMS: introduced in JDK 5, removed in JDK14</li>
<li>G1: default in JDK 9</li>
<li>ZGC: production in 64-bits JDK 17</li>
<li>SGC: support all JDK with LTS versions(8,11,17)</li>
</ul>
<h2 id="Useful-GC-Parameters"><a href="#Useful-GC-Parameters" class="headerlink" title="Useful GC Parameters"></a>Useful GC Parameters</h2><ul>
<li><p>Common GC parameters</p>
<ul>
<li><code>-Xms</code>: min heap size </li>
<li><code>-Xmx</code>: max heap size </li>
<li><code>-XX:ConcGCThreads</code>: the number of threads in concurrent process</li>
<li><code>-XX:ParallelGCThreads</code>: the number of threads in STW process</li>
<li><code>-XX:SoftRefLRUPolicyMSPerMB</code>: impact the early release of soft reference.</li>
</ul>
</li>
<li><p>Parallel New</p>
<ul>
<li><code>-XX:MaxTenuringThreshold</code>: specifies for how many minor GC cycles an object will stay in the survivor spaces until it finally gets tenured into the old space.</li>
<li><code>-XX:SurvivorRatio</code>(8 by default): the ratio of Eden size to Survivor size.</li>
<li><code>-XX:MaxNewSize</code>, <code>-XX:NewSize</code>: the size of the new generation</li>
</ul>
</li>
<li><p>G1</p>
<ul>
<li><strong><code>-XX:MaxGCPauseMillis</code></strong>: It’s the most important parameter for G1, G1 will adjust young generation size(-XX:G1NewSizePercent) automatically according to real pause time.</li>
</ul>
</li>
<li><p>ZGC, SGC:</p>
<ul>
<li>Aha, maybe it’s enough to set common GC parameters in most cases.</li>
</ul>
</li>
<li><p>GC log print &amp; analysis</p>
<ul>
<li><code>-XX:+PrintGC</code></li>
<li><code>-XX:+PrintGCTimeStamps</code></li>
<li><code>-XX:+PrintGCDetails</code></li>
<li><code>-Xloggc</code>: gc file</li>
</ul>
</li>
</ul>
<blockquote>
<p>Suggest to use third-party GC visual tool to review GC log, such as <a href="https://gceasy.io/">GCeasy</a></p>
</blockquote>
<h2 id="No-Universal-GC"><a href="#No-Universal-GC" class="headerlink" title="No Universal GC"></a>No Universal GC</h2><p><img src="/2022/05/21/Programming/Java/ModernGC/universal_gc.png" loading="lazy"></p>
<ul>
<li>Sensitive to worst or P99 pause(&lt;10ms). e.g. web serivces, real-time big-data system<ul>
<li>ZGC for 64bit system</li>
<li>SGC for legacy JDK(8,11,16) or 32-bit system</li>
</ul>
</li>
<li>has very strict and clear pause-time goals and a modest overall throughput<ul>
<li>G1<code>?</code></li>
</ul>
</li>
<li>Requires high throughput but does not care about the worst pause. e.g. batch task <ul>
<li>Parallel, CMS<code>?</code></li>
</ul>
</li>
</ul>
<p><strong>Note: I mark G1, Parallel, CSM with <code>?</code>, as overload is related the cpu load&#x2F;usage but may not stands for the reduction of throughput.</strong></p>
<blockquote>
<p>Benchmark: Quick glance at Cassandra<br>RI &#x3D; read-intensive (75% read, 25% write)</p>
<ul>
<li>Througput<br><img src="/2022/05/21/Programming/Java/ModernGC/bench_throughput.png" loading="lazy"></li>
<li>Pause<br><img src="/2022/05/21/Programming/Java/ModernGC/bench_latency.png" loading="lazy"></li>
</ul>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://wiki.openjdk.org/display/zModernGC/Main">ZGC wiki</a></li>
<li><a href="https://wiki.openjdk.org/display/shenandoah">SGC wiki</a></li>
<li><a href="https://www.youtube.com/watch?v=WU_mqNBEacw">ZGC+SGC youtube</a></li>
<li><a href="https://rodrigo-bruno.github.io/mentoring/77998-Carlos-Goncalves_dissertacao.pdf">A Performance Comparison of Modern Garbage Collectors for Big Data Environments</a></li>
<li><a href="https://tech.meituan.com/2020/11/12/java-9-cms-gc.html">Java中9种常见的CMS GC问题分析与解决</a></li>
<li><a href="https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html">新一代垃圾回收器ZGC的探索与实践 - 美团技术团队</a></li>
</ul>
<!-- https://assets.ctfassets.net/oxjq45e8ilak/709UsobBpBGHxaZ0z6MNvH/1d75677b26f1b7c9a71150c372645ad8/100746_367617808_Simone_Bordet_Concurrent_Garbage_collectors_ZGC__Shenandoah.pdf -->

<!-- 
SGC1.0 https://www.youtube.com/watch?v=E1M3hNlhQCg
 -->

<!-- Shenandoah GC - Version 2.0 (2019): The Great Revolution : https://shipilev.net/talks/jugbb-Sep2019-shenandoah.pdf -->




<!-- http://cr.openjdk.java.net/~pliden/slides/ZGC-PLMeetup-2019.pdf -->

]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title>非对称加密之PKI体系</title>
    <url>/2020/03/10/System%20Design/Network/RSA_PKI_encrypt/</url>
    <content><![CDATA[<h2 id="加密算法简述"><a href="#加密算法简述" class="headerlink" title="加密算法简述"></a>加密算法简述</h2><p>所谓加密算法就是指将信息变成密文的计算方法。 可以很简单也可以很复杂。有的加密算法就是对信息进行简单的替换和乱序， 这种加密算法最明显的缺陷就是算法本身必须保证是保密的。<br>现代加密算法通常需要密匙来完成对信息的加密运算， 算法本身是可以公开的，只要保证密匙的安全就能保存信息的安全。</p>
<p>基于密匙的加密算法可以分为两大类: </p>
<ul>
<li>对称加密算法：<br>加密数据和解密数据都是用的同一个密匙。缺点是密钥不安全。如AES</li>
<li>非对称加密算法:<br>密匙分为公钥和私钥，公钥大多数情况下用来加密数据， 私钥大多数情况下用来解密数据； 不能从公钥推导出私钥； 任何人都可以拥有公钥，都可以用来加密数据， 只有拥有私钥的人才能将信息解密。安全,但是速度比对称加密慢.</li>
</ul>
<h2 id="PKI-公开密匙体"><a href="#PKI-公开密匙体" class="headerlink" title="PKI 公开密匙体"></a>PKI 公开密匙体</h2><h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><ul>
<li>PKI：Public Key Infrastructure，公钥基础设施。不是协议,只是一个比较泛的体系基础概念.</li>
<li>CA：Certificate Of Authority，认证中心。</li>
<li>RSA: 当今使用最为广泛的非对称加密算法。</li>
<li>数字证书：提供了一种发布公钥的简便途径；</li>
<li>一个数字证书包括：拥有者身份信息、公钥、CA数字签名、有效期等其他信息。</li>
<li>数字签名：用来确认信息发送者的身份，保证信息的完整性和抗否认性。</li>
</ul>
<h3 id="RSA-非对称加密解密理论基础"><a href="#RSA-非对称加密解密理论基础" class="headerlink" title="RSA 非对称加密解密理论基础"></a>RSA 非对称加密解密理论基础</h3><p>只能说打个比方, 如果加密就是将信息放入锁盒， 解密就是用钥匙打开。</p>
<ul>
<li>公钥是公开的锁盒,谁都买得到相同的,看得到,摸得到. 大家发送消息就是把消息装进锁盒（加密）,送出去.</li>
<li>私钥是私藏的钥匙,每一个锁盒只有对应的私钥才能打开锁盒,拿到里面的信息.</li>
</ul>
<p><strong>注： 实际使用中没有规定公钥必须加密，因为原理上也允许公钥加密，私钥加密。 公钥私钥在加密体系中并无区别，只是能被公开访问的是公钥， 私密持有的是私钥</strong></p>
<!-- 而实际基于原理，并非 -->

<p>但是具体实现原理,我数学不好,建议看阮一峰的博文</p>
<ul>
<li>数学基础知识: <a href="http://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html">RSA算法原理（一</a></li>
<li>加密解密过程: <a href="http://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html">RSA算法原理（二）</a></li>
</ul>
<h3 id="签名与数字证书的区别"><a href="#签名与数字证书的区别" class="headerlink" title="签名与数字证书的区别"></a>签名与数字证书的区别</h3><ul>
<li>加密，是指对某个内容加密，加密后的内容还可以通过解密进行还原。 </li>
<li>签名，是在信息的后面再加上一段内容，可以证明信息没有被修改过。一般是根据信息计算得到一个hash值（即为<code>数字摘要</code>)。信息解密后，通过新hash需要和原hash是否一致判断信息是否修改。</li>
<li>数字证书,由受信任的CA颁布, 在网上公开,包含签名(防止被篡改), 内含有公钥, 用于证明该公钥的确是该单位的。</li>
</ul>
<h3 id="Tradeoff"><a href="#Tradeoff" class="headerlink" title="Tradeoff"></a>Tradeoff</h3><p>非对称加密速递慢不适合用于大量的数据加密传输。 为了实现数据的加密传输， 非对称加密需要和对称加密结合使用， 即</p>
<ul>
<li>非对称负责对称密匙交换,也叫<code>对话密钥(session key)</code> &#x3D;&gt; 提高安全性</li>
<li>对称加密算法负责实际的数据加密 &#x3D;&gt; 提高传输效率</li>
</ul>
<p>接下来就要讨论各种主流的通信协议</p>
<h3 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h3><p>常用于服务器通信,只涉及客户端和服务端. 有一个服务器在互联网的另一头，你需要远程登录到服务器来执行一些命令配置这台服务器。这个时候你和服务器之间就需要有数据通信。假设客户端叫A，服务器叫B。</p>
<p>流程:</p>
<ol>
<li>A、B之间建立TCP连接</li>
<li>B生成一对公私密钥</li>
<li>B把公钥发送给A</li>
<li>A生成一个用于加密数据的对称密钥K（既我们想通知给客户端的密钥，之后的数据通信都使用这个密钥加密，这个密钥不可让第三方知道）</li>
<li>A把K用公钥加密发送给B，B解密后，从此A、B之间的通信数据都用K密钥进行加密和解密。</li>
</ol>
<p>看上去是完美无瑕的,但是设计时候要考虑任何信息被掉包的情况,比如B被黑客C劫持, 发过来的公钥其实是C的,之后A发送的消息也被C截获,那么K就泄露给了C, 就GG了.</p>
<p>所以我们在登陆SSH的时候,通常会看到人工确认信息</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">The authenticity of host <span class="string">&#x27;xxx.xxx.xxx.xxx (&lt;no hostip for proxy command&gt;)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">RSA key fingerprint is 23:42:c1:e4:3f:d2:cc:37:1d:89:cb:e7:5d:be:5d:53.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? </span></span><br></pre></td></tr></table></figure>
<p>这是希望客户端A<strong>人为</strong>去验证一下登陆的服务器是不是B。显然这种方法只适合对服务器熟悉的场合才能使用,而且需要额外确认, 在广大大众上网时候,许多网站都是陌生的,所以这个方法就存留在了程序员的远程登陆</p>
<h3 id="TLS-x2F-SSL（Secure-Sockets-Layer）"><a href="#TLS-x2F-SSL（Secure-Sockets-Layer）" class="headerlink" title="TLS&#x2F;SSL（Secure Sockets Layer）"></a>TLS&#x2F;SSL（Secure Sockets Layer）</h3><p>SSL和TLS基本一致,就一起讲。<br>在SSL协议中引入了一种类似公共机关（类似于我国的国家公证处）的概念，就是我们熟知的CA(数字证书认证机构),为站点发送数字证书, 来证明服务器可信.</p>
<p>其大致流程相比于SSH,其实多了一步提前验证服务器。整体可以看成四个阶段<br><img src="/2020/03/10/System%20Design/Network/RSA_PKI_encrypt/1.png" alt="xx" loading="lazy"></p>
<h4 id="单向与双向"><a href="#单向与双向" class="headerlink" title="单向与双向"></a>单向与双向</h4><p>具体地, 根据对客户端的验证成都, 又可以分为单向和双向.</p>
<ul>
<li>单向SSL<br><img src="/2020/03/10/System%20Design/Network/RSA_PKI_encrypt/single_direction_ssl.png" alt="2022-11-22T171948" loading="lazy"></li>
</ul>
<p>第3步需要服务端的CA数字证书验证服务端</p>
<ul>
<li>双向SSL<br><img src="/2020/03/10/System%20Design/Network/RSA_PKI_encrypt/bidirectional_ssl.png" alt="2022-11-22T172233" loading="lazy"></li>
</ul>
<p>第3步需要CA的数字证书验证服务端, 第5步验证客户端</p>
<ul>
<li>场景对比<ul>
<li>SSL单向认证只要求站点部署了SSL证书就行，任何用户都可以去访问（IP被限制除外) 一般web应用都是单向的</li>
<li>SSL双向认证则是需要服务端与客户端提供身份认证，只能是服务端允许的客户去访问，安全性相对高一些。常用于内网权限限制, 企业应用对接等.</li>
</ul>
</li>
</ul>
<h3 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h3><p>&#x3D; HTTP+ SSL</p>
<p>所以会导致原本就慢的握手阶段,更加慢.</p>
<!-- TODO 换成本地图片 -->
<!-- #### 利用非对称加密进行通信
1.  用户1 生产随机的secrect key1
使用用户1的公钥对secrect key1进行加密， 然后传递给用户2
用户2接收到加密的secrect key1， 使用对应的私钥进行解密，得到secrect key1
用户2 生产随机的secrect key2
使用用户2的公钥对secrect key2进行加密， 然后传递给用户1
用户1接收到加密的secrect key2， 使用对应的私钥进行解密，得到secrect key2
用户1和用户2就可以使用secrect key1, secrect key2进行加解密

作者：llpy
链接：https://www.jianshu.com/p/c0fdd72faa82
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 -->



<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p><a href="https://www.jianshu.com/p/c65fa3af1c01">PKI&#x2F;CA工作原理及架构</a></p>
<p><a href="https://www.jianshu.com/p/194f787998c1">使用多个ssh public key</a></p>
<p><a href="https://www.jianshu.com/p/29a90d057510">HTTP+SSL&#x3D; HTTPS</a></p>
<p><a href="https://blog.csdn.net/zanghuayiren/article/details/88530121">笔记——PKI基础（二）</a></p>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Network</category>
      </categories>
  </entry>
  <entry>
    <title>Network TCP/UDP</title>
    <url>/2018/12/10/System%20Design/Network/network_tcp/</url>
    <content><![CDATA[<p>这篇文章有待改进，内容还有比较多的内容需要补全。想要了解的建议直接移步reference。<br>The blog is to be continued.</p>
<h2 id="layer"><a href="#layer" class="headerlink" title="layer"></a>layer</h2><p><img src="/2018/12/10/System%20Design/Network/network_tcp/layer.png" loading="lazy"></p>
<h2 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h2><p><img src="/2018/12/10/System%20Design/Network/network_tcp/UDP.png" loading="lazy"></p>
<ul>
<li>保证正确性(cksum)</li>
<li>不保证顺序</li>
<li>不保证送达</li>
<li>资源占用少</li>
<li>包头短</li>
<li>无状态（无连接）</li>
</ul>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p><img src="/2018/12/10/System%20Design/Network/network_tcp/TPC.png" loading="lazy"></p>
<h3 id="Logic"><a href="#Logic" class="headerlink" title="Logic"></a>Logic</h3><p><img src="/2018/12/10/System%20Design/Network/network_tcp/TCP_stats.png" loading="lazy"></p>
<h3 id="transfer-control"><a href="#transfer-control" class="headerlink" title="transfer control"></a>transfer control</h3><ul>
<li><p>retransmission </p>
<ul>
<li>fast retransmission due to 3 Acknowledgement Duplicates： </li>
<li>timeout</li>
</ul>
</li>
<li><p>time adjustment: when accept each packet</p>
</li>
</ul>
<h3 id="problem"><a href="#problem" class="headerlink" title="problem"></a>problem</h3><!-- TODO 语言优化 -->
<ul>
<li>为什么建立要3次，断开要4次？ <ul>
<li>建立：确保client端开启。</li>
<li>关闭: 当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。</li>
</ul>
</li>
<li>为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？<ul>
<li>保证TCP协议的全双工连接能够可靠关闭</li>
<li>保证这次连接的重复数据段从网络中消失</li>
</ul>
</li>
</ul>
<h3 id="transfer-Sliding-windows"><a href="#transfer-Sliding-windows" class="headerlink" title="transfer - Sliding windows"></a>transfer - Sliding windows</h3><ul>
<li>目的：凭借小范围的乱序提升性能，减少阻塞时间, 速度控制</li>
</ul>
<h4 id="sender"><a href="#sender" class="headerlink" title="sender"></a>sender</h4><ul>
<li>Sent and Acknowledged：这些数据表示已经发送成功并已经被确认的数据，比如图中的前31个bytes，这些数据其实的位置是在窗口之外了，因为窗口内顺序最低的被确认之后，要移除窗口，实际上是窗口进行合拢，同时打开接收新的带发送的数据</li>
<li>Send But Not Yet Acknowledged：这部分数据称为发送但没有被确认，数据被发送出去，没有收到接收端的ACK，认为并没有完成发送，这个属于窗口内的数据。</li>
<li>Not Sent，Recipient Ready to Receive：这部分是尽快发送的数据，这部分数据已经被加载到缓存中，也就是窗口中了，等待发送，其实这个窗口是完全有接收方告知的，接收方告知还是能够接受这些包，所以发送方需要尽快的发送这些包</li>
<li>Not Sent，Recipient Not Ready to Receive： 这些数据属于未发送，同时接收端也不允许发送的，因为这些数据已经超出了发送端所接收的范围</li>
</ul>
<p><img src="/2018/12/10/System%20Design/Network/network_tcp/sender_window.png" loading="lazy"></p>
<h4 id="receiver"><a href="#receiver" class="headerlink" title="receiver"></a>receiver</h4><ul>
<li>Received and ACK Not Send to Process：这部分数据属于接收了数据但是还没有被上层的应用程序接收，也是被缓存在窗口内</li>
<li>Received Not ACK: 已经接收并，但是还没有回复ACK，这些包可能输属于Delay ACK的范畴了</li>
<li>Not Received：有空位，还没有被接收的数据。</li>
</ul>
<h3 id="Congestion-Control"><a href="#Congestion-Control" class="headerlink" title="Congestion Control"></a>Congestion Control</h3><ul>
<li>Congestion Avoidance Phase : additive increment</li>
<li>Congestion Detection Phase : multiplicative decrement <ul>
<li>by Retransmission due to Timeout</li>
<li>Retransmission due to 3 Acknowledgement Duplicates</li>
</ul>
</li>
</ul>
<blockquote>
<p>The above default congestion is loss-based congestion control, which is designed for stable network and small buffer.<br>There are another congestion control(BBR) which works for long-distance network and larger buffer, like cross-nation communication(e.g. VPN proxy).<br>BBR considers how fast the network is delivering data. For a given network connection, it uses recent measurements of the network’s delivery rate and round-trip time to build an explicit model that includes both the maximum recent bandwidth available to that connection, and its minimum recent round-trip delay.<br><a href="https://cloud.google.com/blog/products/networking/tcp-bbr-congestion-control-comes-to-gcp-your-internet-just-got-faster">https://cloud.google.com/blog/products/networking/tcp-bbr-congestion-control-comes-to-gcp-your-internet-just-got-faster</a></p>
</blockquote>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="https://www.cnblogs.com/xiehongfeng100/p/4605765.html">https://www.cnblogs.com/xiehongfeng100/p/4605765.html</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#%E5%B0%81%E5%8C%85%E7%B5%90%E6%A7%8B">https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#%E5%B0%81%E5%8C%85%E7%B5%90%E6%A7%8B</a></li>
<li><a href="https://github.com/ohEmily/tcp-emulator-python/blob/master/TCP_Segment.py">https://github.com/ohEmily/tcp-emulator-python/blob/master/TCP_Segment.py</a></li>
<li><a href="https://blog.csdn.net/libo222/article/details/52252505?locationNum=10">https://blog.csdn.net/libo222/article/details/52252505?locationNum=10</a></li>
<li><a href="https://hit-alibaba.github.io/interview/basic/network/TCP.html">https://hit-alibaba.github.io/interview/basic/network/TCP.html</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Network</category>
      </categories>
  </entry>
  <entry>
    <title>Linux I/O Model</title>
    <url>/2020/01/03/System%20Design/Linux/Linux_IO/</url>
    <content><![CDATA[<h2 id="Linux-IO-Model"><a href="#Linux-IO-Model" class="headerlink" title="Linux IO Model"></a>Linux IO Model</h2><h3 id="Buffered-IO-default-96"><a href="#Buffered-IO-default-96" class="headerlink" title="Buffered IO (default)&#96;"></a>Buffered IO (default)&#96;</h3><p>alias: normal IO</p>
<h4 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h4><p>A read process could be divided into 2 stages:</p>
<ol>
<li>Waiting for the data (from disk or network) to be ready in kernel <code>page cache</code> ( load disk data through DMA )</li>
<li>Copying the data from the kernel to the process</li>
</ol>
<h4 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h4><p>Write back Model.</p>
<h3 id="Direct-IO"><a href="#Direct-IO" class="headerlink" title="Direct IO"></a>Direct IO</h3><h4 id="Read-1"><a href="#Read-1" class="headerlink" title="Read"></a>Read</h4><p>Only 1 stage: loading data into process space by DMA</p>
<h4 id="Write-1"><a href="#Write-1" class="headerlink" title="Write"></a>Write</h4><p>direct write to disk.</p>
<h3 id="Comparsion"><a href="#Comparsion" class="headerlink" title="Comparsion"></a>Comparsion</h3><ul>
<li>Buffered beats Direct<ol>
<li>decoupling disk and process</li>
<li>reduce IO reads</li>
</ol>
</li>
<li>Direct beats Buffered<ol>
<li>self-caching applications (e.g. database) work with their own cache management.  </li>
<li>Avoid memory copy between kernel space and user space</li>
</ol>
</li>
</ul>
<h2 id="IO-Model"><a href="#IO-Model" class="headerlink" title="IO Model"></a>IO Model</h2><p>We talk about the IO model about buffered Reading in the following.</p>
<h3 id="IO-Model-Matrix"><a href="#IO-Model-Matrix" class="headerlink" title="IO Model Matrix"></a>IO Model Matrix</h3><table>
<thead>
<tr>
<th></th>
<th>Blocking(阻塞)</th>
<th>Non-blocking(非阻塞)</th>
</tr>
</thead>
<tbody><tr>
<td>Synchronous(同步)</td>
<td>1.Blocking IO(default socket, file read&#x2F;write) <br></td>
<td>2. non-blocking IO</td>
</tr>
<tr>
<td>Asynchronous(异步)</td>
<td>3. IO multiplexing (select, epoll, poll)</td>
<td>4.AIO</td>
</tr>
</tbody></table>
<h3 id="Block-vs-Sync"><a href="#Block-vs-Sync" class="headerlink" title="Block vs Sync"></a>Block vs Sync</h3><p>They are discussed on two indepedent dimensions.</p>
<h4 id="Sync-x2F-Async"><a href="#Sync-x2F-Async" class="headerlink" title="Sync &#x2F; Async"></a>Sync &#x2F; Async</h4><p>Determined by communication (function call is request, return value is response).</p>
<!-- 或者说需不需要主动check -->
<ol>
<li>Sync: Each function call returns a response. </li>
<li>Aysnc: Each function call returns with nothing. The response will be sent back later.</li>
</ol>
<h4 id="blocking-x2F-non-blocking"><a href="#blocking-x2F-non-blocking" class="headerlink" title="blocking &#x2F; non-blocking"></a>blocking &#x2F; non-blocking</h4><p>Determined by whether the process need to wait</p>
<ol>
<li>blocked: process need to wait until function completed</li>
<li>unblocked: process could do other things</li>
</ol>
<h3 id="Typical-IO-Model"><a href="#Typical-IO-Model" class="headerlink" title="Typical IO Model"></a>Typical IO Model</h3><h4 id="Blocking-IO-Blocking-Sync"><a href="#Blocking-IO-Blocking-Sync" class="headerlink" title="Blocking IO (Blocking + Sync)"></a>Blocking IO (Blocking + Sync)</h4><p>The application blocks until the system call is complete (data transferred or error). </p>
<p>The two stages are blocked.</p>
<!-- ![](Linux_IO/bsio.png) -->
<p><img src="/2020/01/03/System%20Design/Linux/Linux_IO/bsio.gif" loading="lazy"></p>
<h5 id="e-g"><a href="#e-g" class="headerlink" title="e.g."></a>e.g.</h5><ul>
<li>socket</li>
<li>stream IO</li>
<li>normal read&#x2F;write</li>
</ul>
<h5 id="pros-amp-cons"><a href="#pros-amp-cons" class="headerlink" title="pros &amp; cons"></a>pros &amp; cons</h5><ul>
<li>pros:<ul>
<li>no delay</li>
<li>easy for developing</li>
</ul>
</li>
<li>cons:<ul>
<li>inefficient</li>
</ul>
</li>
</ul>
<h4 id="Non-blocking-IO-non-Blocking-Sync"><a href="#Non-blocking-IO-non-Blocking-Sync" class="headerlink" title="Non-blocking IO (non-Blocking + Sync)"></a>Non-blocking IO (non-Blocking + Sync)</h4><p>This model requires numerous calls (polling 轮循) to await completion.</p>
<!-- ![](Linux_IO/nsio.png) -->
<p><img src="/2020/01/03/System%20Design/Linux/Linux_IO/ubs.gif" loading="lazy"></p>
<h5 id="e-g-1"><a href="#e-g-1" class="headerlink" title="e.g."></a>e.g.</h5><ul>
<li>java NIO</li>
<li>read&#x2F;write with <code>O_NONBLOCK</code> flag</li>
</ul>
<h5 id="pros-amp-cons-1"><a href="#pros-amp-cons-1" class="headerlink" title="pros &amp; cons"></a>pros &amp; cons</h5><ul>
<li>pros<ul>
<li>do other things when waiting for data ready</li>
</ul>
</li>
<li>cons<ul>
<li>larger latency because it can’t not read data immediatly when data is ready in kernel.</li>
</ul>
</li>
</ul>
<h4 id="IO-multiplexing-Block-Async"><a href="#IO-multiplexing-Block-Async" class="headerlink" title="IO multiplexing (Block + Async)"></a>IO multiplexing (Block + Async)</h4><p>similiar to nonblocking IO, the only difference is that “other things” is listening other IO channels.<br><img src="/2020/01/03/System%20Design/Linux/Linux_IO/iomul.gif" loading="lazy"></p>
<h5 id="e-g-2"><a href="#e-g-2" class="headerlink" title="e.g."></a>e.g.</h5><p>select, poll, epoll </p>
<h5 id="pros-amp-cons-2"><a href="#pros-amp-cons-2" class="headerlink" title="pros &amp; cons"></a>pros &amp; cons</h5><ul>
<li>pros<ul>
<li>single thread listens multiple IO channels, no context switch overhead<!-- - selector has a size limit poll 放开了1024的限制 epoll 完全完成前2者的问题，但是只有linux有， --></li>
</ul>
</li>
<li>cons<ul>
<li>additional system call <code>select</code> for each read</li>
</ul>
</li>
</ul>
<h4 id="Asynchronous-non-blocking-I-x2F-O-non-Blocking-Async"><a href="#Asynchronous-non-blocking-I-x2F-O-non-Blocking-Async" class="headerlink" title="Asynchronous non-blocking I&#x2F;O  (non-Blocking + Async)"></a>Asynchronous non-blocking I&#x2F;O  (non-Blocking + Async)</h4><p>The read request returns immediately, indicating that the read was successfully initiated. The application can then perform other processing while the background read operation completes. When the read response arrives, a signal or a thread-based callback can be generated to complete the I&#x2F;O transaction.<br><img src="/2020/01/03/System%20Design/Linux/Linux_IO/aio.gif" loading="lazy"></p>
<h5 id="e-g-3"><a href="#e-g-3" class="headerlink" title="e.g."></a>e.g.</h5><p>AIO(linux)</p>
<h4 id="Signal-Driven-IO-half-Blocking-Async"><a href="#Signal-Driven-IO-half-Blocking-Async" class="headerlink" title="Signal-Driven IO  (half-Blocking + Async)"></a>Signal-Driven IO  (half-Blocking + Async)</h4><p>uncommon model.</p>
<p>Only stage 2 is blocked.</p>
<p>Strictly speaking, it’s could be regarded as block IO.</p>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p><img src="/2020/01/03/System%20Design/Linux/Linux_IO/IO_summary.png" loading="lazy"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-directio/index.html">Linux 中直接 I&#x2F;O 机制的介绍</a></li>
<li><a href="https://www.jianshu.com/p/486b0965c296">聊聊Linux 五种IO模型</a></li>
<li><a href="https://www.cnblogs.com/LittleHann/p/3897910.html">Linux Network IO Model、Socket IO Model - select、poll、epoll</a></li>
<li><a href="https://developer.ibm.com/articles/l-async/">Boost application performance using asynchronous I&#x2F;O</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>OS Basic</title>
    <url>/2019/01/20/System%20Design/Linux/OS_basic/</url>
    <content><![CDATA[<!-- 这篇文章有待完善，之后有空了会把那手稿拍照给改成文字。
The blog is to be continued. -->


<p>The followings are decribed based on IA-64 Linux system.</p>
<h2 id="Machine-Level"><a href="#Machine-Level" class="headerlink" title="Machine Level"></a>Machine Level</h2><h3 id="Regs-in-IA-64"><a href="#Regs-in-IA-64" class="headerlink" title="Regs in IA-64"></a>Regs in IA-64</h3><ul>
<li>16 integer register (8-byte long)<ul>
<li>%rax, %rcx, %rdx, %rbx, %rsi, %rdi, %rsp, %rbp</li>
<li>%r8, %r9, %r10, %r11, %r12, %13, %r14, %r15</li>
</ul>
</li>
</ul>
<p><img src="/2019/01/20/System%20Design/Linux/OS_basic/IA_reg_1.png" loading="lazy"><br>Note: %rsp only points to stack top</p>
<ul>
<li>16 floating point register (32-byte long)<!-- TODO in 1-7-dmov --></li>
</ul>
<h3 id="Instruction"><a href="#Instruction" class="headerlink" title="Instruction"></a>Instruction</h3><p><strong>No instruction can load two address together</strong></p>
<ul>
<li><strong>push</strong> <code>S</code> (add the value in register <code>S</code> into the stack)<ul>
<li>R[%rsp] ← R[%rsp] - 8</li>
<li>M[R[%rsp]] ← S</li>
</ul>
</li>
<li><strong>pop</strong> D (pop the value from the stack top)<ul>
<li>D ← M[R[%rsp]]</li>
<li>R[%rsp] ← R[%rsp]+8</li>
</ul>
</li>
<li><strong>jmp</strong> change the %rip  (used for if,for,loop)</li>
<li><strong>call</strong> &#x3D; push + jmp<ol>
<li>push caller-registers</li>
<li>push arugments </li>
<li>push retaddr (%rip, the address of <strong>next</strong> instruction) <code> hardware</code> </li>
<li>jmp to callee address <code>by hardware</code><!-- ![](OS_basic/call.png) -->
<img src="/2019/01/20/System%20Design/Linux/OS_basic/call2.png" loading="lazy"></li>
</ol>
</li>
<li><strong>ret</strong><ol>
<li>restore callee-save registers(include %rbp)</li>
<li>pop return address from the stack <code>hardware</code></li>
<li>jmp to the return address <code>hardware</code><!-- Caller-save registers
%rax, %rdi, %rsi, %rdx, %rcx, %r8, %r9, %r10, %r11
Saved by caller
Callee can use these registers freely</li>
</ol>
</li>
</ul>
<p>The contents in these registers may be changed after return<br>Caller must restore them if it tries to use them after calling </p>
<p> Callee-save registers<br>%rbx, %rbp, %r12-15<br>Saved by callee<br>Caller can use these registers freely</p>
<p>Callee must save them before using<br>Callee must restore them before return<br>–&gt;</p>
<h3 id="union"><a href="#union" class="headerlink" title="union"></a>union</h3><p>All member within a union share the same address.<br>Value is determined by the last assignment of any member variable.</p>
<h3 id="Float-IEEE-754-Standard"><a href="#Float-IEEE-754-Standard" class="headerlink" title="Float(IEEE 754 Standard)"></a>Float(IEEE 754 Standard)</h3><ul>
<li>Encoding: <img src="/2019/01/20/System%20Design/Linux/OS_basic/float_encode.png" loading="lazy"><ul>
<li>32 bits float &#x3D;&gt; 8 exp bits, 23 frac bits</li>
<li>64 bits float &#x3D;&gt; 11 exp bits, 52 frac bits</li>
</ul>
</li>
<li>Numeria form: $V&#x3D;(-1)^S2^EM$</li>
<li>Calculation<ul>
<li>bias &#x3D; $2^{m-1} - 1$</li>
<li>Normalized Value: exp ≠ 000..000 ≠ 111..111<ul>
<li>M&#x3D;1.xx..xx (bits of frac)</li>
<li>E&#x3D;exp-Bias ∈[1-2^{m-1}, 2^{m-1}]</li>
</ul>
</li>
<li>Denormalized Value: exp &#x3D; 000.000<ul>
<li>N&#x3D;0.xx..xx</li>
<li>E&#x3D;1-Bias</li>
</ul>
</li>
<li>Special Value: exp &#x3D; 111..111<ul>
<li>frac &#x3D; 000..000 &#x3D;&gt; ∞</li>
<li>frac &#x3D; 111..111 &#x3D;&gt; NaN</li>
</ul>
</li>
</ul>
</li>
<li>summary<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/float_summary.png" loading="lazy"></li>
<li>discontinuous</li>
<li>the closer to the zero, the higher the density</li>
</ul>
<h2 id="User-and-Kernel"><a href="#User-and-Kernel" class="headerlink" title="User and Kernel"></a>User and Kernel</h2><h3 id="mode-bit"><a href="#mode-bit" class="headerlink" title="mode bit"></a>mode bit</h3><ul>
<li>kernel mode bit (ring0)<ul>
<li>execute any instruction</li>
<li>access any memory address</li>
</ul>
</li>
<li>user mode bit (ring3)<ul>
<li>do some things indirectly<ul>
<li>via <code>system call</code> interface <!-- TODO more clear -->
<img src="/2019/01/20/System%20Design/Linux/OS_basic/mode_bit.png" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h3><p><strong>Def</strong>: a shared chunk of OS code</p>
<ul>
<li><strong>not a small process, but a part of some user process</strong></li>
</ul>
<p><strong>Effect</strong>: typically use a <code>mode bit</code> to restrict an app on</p>
<ul>
<li>executing some privileged instrunctions</li>
<li>access kernel address space</li>
</ul>
<p><strong>Mode Switch</strong></p>
<ul>
<li>user -&gt; kernel<ul>
<li><strong>only when</strong> exception occurs and control passes to exception handler</li>
</ul>
</li>
<li>kernel -&gt; user<ul>
<li>when control returns to the user code<!-- ![](OS_basic/kernel_user.jpg) --></li>
</ul>
</li>
</ul>
<p><strong>Context Switches</strong></p>
<ul>
<li>kernel maintains the states for kernel to restart a preempted process including<ol>
<li>value of PC</li>
<li>register file</li>
<li>status registers</li>
<li>user stack</li>
<li>kernel stack</li>
<li>kernel data status<ol>
<li>process table</li>
<li>page table</li>
<li>filetable</li>
<li>…<!-- TODO UNDERSTAND MORE --></li>
</ol>
</li>
</ol>
</li>
</ul>
<h2 id="Excepetional-Control-Flow"><a href="#Excepetional-Control-Flow" class="headerlink" title="Excepetional Control Flow"></a>Excepetional Control Flow</h2><ul>
<li>mechanism<ul>
<li>low level: <ul>
<li>exceptions (implemented by hardware and OS software)</li>
</ul>
</li>
<li>high level:<ul>
<li>e.g. <ul>
<li>process context switch (implemented by OS software)</li>
<li>signals  (implemented by OS software)</li>
<li>nolocal jump (long jump, by C language runtime laibrary)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>handle exception process<!-- ![](OS_basic/exception_process.png) -->
<img src="/2019/01/20/System%20Design/Linux/OS_basic/exception_process_2.png" loading="lazy"> <!-- exception handler
1. processor pushes a return address on kernel stack
2. 
  =-  --></li>
<li>exception table<!-- ![](OS_basic/exception1.jpg) -->
<img src="/2019/01/20/System%20Design/Linux/OS_basic/exception_table.png" loading="lazy"><br><img src="/2019/01/20/System%20Design/Linux/OS_basic/exception_table2.png" loading="lazy"><!-- ![](OS_basic/exception2.jpg) --></li>
<li>exception classes <ul>
<li><p>Interrupt - Signal from I&#x2F;O device - Async - Always returns to next instruction<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/interrupt_handle.png" loading="lazy"></p>
</li>
<li><p>Trap - Intentional exception - Sync - Always returns to next instructio</p>
</li>
</ul>
</li>
</ul>
<p><img src="/2019/01/20/System%20Design/Linux/OS_basic/trap_handle.png" loading="lazy"></p>
<ul>
<li><p>Fault - Potentially recoverable error - Sync - Might return to current instruction<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/fault_handle.png" loading="lazy"></p>
</li>
<li><p>Abort - Nonrecoverable error - Sync - Never returns<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/abort.png" loading="lazy"></p>
</li>
</ul>
<h2 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h2><h3 id="Order"><a href="#Order" class="headerlink" title="Order"></a>Order</h3><p>主机序（Host Order）就是遵循Little-Endian规则.所以当两台主机之间要通过TCP&#x2F;IP协议进行通信的时候就需要调用相应的函数进行主机序（Little-Endian）和网络序（Big-Endian）的转换</p>
<ul>
<li>XX-Endian是指原内容中XX部分在尾部地址存储</li>
<li>Little-Endian： easy to cast, does not need to change address</li>
<li>Big-Endian：easy to compute the decimal value, in line with human intuition</li>
<li>e.g. 0x12345678<ul>
<li>little endian (Intel)<table>
<thead>
<tr>
<th>内存地址</th>
<th>0x4000</th>
<th>0x4001</th>
<th>0x4002</th>
<th>0x4003</th>
</tr>
</thead>
<tbody><tr>
<td>存放内容</td>
<td>0x78</td>
<td>0x56</td>
<td>0x34</td>
<td>0x12</td>
</tr>
</tbody></table>
</li>
<li>big endian (Sum,IBM,network)<table>
<thead>
<tr>
<th>内存地址</th>
<th>0x4000</th>
<th>0x4001</th>
<th>0x4002</th>
<th>0x4003</th>
</tr>
</thead>
<tbody><tr>
<td>存放内容</td>
<td>0x12</td>
<td>0x34</td>
<td>0x56</td>
<td>0x78</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li>check code<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">IsCPULittleEndian</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">union</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">int</span> i;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">char</span> c;</span><br><span class="line">    &#125;u;</span><br><span class="line">    u.i = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> (u.c == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Physical-Cache"><a href="#Physical-Cache" class="headerlink" title="Physical Cache"></a>Physical Cache</h3><p>we take the set associative cache as an example.<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/cache_in_csapp.png" loading="lazy"></p>
<ul>
<li>parameters<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/parameters.png" loading="lazy"></li>
<li>set selection<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/physical_cache_set.png" loading="lazy"></li>
<li>must compare the tag in each valid line in the selected set.<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/physical_cache.png" loading="lazy"></li>
</ul>
<h4 id="Core-i7-Structre"><a href="#Core-i7-Structre" class="headerlink" title="Core i7 Structre"></a>Core i7 Structre</h4><p><img src="/2019/01/20/System%20Design/Linux/OS_basic/I7.png" loading="lazy"></p>
<h4 id="Cache-Coherency"><a href="#Cache-Coherency" class="headerlink" title="Cache Coherency"></a>Cache Coherency</h4><ol>
<li>Snooping Solution<ul>
<li>Send all requests for data to all processors</li>
<li>Works well with bus (natural broadcast medium)</li>
</ul>
</li>
<li>Directory-Based Schemes<ul>
<li>Keep track of what is being shared in one centralized place</li>
<li>Scales better than Snoop</li>
</ul>
</li>
</ol>
<h3 id="virtual-memory-hierarchy"><a href="#virtual-memory-hierarchy" class="headerlink" title="virtual memory hierarchy"></a>virtual memory hierarchy</h3><p><img src="/2019/01/20/System%20Design/Linux/OS_basic/mem_hierarchy.png" loading="lazy"></p>
<!-- ![](OS_basic/mem_structre.png) -->
<ul>
<li>read-write (global)<ul>
<li>.data(initialized global variable) </li>
<li>.bss(uninitialized global variabel)<!-- - TODO? --></li>
</ul>
</li>
<li>read only data<ul>
<li>e.g. constant, const string,</li>
</ul>
</li>
<li>read only code(below the data)<ul>
<li>machine code of the compiled program</li>
</ul>
</li>
</ul>
<h4 id="VA-to-PA"><a href="#VA-to-PA" class="headerlink" title="VA to PA"></a>VA to PA</h4><ul>
<li>VA<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/va.png" loading="lazy"></li>
<li>MMU (memory management unit in CPU)<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/VA2PAMMU.png" loading="lazy"></li>
<li>multi level(64 support 4 level)<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/pagetable_multilevel.png" loading="lazy"></li>
</ul>
<h4 id="page-table"><a href="#page-table" class="headerlink" title="page table"></a>page table</h4><ul>
<li>kernel maintian a page table for each process</li>
<li>CR3 points to page table</li>
<li>mapping from virtual pages to physical address(<strong>memory or disk</strong>)</li>
<li>store in physical memory</li>
</ul>
<h3 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h3><ul>
<li>inside MMU</li>
<li>a cache for page table<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/tlb1.png" loading="lazy"></li>
<li>to skip page table work through if TLB hit</li>
<li>structure like Physical Cache<br><img src="/2019/01/20/System%20Design/Linux/OS_basic/TLB2.png" loading="lazy"></li>
</ul>
<h4 id="PAGE-FAULT-SEGMENTATION-FAULT"><a href="#PAGE-FAULT-SEGMENTATION-FAULT" class="headerlink" title="PAGE FAULT SEGMENTATION FAULT"></a>PAGE FAULT SEGMENTATION FAULT</h4><ul>
<li>MMU generates “page fault”, if the physical page is in disk <ul>
<li>handled by OS</li>
<li>use DMA load to memeory and change associate pointer of page table</li>
<li>and then load from memory</li>
</ul>
</li>
<li>or access some memory can not access or not exist<br>OS aborts process with “segmentation fault”</li>
</ul>
<h4 id="Cache-Algorithm"><a href="#Cache-Algorithm" class="headerlink" title="Cache Algorithm"></a>Cache Algorithm</h4><ul>
<li>FIFO<ul>
<li>link list</li>
</ul>
</li>
<li>LRU<ul>
<li>link list</li>
</ul>
</li>
<li>LFU<ul>
<li>min-heap</li>
</ul>
</li>
<li>Clock<ul>
<li>ring queue</li>
<li>Hit：通过hash快速定位，并将reference bit设置为1</li>
<li>Miss：<ol>
<li>从Head开始查找Reference bit为0 的entry</li>
<li>如果Reference bit为1，清除该位，指针前移，直到找到为0的entry为止。</li>
<li>如果Reference bit 为0， 将数据放入该entry，并将Reference bit置1。</li>
</ol>
</li>
</ul>
</li>
<li>these methods could add a hash table to quick check cahce hit but cost more space</li>
</ul>
<h2 id="Kernel-1"><a href="#Kernel-1" class="headerlink" title="Kernel"></a>Kernel</h2><p><img src="/2019/01/20/System%20Design/Linux/OS_basic/monlickernel_microkernel.png" loading="lazy"><br><img src="/2019/01/20/System%20Design/Linux/OS_basic/exo.png" loading="lazy"></p>
<ul>
<li>exokernel<br>Kernel: only protect the resources<br>Application: manage the resources</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>-《Introduction to Computer System》</p>
<ul>
<li><a href="https://people.eecs.berkeley.edu/~pattrsn/252F96/Lecture18.pdf">Lecture 18:<br>Snooping vs. Directory Based<br>Coherency</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Operating System | Compiliation Process</title>
    <url>/2019/07/10/System%20Design/Linux/OS_compile_link_symbol/</url>
    <content><![CDATA[<h2 id="Compliation-process"><a href="#Compliation-process" class="headerlink" title="Compliation process"></a>Compliation process</h2><h3 id="Process-Graph"><a href="#Process-Graph" class="headerlink" title="Process Graph"></a>Process Graph</h3><p><img src="/2019/07/10/System%20Design/Linux/OS_compile_link_symbol/process.png" loading="lazy"></p>
<h3 id="General-Description"><a href="#General-Description" class="headerlink" title="General Description"></a>General Description</h3><p><img src="/2019/07/10/System%20Design/Linux/OS_compile_link_symbol/generally_process.png" loading="lazy"></p>
<ul>
<li>General Compilation  (1,2,3)<ul>
<li>translates source code file to machine code file <strong>respectively</strong> </li>
<li>leaves undefined functions&#x2F;symbols to be filled in by linker</li>
</ul>
</li>
<li>Link <ul>
<li>links the object code with the library code to produce an executable file</li>
</ul>
</li>
</ul>
<h3 id="Specific-Description"><a href="#Specific-Description" class="headerlink" title="Specific Description"></a>Specific Description</h3><ol>
<li>Preprocessing <code>-E</code></li>
</ol>
<ul>
<li>Removal of Comments, Expansion of Macros, Expansion of the included files.</li>
<li>The lines in our code that begin with the “#” character are preprocessor directives.</li>
</ul>
<ol start="2">
<li>Compilation  <code>-S</code></li>
</ol>
<ul>
<li>translates the preprocessed code to assembly instructions specific to the target processor architecture.</li>
</ul>
<ol start="3">
<li>Assembly    <code>-c</code></li>
</ol>
<ul>
<li>translates the assembly instructions to object code. The output consists of actual instructions to be run by the target processor.</li>
<li>leaves the addresses of the external functions undefined, to be filled in later by the Linker.</li>
<li>The contents of output file is in a binary format and can be inspected using <code>hexdump</code> or <code>od</code></li>
</ul>
<ol start="4">
<li>Linking  <code>-o</code></li>
</ol>
<ul>
<li>fill in the addresses of all the external functions (to be called) with the actual definitions</li>
<li>combine object files and libraries into a single executable file, make program run.</li>
</ul>
<blockquote>
<p>Executable file: Can be loaded (copied) into memory and executed</p>
</blockquote>
<h2 id="linking-Type"><a href="#linking-Type" class="headerlink" title="linking Type"></a>linking Type</h2><h3 id="static-linking"><a href="#static-linking" class="headerlink" title="static linking:"></a>static linking:</h3><h4 id="when"><a href="#when" class="headerlink" title="when"></a>when</h4><p>at compiling time , has two major tasks:</p>
<ul>
<li><strong>Symbol resolution</strong>: It associates each symbol reference with exactly one symbol definition .Every symbol have predefined task.</li>
<li><strong>Relocation</strong>: It relocate code and data section and modify symbol references to the relocated memory location.</li>
</ul>
<h4 id="static-lib"><a href="#static-lib" class="headerlink" title="static lib"></a>static lib</h4><p>The linker copy all static library <code>.a (unix), .lib(windows)</code> used in the program into executable image. </p>
<h4 id="features"><a href="#features" class="headerlink" title="features"></a>features</h4><ul>
<li>pros: <ol>
<li>does not require the presence of library on the system when it is run </li>
<li>faster and more portable</li>
<li>less error chance.</li>
</ol>
</li>
<li>cons:<ol>
<li>more space of both memory and executable file.</li>
</ol>
</li>
</ul>
<h3 id="dynamic-linking"><a href="#dynamic-linking" class="headerlink" title="dynamic linking"></a>dynamic linking</h3><h4 id="when-1"><a href="#when-1" class="headerlink" title="when"></a>when</h4><ul>
<li>load-time (when program is loaded into memory and executed by the loader)<ul>
<li>usually for fixed functionality (e.g. C run-time library)</li>
</ul>
</li>
<li>run-time (load a dynamic library when need it)<ul>
<li>pros: <ul>
<li>more dynamic functionality such as plugin loading through <code>LoadLibrary()</code> API; </li>
<li>lazy mode: speed up program startup</li>
</ul>
</li>
<li>cons: need to manage lib loading&#x2F;freeing and function lookup manually</li>
</ul>
</li>
</ul>
<h4 id="dynamic-shared-lib"><a href="#dynamic-shared-lib" class="headerlink" title="dynamic(shared) lib"></a>dynamic(shared) lib</h4><p>Multiple processes could load the same dynamic library <code>.so(linux), .dll(windows), .dylib(macosx)</code>. There are only one physical copy of the library code in system memory. Every process can have access to that library code at any virtual address it likes.</p>
<h4 id="features-1"><a href="#features-1" class="headerlink" title="features"></a>features</h4><ul>
<li>pros: <ol>
<li>less space of both memory and executable file. </li>
<li>easy library update</li>
</ol>
</li>
<li>cons:<ol>
<li>more chances of error and failure</li>
</ol>
</li>
</ul>
<h2 id="ELF-Format"><a href="#ELF-Format" class="headerlink" title="ELF Format"></a>ELF Format</h2><p><img src="/2019/07/10/System%20Design/Linux/OS_compile_link_symbol/ELF_format.png" loading="lazy"></p>
<ul>
<li>load to memory<ul>
<li>.text : program code</li>
<li>.rodata : const variable, const string</li>
<li>.data : <code>initialized</code> global and static variables</li>
<li>.bss: <code>uninitialized</code> global and static variables</li>
</ul>
</li>
<li>only in relocated ELF<ul>
<li>symtab: symbol table</li>
<li>.ref.text : relocation info for .text section (addresses of instructions that will need to be modified in the executable)</li>
<li>.ref.data: relocation info for .data section (addresses of pointer data that will need to be modified in the merged executable)<!-- 具体是啥不懂了 --></li>
</ul>
</li>
</ul>
<!-- TODO装在ELF 看这篇博客https://blog.csdn.net/b2222505/article/details/72496149 -->
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.cnblogs.com/ysocean/p/7497468.html">深入理解计算机系统（1.1）——Hello World 是如何运行的</a></li>
<li><a href="http://www.chuquan.me/2018/05/21/elf-introduce/">计算机那些事(4)——ELF文件结构</a></li>
<li><a href="http://faculty.cs.niu.edu/~mcmahon/CS241/Notes/compile.html">The C++ compilation process</a></li>
<li><a href="https://medium.com/@meghamohan/everything-you-want-to-know-about-gcc-fa5805452f96">Everything you want to know about GCC</a></li>
<li><a href="https://codingfreak.blogspot.com/2008/02/compilation-process-in-gcc.html">Compilation process in GCC</a></li>
<li><a href="https://stackoverflow.com/questions/6264249/how-does-the-compilation-linking-process-work">How does the compilation&#x2F;linking process work?</a></li>
<li><a href="https://stackoverflow.com/questions/2055840/difference-between-load-time-dynamic-linking-and-run-time-dynamic-linking">Difference between load-time dynamic linking and run-time dynamic linking</a></li>
<li><a href="https://www.bottomupcs.com/chapter08.xhtml">Chapter 9. Dynamic Linking</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Operating System | Memory allocation</title>
    <url>/2019/04/20/System%20Design/Linux/OS_memAlloc/</url>
    <content><![CDATA[<p>文章还未完善</p>
<h2 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h2><p>Note:malloc is a glic function, not syscall</p>
<h3 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h3><p><img src="/2019/04/20/System%20Design/Linux/OS_memAlloc/malloc_system.png" loading="lazy"></p>
<h2 id="mem-structure"><a href="#mem-structure" class="headerlink" title="mem structure"></a>mem structure</h2><p><img src="/2019/04/20/System%20Design/Linux/OS_memAlloc/mem_str.png" loading="lazy"></p>
<h2 id="physical-page-allocation"><a href="#physical-page-allocation" class="headerlink" title="physical page allocation"></a>physical page allocation</h2><h3 id="buddy"><a href="#buddy" class="headerlink" title="buddy"></a>buddy</h3><p>Linux内核中引入了伙伴系统算法(Buddy system)。把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。如图：</p>
<p><img src="/2019/04/20/System%20Design/Linux/OS_memAlloc/buddy_0.png" loading="lazy"></p>
<p>假设要申请一个256个页框的块，先从256个页框的链表中查找空闲块，如果没有，就去512个页框的链表中找，找到了则将页框块分为2个256个页框的块，一个分配给应用，另外一个移到256个页框的链表中。如果512个页框的链表中仍没有空闲块，继续向1024个页框的链表查找，如果仍然没有，则返回错误。页框块在释放时，会主动将两个连续的页框块合并为一个较大的页框块。</p>
<p>从上面可以知道Buddy算法一直在对页框做拆开合并拆开合并的动作。Buddy算法牛逼就牛逼在运用了世界上任何正整数都可以由2^n的和组成。这也是Buddy算法管理空闲页表的本质。 </p>
<h3 id="slab"><a href="#slab" class="headerlink" title="slab"></a>slab</h3><p>TODO</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><p><a href="https://github.com/godspeed1989/buddy_allocator">Linux内核内存管理算法Buddy和Slab</a><br><a href="http://blog.jqian.net/post/malloc.html">内存分配malloc浅析</a><br><a href="https://www.kernel.org/doc/gorman/html/understand/understand009.html">Chapter 6  Physical Page Allocation</a><br><a href="http://pages.cs.wisc.edu/~sschang/OS-Qual/memory/Memory.htm">Allocating Main Memory</a><br><a href="https://www.youtube.com/watch?v=1pCC6pPAtio">Memory Partitioning 3: Buddy System</a><br><a href="http://kernel.pursuitofcloud.org/531187">Linux内存管理(二)</a></p>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>分布式系统基础之常见评价指标</title>
    <url>/2017/02/20/System%20Design/Distributed%20System/basic/</url>
    <content><![CDATA[<!-- # 常见评价指标 -->
<p>在了解分布式之前，先讲述一些一些常见的评价指标。这些概念在之后的系统介绍中将会经常提起。<br>有些中文有些歧义，建议以英文为准。</p>
<h2 id="性能指标-performance"><a href="#性能指标-performance" class="headerlink" title="性能指标 performance"></a>性能指标 performance</h2><ul>
<li>吞吐<code>Throughout</code>: Rate of data transmitted over a communication channel<ul>
<li>Bytes&#x2F;s, MB&#x2F;s,</li>
<li>Ops&#x2F;s<ul>
<li>QPS(Queries&#x2F;s)</li>
<li>TPS(Transactions&#x2F;s)</li>
</ul>
</li>
</ul>
</li>
<li>带宽<code>Bandwith</code>: The <strong>maximum</strong> possible rate of data can be transmitted)<ul>
<li>highlight the upper bound(Bytes&#x2F;s, MB&#x2F;s,)</li>
</ul>
</li>
<li>并发量<code>(degree of) Concurrency</code>: parallelism of workload in a computing system</li>
<li>响应时间<code>latency</code>:<ul>
<li><p>(common) round-trip latency(RTT): the total time since a request is sent and the response is recevied</p>
</li>
<li><p>one-way latency: the time from sending to get get acknowledge</p>
</li>
<li><p>avg latency &#x3D; <code>Concurrency</code> &#x2F; <code>Throughput</code>(Ops&#x2F;s)</p>
</li>
</ul>
</li>
</ul>
<h3 id="DO-NOT-TRUST-AVERAGE"><a href="#DO-NOT-TRUST-AVERAGE" class="headerlink" title="DO NOT TRUST AVERAGE"></a>DO NOT TRUST AVERAGE</h3><p>一个完整的性能测吞吐量都要做响应时间限定和成功率统计。统计平均值参考价值不大<br>如P99 ~ 10ns &#x3D;&gt; 99% request get response in 10ns, the other request hit error or take more than 10ns。<br>并且往往 latency 和 Throughout&#x2F;QPS&#x2F;TPS 存在冲突</p>
<blockquote>
<p>Reference</p>
<ul>
<li><a href="http://www.360doc.com/content/16/0706/09/478627_573462703.shtml">性能测试怎么做</a></li>
<li><a href="https://www.dynatrace.com/news/blog/why-averages-suck-and-percentiles-are-great/">Why averages suck and percentiles are great</a></li>
</ul>
</blockquote>
<h2 id="可扩展-伸缩-性-scalability"><a href="#可扩展-伸缩-性-scalability" class="headerlink" title="可扩展(伸缩)性 scalability"></a>可扩展(伸缩)性 scalability</h2><ul>
<li>指横向扩展性(scale out)， 比如增加节点数量</li>
<li>注意区分 纵向扩展 (scale up) ，比如 同一个节点加内存、CPU</li>
<li>在软件架构中还存在可扩展性(Extensibility) ，指的是架构上好不好增加需求和功能。</li>
</ul>
<h2 id="可用性-availablibity"><a href="#可用性-availablibity" class="headerlink" title="可用性 availablibity"></a>可用性 availablibity</h2><p>可用性也有带性能的意思，可用指在一定<strong>（正常）响应时间的范围内可用</strong>，超出就算不可用。不强调性能上限，但是受<strong>下限</strong>影响。</p>
<ul>
<li>两种计算方法<ol>
<li>可以提供服务的时间&#x2F;（可提供服务时间+不可提供服务时间）</li>
<li>请求成功次数&#x2F;总请求次数 （不常用，因为请求失败海可能是由网络等非系统本身问题导致的exception，并不是系统的锅）</li>
</ol>
</li>
</ul>
<h2 id="可靠性-reliability"><a href="#可靠性-reliability" class="headerlink" title="可靠性 reliability"></a>可靠性 reliability</h2><p>听上去类似availablibity， 但是availablibity强调占比，reliability强调时长</p>
<p>可用性好不一定可靠性好，比如一个系统每隔1h挂1s，他的可用性就是99.9999以上，看上去很高，但是间隔1h这个还不如那种一年只宕机2星期的。</p>
<ul>
<li>计算方法<br>  平均失败间隔时长 &#x3D; 平均连续运行时长</li>
</ul>
<h2 id="一致性-consistency"><a href="#一致性-consistency" class="headerlink" title="一致性 consistency"></a>一致性 consistency</h2><p>严格程度依次下降如下：</p>
<ul>
<li>strict 分布式基本不采用这个</li>
<li>sequential</li>
<li>causal</li>
<li>eventual</li>
</ul>
<h2 id="分区容错性-Partition-tolerance"><a href="#分区容错性-Partition-tolerance" class="headerlink" title="分区容错性 Partition tolerance"></a>分区容错性 Partition tolerance</h2><p>分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。</p>
<p>注意区分 容错性 fault tolerance：定义更加广泛，比分区容错性更广，就指发生错误时候的恢复能力和业务能否继续正常运行。比如设置checkpoint。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="可维护性-maintainability"><a href="#可维护性-maintainability" class="headerlink" title="可维护性 maintainability"></a>可维护性 maintainability</h3><p>发生故障的系统被恢复的难易程度</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.mysoftkey.com/architecture/understanding-of-cap-theorem/">Understanding of CAP Theorem</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Distributed System</category>
      </categories>
  </entry>
  <entry>
    <title>Get Started with Cache</title>
    <url>/2022/02/20/System%20Design/Distributed%20System/cache_overview/</url>
    <content><![CDATA[<h1 id="What’s-Cache"><a href="#What’s-Cache" class="headerlink" title="What’s Cache"></a>What’s Cache</h1><p>A cache is a high-speed data storage layer that stores a subset of data, typically transient in nature, so that future requests for that data are served up faster than is possible by accessing the data’s primary storage location.</p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>Cache is a general technique that uses any high-speed temporary storage to avoid accessing low-speed storage. It’s widely used in various situations:</p>
<ol>
<li>(CPUCache &gt; RAM): CPU Cache saves some data to avoid accessing RAM.</li>
<li>(RAM &gt; DISK): RAM could be a cache when loading the data of disk.</li>
<li>(Local Memory &gt; remote memory): application saves data to the local cache to reduce communication with the remote server.</li>
<li>(Close server &gt; far server): CDN</li>
<li>….</li>
</ol>
<blockquote>
<p><a href="https://conceptsall.com/the-memory-hierarchy-in-computer-architecture/">The Memory Hierarchy in Computer Architecture</a><br><img src="/2022/02/20/System%20Design/Distributed%20System/cache_overview/Memory_Hierarchy.png" loading="lazy"></p>
</blockquote>
<h2 id="Pros-amp-Note"><a href="#Pros-amp-Note" class="headerlink" title="Pros &amp; Note"></a>Pros &amp; Note</h2><ul>
<li><p>Pros</p>
<ul>
<li>Improve Application Performance(latency &amp; throughput), especially the reading operation</li>
<li>Reduce the load of low-storage, e.g. disk, database</li>
<li>Eliminate Database Hotspots</li>
</ul>
</li>
<li><p>Cons</p>
<ul>
<li>more memory usage</li>
<li>should be useless in a write-intensive scenario</li>
</ul>
</li>
<li><p>Note</p>
<ul>
<li>Cache should be transparent to business, so a good cache design should never impact business logic.</li>
<li>It’s important to monitor cache hit&#x2F;miss rate to make sure if cache really works</li>
<li>Be careful about the data consistency between cache and primary storage if<ul>
<li>the data on primary storage could modify without notifying cache</li>
<li>application writes newest data to cache only</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Typical-Issues-and-Solutions"><a href="#Typical-Issues-and-Solutions" class="headerlink" title="Typical Issues and Solutions"></a>Typical Issues and Solutions</h1><p>Here is a typical workflow to query data powered by cache. Normally, cache plays a role in protecting the database and improving performance. But sometimes it does not work well, let’s show what will possibly happen and how to solve them.<br><img src="/2022/02/20/System%20Design/Distributed%20System/cache_overview/cache_workflow.svg" loading="lazy"></p>
<h2 id="Cache-Avalanche-缓存雪崩"><a href="#Cache-Avalanche-缓存雪崩" class="headerlink" title="Cache Avalanche (缓存雪崩)"></a>Cache Avalanche (缓存雪崩)</h2><p>If <strong>massive cache entries are not available</strong> for some reason, the most query requests that were originally blocked by the cache will flock to the database like a mad dog. At this point, if the database can’t withstand this huge pressure, it will collapse.</p>
<ul>
<li>Typical cause <ol>
<li>cache node crash</li>
<li>network stuck</li>
<li>many cache entry get expired at the same time</li>
</ol>
</li>
<li>Solution<ol>
<li>short-term solution: close&#x2F;downgrade the application layer if it’s not important to protect database </li>
<li>apply a cache cluster to ensure the high availability of caches</li>
<li>rewrite a scattered expiration time(aka random gap time) or even disable expired time</li>
</ol>
</li>
</ul>
<h2 id="Cache-Penetration-（缓存穿透"><a href="#Cache-Penetration-（缓存穿透" class="headerlink" title="Cache Penetration （缓存穿透)"></a>Cache Penetration （缓存穿透)</h2><p>The data to be queried usually exists! However, when <strong>the data does not exist at all</strong>, the application would always hit cache miss and have to query the database again and again. </p>
<ul>
<li>Typical cause <ul>
<li>illegal or unexpected data query</li>
<li>normal request</li>
</ul>
</li>
<li>Solution<ul>
<li>filter illegal or unexpected request</li>
<li>cache empty key </li>
<li>setup bloom filter to skip most queries of unexisted key<blockquote>
<p>Note: bloom filter is a data structure to check if it may exist or must not exist. It needs a initialization based on full data. It’s usually used with scheduled initialization for dynamic primary data.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="Hotspot-Invalid-缓存击穿"><a href="#Hotspot-Invalid-缓存击穿" class="headerlink" title="Hotspot Invalid (缓存击穿)"></a>Hotspot Invalid (缓存击穿)</h2><p>Few hot data with really high requests get expired or deleted, there will be a large number of requests falling on the database at this moment, which may cause the database to crash even if most queries are duplicated.</p>
<ul>
<li>Typical cause <ul>
<li>business bug</li>
</ul>
</li>
<li>Solution<ul>
<li>make a clear plan for hot data refresh</li>
<li>use mutex or other checking to avoid duplicate query</li>
</ul>
</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://aws.amazon.com/caching/">Amazon Caching Overview</a></li>
<li><a href="https://segmentfault.com/a/1190000041514210/en">Cache avalanche, penetration, breakdown that Xiaobai can also understand</a></li>
<li><a href="https://medium.com/@mena.meseha/3-major-problems-and-solutions-in-the-cache-world-155ecae41d4f">3 major problems and solutions in the cache world</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Distributed System</category>
      </categories>
  </entry>
  <entry>
    <title>Consistency Model Summary in Distributed System</title>
    <url>/2022/10/16/System%20Design/Distributed%20System/consistency_model/</url>
    <content><![CDATA[<h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>Generally, consistency model define the behavior how mutliple concurrent workflows read&#x2F;write data or replciation. And it works similiar among the following situations:</p>
<ul>
<li>Mutilple threads read&#x2F;write memory within a process</li>
<li>Mutilple processes read&#x2F;write shared memory within a machine</li>
<li>Mutilple nodes read&#x2F;write shared data within a cluster</li>
</ul>
<p>In the following paragraph, I’d like to use thread to stands for the concurrent workflow to ease the demostration. So you can simply replace thread with process or node in the following paragraph.</p>
<h2 id="Consistency-is-Hard-in-distributed-systems"><a href="#Consistency-is-Hard-in-distributed-systems" class="headerlink" title="Consistency is Hard in (distributed) systems"></a>Consistency is Hard in (distributed) systems</h2><ul>
<li>Data replication (Caching)</li>
<li>Concurrency (no shared clock)</li>
<li>Failures (machine or network)</li>
</ul>
<h2 id="Consistency-Model"><a href="#Consistency-Model" class="headerlink" title="Consistency Model"></a>Consistency Model</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><table>
    <thead>
        <tr>
            <th rowspan=2></th>
            <th colspan=3>Strong Consistency</th>
            <th colspan=2>Weak Consistency</th>
        </tr>
    </thead>
    <tbody style="text-align: center">
      <tr>
            <td> Def </td>
            <td colspan=3> The current state of a data item follows a universally and mutually accepted sequence of change of state.<br>每个并发workflow`线程or进程or节点`看到的操作执行顺序是一样的 </td>
            <td colspan=2> It allows distinct views of the database state to see different and unmatched updates in the database state. </td>
        </tr>
        <tr>
            <td> Client Awareness </td>
            <td colspan=3> No. End-Client is unaware of replications of data. </td>
            <td colspan=2> Yes. For a specific key, different clients may get different value/version. </td>
        </tr>
        <tr>
            <td> Typical Models </td>
            <td> Strict<br>严格 </td>
            <td> Linear/Atomic<br>线性 </td>
            <td> <b>Sequential<br>顺序</b> </td>
            <td> Casual<br>因果 </td>
            <td> <b>Eventual<br>最终</b> </td>
        </tr>
        <tr>
            <td>Comparsion</td>
            <td colspan=5> ----> (from left to right)  ---->
               <br> less consistent data
               <br> higher performance(lower latency, higher thoughput) 
               <br> higher availability       
             </td>
        </tr>
        <tr>
            <td>Description</td>
            <td>every read will see the most recent write in real time.</td>
            <td>reads see the most recent write that is not overlapped with it.</td>
            <td>all writes must be globally ordered in some way that all threads/process/nodes agree</td>
            <td>if A causes B, all threads that see the result of B must see the result of A as well.</td>
            <td>No order constraints at all. But eventually all threads will converge. </td>
        </tr>
         <tr>
            <td>Common Design</td>
            <td>Impossible in practice for threads or nodes to agree on a precise current time </td>
            <td>Distributed Lock,<br>2PC commit,<br>Distributed Data Store with Consensus(Paxos, Raft) </td>
            <td>Consistent Core Pattern with centrized design </td>
            <td> <a href="https://timilearning.com/posts/mit-6.824/lecture-17-cops/">1. COPS</a> <br> 2. Logical Lock (version)   </td>
            <td>1. Asynchronous data synchronization: (copying 、update log、meesage queue )<br>2. data with version </td>
        </tr>
        <tr>
            <td> Project</td>
            <td>  </td>
            <td> Google Spanner, GFS  </td>
            <td> 1. IVY(distributed shared memory)<br>2. Zookeeper</td>
            <td> 1. MongoDB,<br>2. Message App(Whatsapp/iMessage)<br> 3. self share(wechat moments) </td>
            <td> 1. DNS syncing<br>2. Amazon DynamoDB <br>3. Elasticsearch(syncing between primary and replica shards<br>4. Gossip protocol<br>5. Most news platform <br>6. Block chain </td>
        </tr>
    </tbody>
</table>

<h3 id="Simple-Example"><a href="#Simple-Example" class="headerlink" title="Simple Example"></a>Simple Example</h3><ol>
<li><strong>Strict Consistency</strong><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215152555.webp" loading="lazy"></li>
<li><strong>Linear&#x2F;Atomic Consistency</strong><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215152613.webp" loading="lazy"><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215152758.webp" loading="lazy"></li>
<li><strong>Sequential Consistency</strong><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215152938.webp" loading="lazy"></li>
<li><strong>Casual Consistency</strong><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215153049.webp" loading="lazy"><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215153343.webp" loading="lazy"></li>
<li><strong>Eventual Consistency</strong><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215153356.webp" loading="lazy"></li>
<li><strong>Not Consistent Consistency</strong><br><img src="/2022/10/16/System%20Design/Distributed%20System/consistency_model/20231215153405.webp" loading="lazy"></li>
</ol>
<h3 id="Real-Example-Quorum-NWR"><a href="#Real-Example-Quorum-NWR" class="headerlink" title="Real Example - Quorum(NWR)"></a>Real Example - Quorum(NWR)</h3><p>Quorum-based consistency is common to set replication consistency, such as <code>Cassandra</code>, <code>HDFS</code>. It uses a voting mechanism to determine the consistency of data operations. Each data operation, such as read or write, requires a certain number of nodes to acknowledge the operation before it is considered successful. </p>
<ul>
<li><strong>N</strong> &#x3D; nodes in the quorum group(cluster)</li>
<li><strong>W</strong> &#x3D; minimum write nodes (write quorum)<ul>
<li>the write operation could only be completed after writing <strong>W</strong> nodes synchronously. And then the updated node will deliver change to to other nodes asynchronously.</li>
</ul>
</li>
<li><strong>R</strong> &#x3D; minimum read nodes (read quorum)<ul>
<li>the read operation could only be completed after reading <strong>R</strong> nodes synchronously.</li>
</ul>
</li>
</ul>
<h4 id="Relation-with-Consistency"><a href="#Relation-with-Consistency" class="headerlink" title="Relation with Consistency"></a>Relation with Consistency</h4><ul>
<li><strong>≥Sequential</strong>:    <strong>W + R &gt; N</strong><ul>
<li>e.g. Let X&#x3D;0 initially. After a write operation to set X&#x3D;1, the read operation will get X&#x3D;1</li>
</ul>
</li>
<li><strong>Eventual</strong>:    <strong>W + R ≤ N</strong><ul>
<li>e.g. Let X&#x3D;0 initially. After a write operation to set X&#x3D;1, the read operation may still get X&#x3D;0</li>
</ul>
</li>
</ul>
<blockquote>
<p>Cassandra could achieve consistency level by setting different <a href="https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html#:~:text=Consistency%20levels%20in%20Cassandra%20can%20be%20configured%20to,for%20all%20queries%20in%20the%20current%20cqlsh%20session.">quorum config</a></p>
</blockquote>
<h2 id="Confused-Concepts"><a href="#Confused-Concepts" class="headerlink" title="Confused Concepts"></a>Confused Concepts</h2><h3 id="Consitency-vs-Coherence"><a href="#Consitency-vs-Coherence" class="headerlink" title="Consitency vs Coherence"></a>Consitency vs Coherence</h3><ul>
<li><strong>Coherence</strong> is related to the multiple values&#x2F;versions among different data <strong>layer</strong>. e.g. Cache Coherence</li>
<li><strong>Consistency</strong> is the agreement between multiple <strong>threads&#x2F;processes&#x2F;nodes</strong> in a system to achieve a certain value.</li>
</ul>
<blockquote>
<p>在中文中，都是翻译成一致性。但是其实是有侧重的，Coherence关心同一个数据在不同垂直层级上的不同值、版本，比如缓存；而Consistency讨论的是 同一个水平层级下不同的节点、副本之间如何得到相同的值、版本。在大部分工作场合里，其实也不需要去区分。</p>
</blockquote>
<h3 id="Consistency-vs-Isolation-Database"><a href="#Consistency-vs-Isolation-Database" class="headerlink" title="Consistency vs Isolation (Database)"></a>Consistency vs Isolation (Database)</h3><ul>
<li><strong>Isolation</strong>:<br>refers to the ability of a database to allow a transaction to execute as if there are no other concurrently running transactions. The overarching goal is to prevent reads and writes of temporary, incomplete, aborted, or otherwise incorrect data written by concurrent transactions.</li>
<li><strong>Consistency</strong>:<br>when a modern system offers multiple consistency levels, they define consistency in terms of the client view of the database. e.g. If two clients can see different states at the same point in time, we say that their view of the database is inconsistent</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.modb.pro/db/60909">Understand Consistency Levels in Distributed Systems</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/618127949">共识、线性一致性、顺序一致性、最终一致性、强一致性概念区分</a></li>
<li><a href="https://www.geeksforgeeks.org/weak-levels-of-consistency/">Weak Levels of Consistency</a></li>
<li><a href="https://sertse.medium.com/consistency-vs-coherence-2cf1609eaf20#:~:text=In%20simpler%20terms%20the%20difference%20between%20Consistency%20and,with%20respect%20to%20accesses%20to%20other%20locations.%20">Consistency Vs Coherence</a></li>
<li><a href="https://fauna.com/blog/demystifying-database-systems-introduction-to-consistency-levels">Demystifying Database Systems, Part 3: Introduction to Consistency Levels</a></li>
<li><a href="https://r12f.com/posts/summarizing-consistency-model/">数据一致性 VS 事务隔离性 </a></li>
<li><a href="http://dbmsmusings.blogspot.com/2019/07/overview-of-consistency-levels-in.html">Overview of Consistency Levels in Database Systems</a><!-- TODO  --></li>
<li><a href="https://www.cs.cmu.edu/~srini/15-446/S09/lectures/10-consistency.pdf">CMU slides 15-446 Distributed Systems Spring 2009</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/57315959">知乎 分布式系统一致性总结</a></li>
</ul>
<!-- 
### Quorum（属于最终一致性） NWR 中的三个要素NWR

1. N 表示副本数，又叫做复制因子（Replication Factor）
2. W又称写一致性级别（Write Consistency Level），表示成功完成 W 个副本更新，才完成写操作
3. R，又称读一致性级别（Read Consistency Level），表示读取一个数据对象时需要读 R 个副本。你可以这么理解，读取指定数据时，要读 R 副本，然后返回 R 个副本中最新的那份数据
   N、W、R 值的不同组合，会产生不同的一致性效果，具体来说，有这么两种效果：
4. 当 W + R > N 的时候，对于客户端来讲，整个系统能保证强一致性，一定能返回更新后的那份数据。
5. 当 W + R <= N 的时候，对于客户端来讲，整个系统只能保证最终一致性，可能会返回旧数据。
https://www.cs.cmu.edu/~srini/15-446/S09/lectures/10-consistency.pdf
6.  -->]]></content>
      <categories>
        <category>System Design</category>
        <category>Distributed System</category>
      </categories>
  </entry>
  <entry>
    <title>Consistency in Distributed System - CAP、BASE</title>
    <url>/2020/02/20/System%20Design/Distributed%20System/distributed_consitency/</url>
    <content><![CDATA[<h1 id="CAP-Theorem"><a href="#CAP-Theorem" class="headerlink" title="CAP Theorem"></a>CAP Theorem</h1><p>常见的解释是三者最多只能两者相互满足，</p>
<ul>
<li><p>C-Consistency: All nodes see the same data at the same time.</p>
</li>
<li><p>A-Availability:  Reads and writes always succeed</p>
</li>
<li><p>P-Partition tolerance: The system continues to operate despite arbitrary message loss or failure of part of the system<br><img src="/2017/02/20/System%20Design/Distributed%20System/basic/CAP_Theorem_view.png" loading="lazy"></p>
</li>
<li><p><strong>CA</strong>: Single site cluster, therefore all nodes are always in contact, when a partition occurs, the system blocks. Choose C and A with compromising of P (Partition Tolerance). e.g. type of applications: Banking and Finance application, a system which must have transaction </p>
<ul>
<li>e.g. connected to RDBMS.</li>
</ul>
</li>
<li><p><strong>AP</strong>: System is still available under partitioning, but some of the data returned may be inaccurate. Choose A and P with compromising of C (Consistency). When to choose AP to achieve what is itself a question. There is a use case: return the most recent version of the data you have, which could be stale. This system state will also accept writes that can be processed later when the partition is resolved. Sometimes architects choose <strong>eventual consistency</strong> with compromising Availability or Partition tolerance to some extent. </p>
<ul>
<li>Applications: shopping carts, any consumer-facing system, News publishing CMS, couchDB, cassandra. </li>
<li>Typical protocol: Gossip</li>
</ul>
</li>
<li><p><strong>CP</strong>: Some data may not be accessible, but the rest is still consistent&#x2F;accurate. choose based on the requirement analysis. </p>
<ul>
<li>Ecomerence&#x2F;Pay System, MongoDB, zookeeper, Hbase etc.</li>
</ul>
</li>
</ul>
<blockquote>
<p>分布式场景下其实是<strong>当P满足时候，A和C只能二选一</strong>， 因为满足CA其实就是单点, 比如当CA数据库节点用主从备份后，如果同时访问从节点，就失去一致性。<br>即当分布式内出现网络中断的时候，无法同时满足一致性和高可用。降低一点一致性要求，是可以达到，比如gossip协议，可以允许等网络恢复后，再把信息传播过去，提供eventual 一致性。</p>
</blockquote>
<h1 id="BASE-Achieve-CAP-basically"><a href="#BASE-Achieve-CAP-basically" class="headerlink" title="BASE - Achieve CAP basically"></a>BASE - Achieve CAP basically</h1><p>Basically Available、Soft State、Eventual Consistency. BASE targets to achieve CAP at the same time but not perfect in three aspects, like 80%A+80%C+80%P</p>
<ul>
<li>Basically-Available (基本可用): A distributed system should be available to respond with some acknowledgment — even if it’s a failure message, to any incoming request.</li>
<li>Soft-state (软状态\柔性事务): The system may keep changing states as and when it receives new information. The eventual consistent system must have the soft state.</li>
<li>Eventual Consistency(最终一致性): The components in the system may not reflect the same value&#x2F;state of a record at a given point in time. They will settle it with time, eventually, though.</li>
</ul>
<!-- PAXOS raft, GOSSIP TBD -->


<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://blog.csdn.net/TJtulong/article/details/106510970">常用的分布式一致性协议</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Distributed System</category>
      </categories>
  </entry>
  <entry>
    <title>Distributed Transaction - 2PC, 3PC</title>
    <url>/2021/08/20/System%20Design/Distributed%20System/distributed_transcation/</url>
    <content><![CDATA[<h1 id="What’s-distributed-transaction"><a href="#What’s-distributed-transaction" class="headerlink" title="What’s distributed transaction?"></a>What’s distributed transaction?</h1><p>The article describes some common algorithms to achieve the ACID transaction in Distributed System. Please review the following pages first if you are not familiar with some basic concepts, such as ACID, CAP, BASE.</p>
<ul>
<li><a href="/2021/04/05/Storage/Database/Database_Transaction/" title="Database Transaction - ACID &amp; Isolation Level">Database Transaction - ACID &amp; Isolation Level</a></li>
<li><a href="/2020/02/20/System%20Design/Distributed%20System/distributed_consitency/" title="Consistency in Distributed System - CAP、BASE">Consistency in Distributed System - CAP、BASE</a></li>
</ul>
<p>The distributed transaction aims to achieve ACID among multiple databases. </p>
<blockquote>
<p>In a distributed transaction environment, multiple processes participate in a transaction, each executing its own sub-transaction that can commit only if there is unanimous consensus by all <code>participants</code> to do so. Each system runs a transaction manager, a process that is responsible for participating in the commit algorithm algorithm to decide whether to commit or abort its sub-transaction. One of these transaction managers may be elected as the <code>coordinator</code> and initiates and runs the commit algorithm.</p>
</blockquote>
<!-- # What's distributed  -->

<h1 id="2-Phase-Commit"><a href="#2-Phase-Commit" class="headerlink" title="2-Phase Commit"></a>2-Phase Commit</h1><p>This protocol requires a coordinator. The client contacts the <code>coordinator</code> and proposes a value. The coordinator then tries to establish the consensus among a set of processes (a.k.a <code>Participants</code>) in two phases, hence the name.<br><img src="/2021/08/20/System%20Design/Distributed%20System/distributed_transcation/2PC.svg" loading="lazy"></p>
<h2 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h2><ul>
<li><p>Phase 1: Vote Phase</p>
<ul>
<li>(1) Coordinator sends a request (“can you commit?”) to every participant (reliably, retransmitting as often as needed until all replies are received)</li>
<li>(2) Participants write <code>WAL</code> first to support rollback and run transactions without committing and </li>
<li>(3) Phase 1 is complete when each participant responds.</li>
</ul>
</li>
<li><p>Phase 2: Decision Phase</p>
<ul>
<li>(4) If the coordinator gets even a single abort response from a participant, it will send requests to all participants to abort the entire transaction. Otherwise, it will tell all participants to commit.</li>
<li>(5) Participant gets the request to commit&#x2F;rollback</li>
<li>(6) Regard the transaction as finished if all decisions are done well.</li>
</ul>
</li>
</ul>
<h2 id="Cons"><a href="#Cons" class="headerlink" title="Cons"></a>Cons</h2><p>it’s easy to implement but has several drawbacks since<br><strong>EVERY STEP CAN FAIL!!</strong></p>
<p>The two-phase commit protocol is a blocking protocol that relies on a fail-restart failure model.</p>
<ul>
<li>Low Performance<ul>
<li>Synchronous blocking model: all transactions have to wait for the release of the locked resource</li>
<li>Easy Rollback: All participants have to roll back when a participant says No.</li>
</ul>
</li>
<li>Single-Point of failure(SPOF)<ul>
<li>If the coordinator crashes after (1) and before (4), all participants would hang forever</li>
</ul>
</li>
<li>Inconsistent Data <ul>
<li>Some participants may not complete commit(5) due to network or self-crash. And the coordinator after (4), there is no one to record the status of participants even if the system elects a new coordinator.</li>
</ul>
</li>
</ul>
<h1 id="3-Phase-Commit"><a href="#3-Phase-Commit" class="headerlink" title="3-Phase Commit"></a>3-Phase Commit</h1><p>This is an extension of 2PC with the following two major optimizations:<br><img src="/2021/08/20/System%20Design/Distributed%20System/distributed_transcation/3PC.svg" loading="lazy"></p>
<ul>
<li><p>Introduce timeout to both coordinator and participant</p>
<ol>
<li>regard the timeout of participant response as <code>No</code></li>
<li>regard the timeout of coordinator request as <code>move on</code> if participant is ready to commit.</li>
</ol>
</li>
<li><p>Introduce one more phase </p>
<ul>
<li>Make sure all participants are able to run transcation to avoid some rollback</li>
<li>enables the use of a <code>recovery coordinator</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>If the participant is found to be in phase 2, that means that every participant has completed phase 1 and voted on the outcome. The completion of phase 1 is guaranteed. It is possible that some participants may have received commit requests (phase 3). The recovery coordinator can safely resume at phase 2.<br>If the participant was in phase 1, that means NO participant has started commits or aborts. The protocol can start at the beginning..<br>If the participant was in phase 3, the coordinator can continue in phase 3 – and make sure everyone gets the commit&#x2F;abort request</p>
</blockquote>
<h2 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h2><ul>
<li>Pros:<ul>
<li>reduce blocking waiting and the possibility of rollback to improve performance</li>
<li>recovery coordinator to handle SPOF</li>
</ul>
</li>
<li>Cons:<ul>
<li>Inconsistent data is still there due to  (same as 2PC).</li>
</ul>
</li>
</ul>
<!-- > In modern distributed storage system,  -->

<!-- # TODO和  PAXOS 的关系
<!-- 
TODO
分布式事务(2PC) vs 共识协议(Paxos/raft)

本质上，分布式事务和共识协议解决的不是同一个问题。2PC解决的是分布式事务的一致性，存储的数据各有不同，目标侧重于ACID；Paxos/raft解决的是副本间数据的一致性和高可用，存储的数据完全一致，目标侧重于replication。

故在实际分布式应用中，会将Paxos/Raft和2PC结合使用。
比如在分布式数据库中，通过Paxos/Raft来保证数据副本的一致性，2PC+MVCC来实现分布式事务的一致性。
https://www.modb.pro/db/377116
https://cloud.tencent.com/developer/article/1763152
 -->

<!-- # Summary -->



<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://blog.csdn.net/TJtulong/article/details/106510970">常用的分布式一致性协议</a></li>
<li><a href="https://people.cs.rutgers.edu/~pxk/417/notes/transactions.html">Distributed Transactions</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/35616810">分布式一致性之两阶段提交协议、三阶提交协议</a></li>
<li><a href="https://www.cnblogs.com/qdhxhz/p/11167025.html">分布式事务(1)—2PC和3PC原理</a></li>
<li><a href="https://www.geeksforgeeks.org/three-phase-commit-protocol/">Three Phase Commit Protocol</a></li>
<li><a href="basic.mdhttps://www.ibm.com/docs/en/cics-ts/5.2?topic=processing-why-distributed-transaction">Why distributed transaction processing?</a></li>
<li><a href="https://medium.com/geekculture/distributed-transactions-two-phase-commit-c82752d69324">Distributed Transactions &amp; Two-phase Commit</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Distributed System</category>
      </categories>
  </entry>
  <entry>
    <title>负载平衡算法</title>
    <url>/2017/03/15/System%20Design/Distributed%20System/load_balance/</url>
    <content><![CDATA[<h1 id="一些基本的负载平衡算法"><a href="#一些基本的负载平衡算法" class="headerlink" title="一些基本的负载平衡算法"></a>一些基本的负载平衡算法</h1><p>以下算法，一般都只考虑节点负载的平衡，不考虑cache命中以及session维护</p>
<h2 id="Round-Robin-x2F-Random-（weighted-allowed）"><a href="#Round-Robin-x2F-Random-（weighted-allowed）" class="headerlink" title="Round Robin &#x2F; Random  （weighted allowed）"></a>Round Robin &#x2F; Random  （weighted allowed）</h2><ul>
<li>特点<ul>
<li>每个接受请求的概率相同（与权值正比）</li>
<li>simple</li>
<li>state<ul>
<li>fixed weight &#x3D; stateless</li>
<li>dynamic weight &#x3D; 依赖权值计算的具体方法（<strong>可以根据连接数、响应时间、吞吐、内存、CPU等决定权值</strong>）</li>
</ul>
</li>
</ul>
</li>
<li>场景<ul>
<li>每个处理节点性能差不多</li>
<li>期望低延迟路由，计算量小</li>
</ul>
</li>
</ul>
<h2 id="Chained-Failover"><a href="#Chained-Failover" class="headerlink" title="Chained Failover"></a>Chained Failover</h2><ul>
<li>节点成链条，每次只有当前节点无法接受更多时，选择链条的下一个节点。</li>
<li>可以和主从备份相结合</li>
</ul>
<h2 id="基于某个资源最小的节点"><a href="#基于某个资源最小的节点" class="headerlink" title="基于某个资源最小的节点"></a>基于某个资源最小的节点</h2><ul>
<li>共性： 有状态，需要节点个数<ul>
<li>无中心化<ul>
<li>sender 去pull receiver的节点负载</li>
<li>receivwe 去 push 负载到 sender</li>
</ul>
</li>
<li>中心化<ul>
<li>由中心监控节点负责路由和连接记录</li>
</ul>
</li>
<li>可以弱加权： 连接数差不多时，选权值高的</li>
</ul>
</li>
</ul>
<h3 id="Least-Connection-最小连接（active-task）数"><a href="#Least-Connection-最小连接（active-task）数" class="headerlink" title="Least Connection 最小连接（active task）数"></a>Least Connection 最小连接（active task）数</h3><ul>
<li>特点<ul>
<li>优先发送给当前连接数最少的节点</li>
<li>往往需要对每个节点设置最大连接数</li>
</ul>
</li>
<li>场景<ul>
<li>每个连接（任务）开销差不多</li>
</ul>
</li>
</ul>
<h2 id="The-Least-Response-Time-Method"><a href="#The-Least-Response-Time-Method" class="headerlink" title="The Least Response Time Method"></a>The Least Response Time Method</h2><ul>
<li>特点<ul>
<li>优先发送给最近响应时间内少的节点</li>
</ul>
</li>
<li>场景<ul>
<li>用于WAN下就近选择服务器，不适合LAN下极低响应的环境</li>
</ul>
</li>
</ul>
<h3 id="The-Least-Bandwidth-Throughput-Method"><a href="#The-Least-Bandwidth-Throughput-Method" class="headerlink" title="The Least Bandwidth(Throughput) Method"></a>The Least Bandwidth(Throughput) Method</h3><ul>
<li>特点<ul>
<li>优先发送给最近一段时间内使用带宽最少的节点</li>
</ul>
</li>
</ul>
<h3 id="The-Least-Packets-method"><a href="#The-Least-Packets-method" class="headerlink" title="The Least Packets method"></a>The Least Packets method</h3><ul>
<li>特点<ul>
<li>优先发送给最近一段时间内传输包最少的节点</li>
</ul>
</li>
</ul>
<h1 id="一致性Hash-Memcached采用"><a href="#一致性Hash-Memcached采用" class="headerlink" title="一致性Hash - Memcached采用"></a>一致性Hash - Memcached采用</h1><p>本质：用DHT(distributed hash table）管理键值，原本的目的是在P2P网络中快速定位资源，但是也常用来做负载均衡</p>
<h2 id="普通的Hash负载平衡"><a href="#普通的Hash负载平衡" class="headerlink" title="普通的Hash负载平衡"></a>普通的Hash负载平衡</h2><ul>
<li>根据key(比如IP)对节点个数取模</li>
<li>优: 机器不变动时，<strong>缓存友好</strong>和<strong>便于维护session</strong></li>
<li>缺点：机器变动时，导致IP和节点的映射变化，<strong>缓存命中率下降</strong>，IO增加</li>
</ul>
<h2 id="优雅地处理节点动态增减"><a href="#优雅地处理节点动态增减" class="headerlink" title="优雅地处理节点动态增减"></a>优雅地处理节点动态增减</h2><ul>
<li>目的: 为了使得原来的IP与节点映射关系变化尽量少</li>
<li>方法：对 $2^{32}-1$ 取模，得到hash环。 每个请求直接路由到顺时针下的那个节点。 插入和删除节点就是在环上增减点</li>
<li>减少： C节点宕机, 对象C从节点C变为D<br><img src="/2017/03/15/System%20Design/Distributed%20System/load_balance/hash_delete.png" loading="lazy"></li>
<li>增加： 增加D节点，对象C从节点C变为D， 一般是随机分配<br><img src="/2017/03/15/System%20Design/Distributed%20System/load_balance/hash_remove.png" loading="lazy"></li>
</ul>
<h3 id="几种维护节点的方法"><a href="#几种维护节点的方法" class="headerlink" title="几种维护节点的方法"></a>几种维护节点的方法</h3><ul>
<li>链表：快改慢查， 每个节点记录前一个节点和后一个节点的位置信息<ul>
<li>根据key查找节点： O(N) , N为节点数量 </li>
<li>增删节点 ： O(1)</li>
</ul>
</li>
</ul>
<ul>
<li><p>幂次逼近，Chord系统采用： 每个节点都要维护一个大小为N（可以更小）的finger table。</p>
<ul>
<li>查找节点： O(logN)</li>
<li>增删节点： O(logN)， 可以只更新一个节点的finger table </li>
<li>容错：为防止某节点之后连续的节点失效，导致新加入的节点未加入，所以对于每个节点需要额外维护一个长度为r的后续节点表，比如r&#x3D;1&#x2F;2，只要不是连续有一半机器失效，就可以正常工作。</li>
</ul>
</li>
<li><p>虚拟节点：Dynamo系统</p>
<ul>
<li><p>去中心化，可以从任意一个节点请求，也可以从负载均衡器开始</p>
</li>
<li><p>一个实际物理节点对应多个虚拟节点<br><img src="/2017/03/15/System%20Design/Distributed%20System/load_balance/virrual_note.png" loading="lazy"></p>
<ul>
<li>负载高的节点 减少虚拟节点</li>
<li>负载低的节点 增加虚拟节点</li>
</ul>
</li>
<li><p>冗余容错：NWR策略</p>
<blockquote>
<p>只要满足W+R &gt; N（即W和R读取的数据必有重叠），就可以保证当存在不超过一台机器故障的时候，至少能读到一份有效的数据。如果应用重视读效率，可以设置W&#x3D;N，R&#x3D;1; 如果应用需要在读&#x2F;写之间权衡，一般可设置成N&#x3D;3, W&#x3D;2, R&#x3D;2。Dynamo推荐使用322的组合。<br>N：同一份数据备份的份数<br>W：是更新一个数据对象的时候需要确保成功更新的份数<br>R：读取一个数据需要读取的最少节点（备份）的份数</p>
</blockquote>
</li>
<li><p>数据版本管理： vector clock      </p>
<ul>
<li>只保证eventual consistency，写请求可以写更新所有节点前返回，这个时候get就可能得到旧版数据。</li>
<li>一旦<strong>数据之间发生了冲突不会丢失</strong>，但是可能会有<strong>已被删除的数据重新出现</strong></li>
<li>这就会导致版本会出现分支，因为修改一个keyvalue时候，并不会阻塞，分支无法自动解决，需要人为定义merge方法。</li>
</ul>
</li>
<li><p>传播节点增删协议： Gossip</p>
<ul>
<li>不断传播信息到接触到的最多的节点。</li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- TODO: 为什么会有几个节点一开始传播不到 ，是因为无中心化的集群每个节点就没必要链接所有节点？-->

<h2 id="如何达到负载均衡"><a href="#如何达到负载均衡" class="headerlink" title="如何达到负载均衡"></a>如何达到负载均衡</h2><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>极端情况下的hash冲突</li>
<li>多节点管理维护成本还是较高的。</li>
<li>DHT使得key变成散列，<strong>适合随机访问</strong>，如果存在顺序访问操作，还是B系列树结构比较合适</li>
</ul>
<h1 id="Hash槽-redis采用"><a href="#Hash槽-redis采用" class="headerlink" title="Hash槽 - redis采用"></a>Hash槽 - redis采用</h1><ul>
<li><p>目的：<strong>为了避免高额的管理成本</strong></p>
</li>
<li><p>取消了虚拟节点，每个物理节点管理一块连续的hash区域。</p>
</li>
<li><p>删除节点和增加节点方法和一致性hash一样</p>
</li>
<li><p>负载均衡方式改为调整槽的大小，而不是增加、减少虚拟节点个数</p>
</li>
<li><p>图示：一个 Redis Cluster包含16384（0~16383）个哈希槽，存储在Redis Cluster中的所有键都会被映射到这些slot中，集群中的每个键都属于这16384个哈希槽中的一个，集群使用公式slot&#x3D;CRC16（key）&#x2F;16384来计算key属于哪个槽</p>
</li>
</ul>
<p><img src="/2017/03/15/System%20Design/Distributed%20System/load_balance/redis-hash.png" loading="lazy"></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://kemptechnologies.com/load-balancer/load-balancing-algorithms-techniques/">https://kemptechnologies.com/load-balancer/load-balancing-algorithms-techniques/</a></li>
<li><a href="https://poweruphosting.com/blog/load-balancing-algorithms/">https://poweruphosting.com/blog/load-balancing-algorithms/</a></li>
<li><a href="https://my.oschina.net/freegeek/blog/334842">https://my.oschina.net/freegeek/blog/334842</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34985026">https://zhuanlan.zhihu.com/p/34985026</a></li>
<li><a href="https://www.cnblogs.com/gnuhpc/archive/2012/01/13/2321476.html">https://www.cnblogs.com/gnuhpc/archive/2012/01/13/2321476.html</a></li>
<li><a href="https://draveness.me/dynamo">https://draveness.me/dynamo</a></li>
</ul>
]]></content>
      <categories>
        <category>System Design</category>
        <category>Distributed System</category>
      </categories>
  </entry>
</search>
